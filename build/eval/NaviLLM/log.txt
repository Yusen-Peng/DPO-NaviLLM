2026-01-05 16:50:30,088   INFO  **********************Start logging**********************
2026-01-05 16:50:30,088   INFO  CUDA_VISIBLE_DEVICES=0
2026-01-05 16:50:30,088   INFO  data_dir         /data/wanghaoxuan/data
2026-01-05 16:50:30,088   INFO  cfg_file         configs/multi.yaml
2026-01-05 16:50:30,088   INFO  pretrained_model_name_or_path /data/wanghaoxuan/data/models/Vicuna-7B
2026-01-05 16:50:30,088   INFO  off_batch_task   False
2026-01-05 16:50:30,088   INFO  debug            False
2026-01-05 16:50:30,088   INFO  few_shot         None
2026-01-05 16:50:30,088   INFO  tour3d_nav_head  False
2026-01-05 16:50:30,088   INFO  seed             0
2026-01-05 16:50:30,088   INFO  num_epochs       30
2026-01-05 16:50:30,088   INFO  resume_from_checkpoint /data/wanghaoxuan/model_with_pretrain.pt
2026-01-05 16:50:30,089   INFO  from_scratch     False
2026-01-05 16:50:30,089   INFO  batch_size       4
2026-01-05 16:50:30,089   INFO  val_batch_size   2
2026-01-05 16:50:30,089   INFO  lr               1e-05
2026-01-05 16:50:30,089   INFO  feat_dropout     0.4
2026-01-05 16:50:30,089   INFO  num_warmup_steps 0
2026-01-05 16:50:30,089   INFO  num_steps_per_epoch -1
2026-01-05 16:50:30,089   INFO  gradient_accumulation_step 2
2026-01-05 16:50:30,089   INFO  precision        amp_bf16
2026-01-05 16:50:30,089   INFO  workers          0
2026-01-05 16:50:30,089   INFO  gpu              0
2026-01-05 16:50:30,089   INFO  world_size       1
2026-01-05 16:50:30,089   INFO  local_rank       0
2026-01-05 16:50:30,089   INFO  dist_url         env://
2026-01-05 16:50:30,089   INFO  dist_backend     nccl
2026-01-05 16:50:30,089   INFO  horovod          False
2026-01-05 16:50:30,089   INFO  no_set_device_rank False
2026-01-05 16:50:30,089   INFO  output_dir       build/eval
2026-01-05 16:50:30,089   INFO  max_saved_checkpoints 0
2026-01-05 16:50:30,089   INFO  save_ckpt_per_epochs 10
2026-01-05 16:50:30,090   INFO  save_latest_states False
2026-01-05 16:50:30,090   INFO  save_pred_results False
2026-01-05 16:50:30,090   INFO  save_detail_results False
2026-01-05 16:50:30,090   INFO  mode             test
2026-01-05 16:50:30,090   INFO  stage            multi
2026-01-05 16:50:30,090   INFO  ignoreid         -100
2026-01-05 16:50:30,090   INFO  enable_og        False
2026-01-05 16:50:30,090   INFO  enable_summarize False
2026-01-05 16:50:30,090   INFO  enable_fgr2r     False
2026-01-05 16:50:30,090   INFO  disable_nav      False
2026-01-05 16:50:30,090   INFO  gen_loss_coef    1.0
2026-01-05 16:50:30,090   INFO  obj_loss_coef    1.0
2026-01-05 16:50:30,090   INFO  teacher_forcing_coef 1.0
2026-01-05 16:50:30,090   INFO  fuse_obj         False
2026-01-05 16:50:30,090   INFO  use_lora         False
2026-01-05 16:50:30,090   INFO  lora_rank        8
2026-01-05 16:50:30,090   INFO  lora_alpha       16
2026-01-05 16:50:30,090   INFO  lora_dropout     0.05
2026-01-05 16:50:30,090   INFO  lora_target      None
2026-01-05 16:50:30,091   INFO  freeze_llama     False
2026-01-05 16:50:30,091   INFO  tune_token_emb   False
2026-01-05 16:50:30,091   INFO  no_loc_fts       False
2026-01-05 16:50:30,091   INFO  multi_endpoints  1
2026-01-05 16:50:30,091   INFO  path_type        trusted_path
2026-01-05 16:50:30,091   INFO  test_datasets    ['CVDN']
2026-01-05 16:50:30,091   INFO  validation_split val_unseen
2026-01-05 16:50:30,091   INFO  do_sample        False
2026-01-05 16:50:30,091   INFO  temperature      1.0
2026-01-05 16:50:30,091   INFO  max_datapoints   None
2026-01-05 16:50:30,091   INFO  rank             0
2026-01-05 16:50:30,091   INFO  distributed      False
2026-01-05 16:50:30,091   INFO  device           cuda:0
2026-01-05 16:50:30,091   INFO  image_feat_size  1024
2026-01-05 16:50:30,091   INFO  obj_feat_size    768
2026-01-05 16:50:30,091   INFO  angle_feat_size  4
2026-01-05 16:50:30,091   INFO  enc_full_graph   True
2026-01-05 16:50:30,091   INFO  expert_policy    spl
2026-01-05 16:50:30,091   INFO  num_pano_layers  2
2026-01-05 16:50:30,091   INFO  ----------- Feature -----------
2026-01-05 16:50:30,092   INFO  cfg.Feature.object_feature_type: 
2026-01-05 16:50:30,092   INFO  cfg.Feature.angle_feat_size: 4
2026-01-05 16:50:30,092   INFO  cfg.Feature.max_objects: 70
2026-01-05 16:50:30,092   INFO  cfg.Feature.image_feat_size: 1024
2026-01-05 16:50:30,092   INFO  ----------- feature_database -----------
2026-01-05 16:50:30,092   INFO  cfg.Feature.feature_database.mp3d: eva_features/mp3d_EVA02-CLIP-L-14-336.hdf5
2026-01-05 16:50:30,092   INFO  cfg.Feature.feature_database.scan_qa: eva_features/scanqa_EVA02-CLIP-L-14-336.hdf5
2026-01-05 16:50:30,092   INFO  cfg.Feature.feature_database.room_tour: eva_features/web_obj_prog_p1_EVA02-CLIP-L-14-336.hdf5.bak
2026-01-05 16:50:30,092   INFO  cfg.Feature.feature_database.room3d_tour: eva_features/web_3d_obj_prog_crop_p1_EVA02-CLIP-L-14-336.hdf5
2026-01-05 16:50:30,092   INFO  cfg.Feature.feature_database.coco: eva_features/coco_EVA02-CLIP-L-14-336.hdf5
2026-01-05 16:50:30,092   INFO  cfg.Feature.obj_feat_size: 768
2026-01-05 16:50:30,092   INFO  ----------- object_database -----------
2026-01-05 16:50:30,092   INFO  cfg.Feature.object_database.reverie: obj_features/reverie_obj_feat
2026-01-05 16:50:30,092   INFO  cfg.Feature.object_database.soon: obj_features/soon_obj_feat
2026-01-05 16:50:30,092   INFO  ----------- Dataset -----------
2026-01-05 16:50:30,092   INFO  ----------- R2R -----------
2026-01-05 16:50:30,092   INFO  cfg.Dataset.R2R.DIR: R2R
2026-01-05 16:50:30,092   INFO  ----------- SPLIT -----------
2026-01-05 16:50:30,092   INFO  cfg.Dataset.R2R.SPLIT.train: FGR2R_train.json
2026-01-05 16:50:30,093   INFO  cfg.Dataset.R2R.SPLIT.val_seen: R2R_val_seen_enc.json
2026-01-05 16:50:30,093   INFO  cfg.Dataset.R2R.SPLIT.val_unseen: R2R_val_unseen_enc.json
2026-01-05 16:50:30,093   INFO  cfg.Dataset.R2R.SPLIT.test: R2R_test_enc.json
2026-01-05 16:50:30,093   INFO  ----------- REVERIE -----------
2026-01-05 16:50:30,093   INFO  cfg.Dataset.REVERIE.DIR: REVERIE
2026-01-05 16:50:30,093   INFO  cfg.Dataset.REVERIE.bbox_file: BBoxes.json
2026-01-05 16:50:30,093   INFO  ----------- SPLIT -----------
2026-01-05 16:50:30,093   INFO  cfg.Dataset.REVERIE.SPLIT.train: REVERIE_train_enc.json
2026-01-05 16:50:30,093   INFO  cfg.Dataset.REVERIE.SPLIT.val_seen: REVERIE_val_seen_enc.json
2026-01-05 16:50:30,093   INFO  cfg.Dataset.REVERIE.SPLIT.val_unseen: REVERIE_val_unseen_enc.json
2026-01-05 16:50:30,093   INFO  cfg.Dataset.REVERIE.SPLIT.test: REVERIE_test_enc.json
2026-01-05 16:50:30,093   INFO  ----------- CVDN -----------
2026-01-05 16:50:30,093   INFO  cfg.Dataset.CVDN.DIR: CVDN
2026-01-05 16:50:30,093   INFO  ----------- SPLIT -----------
2026-01-05 16:50:30,093   INFO  cfg.Dataset.CVDN.SPLIT.train: train.json
2026-01-05 16:50:30,093   INFO  cfg.Dataset.CVDN.SPLIT.val_seen: val_seen.json
2026-01-05 16:50:30,093   INFO  cfg.Dataset.CVDN.SPLIT.val_unseen: val_unseen.json
2026-01-05 16:50:30,093   INFO  cfg.Dataset.CVDN.SPLIT.test: test_cleaned.json
2026-01-05 16:50:30,093   INFO  ----------- SOON -----------
2026-01-05 16:50:30,094   INFO  cfg.Dataset.SOON.DIR: SOON
2026-01-05 16:50:30,094   INFO  ----------- SPLIT -----------
2026-01-05 16:50:30,094   INFO  cfg.Dataset.SOON.SPLIT.train: train_enc_pseudo_obj_ade30k_label.jsonl
2026-01-05 16:50:30,094   INFO  cfg.Dataset.SOON.SPLIT.val_seen: val_unseen_instrs_enc_pseudo_obj_ade30k_label.jsonl
2026-01-05 16:50:30,094   INFO  cfg.Dataset.SOON.SPLIT.val_unseen: val_unseen_house_enc_pseudo_obj_ade30k_label.jsonl
2026-01-05 16:50:30,094   INFO  cfg.Dataset.SOON.SPLIT.test: test_v2_enc.jsonl
2026-01-05 16:50:30,094   INFO  ----------- ScanQA -----------
2026-01-05 16:50:30,094   INFO  cfg.Dataset.ScanQA.DIR: ScanQA
2026-01-05 16:50:30,094   INFO  ----------- SPLIT -----------
2026-01-05 16:50:30,094   INFO  cfg.Dataset.ScanQA.SPLIT.train: ScanQA_v1.0_train_reformat.json
2026-01-05 16:50:30,094   INFO  cfg.Dataset.ScanQA.SPLIT.val_unseen: ScanQA_v1.0_val_reformat.json
2026-01-05 16:50:30,094   INFO  cfg.Dataset.ScanQA.SPLIT.test_wo_obj: ScanQA_v1.0_test_wo_obj_reformat.json
2026-01-05 16:50:30,094   INFO  cfg.Dataset.ScanQA.SPLIT.test_w_obj: ScanQA_v1.0_test_w_obj_reformat.json
2026-01-05 16:50:30,094   INFO  ----------- RoomTour -----------
2026-01-05 16:50:30,094   INFO  cfg.Dataset.RoomTour.DIR: RoomTour
2026-01-05 16:50:30,094   INFO  ----------- SPLIT -----------
2026-01-05 16:50:30,094   INFO  cfg.Dataset.RoomTour.SPLIT.train: p1_train_reformat.json
2026-01-05 16:50:30,094   INFO  ----------- Tour3D -----------
2026-01-05 16:50:30,094   INFO  cfg.Dataset.Tour3D.DIR: RoomTour
2026-01-05 16:50:30,094   INFO  ----------- SPLIT -----------
2026-01-05 16:50:30,095   INFO  cfg.Dataset.Tour3D.SPLIT.train: p1_train_colmap_trajectory_tour3d.json
2026-01-05 16:50:30,095   INFO  ----------- EQA -----------
2026-01-05 16:50:30,095   INFO  cfg.Dataset.EQA.DIR: EQA_MP3D
2026-01-05 16:50:30,095   INFO  ----------- SPLIT -----------
2026-01-05 16:50:30,095   INFO  cfg.Dataset.EQA.SPLIT.val_unseen: eqa_val_enc.json
2026-01-05 16:50:30,095   INFO  cfg.Dataset.EQA.ANSWER_VOCAB: eqa_answer_vocab.json
2026-01-05 16:50:30,095   INFO  ----------- R2R_AUG -----------
2026-01-05 16:50:30,095   INFO  cfg.Dataset.R2R_AUG.DIR: R2R
2026-01-05 16:50:30,095   INFO  ----------- SPLIT -----------
2026-01-05 16:50:30,095   INFO  cfg.Dataset.R2R_AUG.SPLIT.train: R2R_prevalent_aug_train_enc.jsonl
2026-01-05 16:50:30,095   INFO  ----------- REVERIE_AUG -----------
2026-01-05 16:50:30,095   INFO  cfg.Dataset.REVERIE_AUG.DIR: REVERIE
2026-01-05 16:50:30,095   INFO  cfg.Dataset.REVERIE_AUG.bbox_file: BBoxes.json
2026-01-05 16:50:30,095   INFO  ----------- SPLIT -----------
2026-01-05 16:50:30,095   INFO  cfg.Dataset.REVERIE_AUG.SPLIT.train: REVERIE_speaker_aug_enc.jsonl
2026-01-05 16:50:30,095   INFO  ----------- LLaVA -----------
2026-01-05 16:50:30,095   INFO  cfg.Dataset.LLaVA.DIR: LLaVA
2026-01-05 16:50:30,095   INFO  ----------- SPLIT -----------
2026-01-05 16:50:30,095   INFO  cfg.Dataset.LLaVA.SPLIT.train: detail_23k.json
2026-01-05 16:50:30,096   INFO  ----------- Pretrain -----------
2026-01-05 16:50:30,096   INFO  cfg.Pretrain.SOURCE: ['Tour3D', 'RoomTour', 'ScanQA', 'LLaVA']
2026-01-05 16:50:30,096   INFO  cfg.Pretrain.Ratio: [10, 20, 5, 2]
2026-01-05 16:50:30,096   INFO  ----------- LOSS_COEF -----------
2026-01-05 16:50:30,096   INFO  cfg.Pretrain.LOSS_COEF.R2R_AUG: 1
2026-01-05 16:50:30,096   INFO  cfg.Pretrain.LOSS_COEF.REVERIE_AUG: 1
2026-01-05 16:50:30,096   INFO  ----------- Multi -----------
2026-01-05 16:50:30,096   INFO  cfg.Multi.SOURCE: ['Tour3D', 'R2R', 'REVERIE', 'CVDN', 'SOON', 'ScanQA', 'LLaVA']
2026-01-05 16:50:30,096   INFO  cfg.Multi.Ratio: [10, 20, 5, 1, 5, 5, 5]
2026-01-05 16:50:30,096   INFO  ----------- LOSS_COEF -----------
2026-01-05 16:50:30,096   INFO  ----------- Model -----------
2026-01-05 16:50:30,096   INFO  cfg.Model.num_l_layers: 9
2026-01-05 16:50:30,096   INFO  cfg.Model.num_pano_layers: 2
2026-01-05 16:50:30,096   INFO  cfg.Model.num_x_layers: 4
2026-01-05 16:50:30,096   INFO  cfg.Model.graph_sprels: True
2026-01-05 16:50:30,096   INFO  cfg.Model.fusion: dynamic
2026-01-05 16:50:30,096   INFO  cfg.Model.enc_full_graph: True
2026-01-05 16:50:30,096   INFO  cfg.Model.expert_policy: spl
2026-01-05 16:50:30,096   INFO  ----------- Optim -----------
2026-01-05 16:50:30,097   INFO  ----------- val_max_action_len -----------
2026-01-05 16:50:30,097   INFO  cfg.Optim.val_max_action_len.R2R: 15
2026-01-05 16:50:30,097   INFO  cfg.Optim.val_max_action_len.REVERIE: 15
2026-01-05 16:50:30,097   INFO  cfg.Optim.val_max_action_len.CVDN: 30
2026-01-05 16:50:30,097   INFO  cfg.Optim.val_max_action_len.SOON: 20
2026-01-05 16:50:30,097   INFO  cfg.Optim.val_max_action_len.EQA: 15
2026-01-05 16:50:30,097   INFO  ----------- train_max_action_len -----------
2026-01-05 16:50:30,097   INFO  cfg.Optim.train_max_action_len.R2R: 15
2026-01-05 16:50:30,097   INFO  cfg.Optim.train_max_action_len.Tour3D: 15
2026-01-05 16:50:30,097   INFO  cfg.Optim.train_max_action_len.REVERIE: 15
2026-01-05 16:50:30,097   INFO  cfg.Optim.train_max_action_len.CVDN: 15
2026-01-05 16:50:30,097   INFO  cfg.Optim.train_max_action_len.SOON: 15
2026-01-05 16:50:30,097   INFO  cfg.Optim.train_max_action_len.EQA: 15
2026-01-05 16:50:30,097   INFO  cfg.Optim.train_max_action_len.R2R_AUG: 15
2026-01-05 16:50:30,097   INFO  cfg.Optim.train_max_action_len.REVERIE_AUG: 15
2026-01-05 16:50:32,444   INFO  [INFO] CVDNDataset loaded with 907 instructions, using splits: val_unseen
2026-01-05 16:50:32,445   INFO  
- Dataset: load 907 CVDN samples
- Dataset: load val_unseen split: 907 samples in total
- Dataset: load val_unseen split: 10 scans in total
2026-01-05 16:50:32,448   INFO  CVDN: 907 samples loaded
2026-01-05 16:50:32,616   INFO  Initialize the model from config.
2026-01-05 16:52:01,132   INFO  model type: torch.bfloat16
2026-01-05 16:52:01,134   INFO  Trainable params: lang_model.model.embed_tokens.weight,lang_model.model.layers.0.self_attn.q_proj.weight,lang_model.model.layers.0.self_attn.k_proj.weight,lang_model.model.layers.0.self_attn.v_proj.weight,lang_model.model.layers.0.self_attn.o_proj.weight,lang_model.model.layers.0.mlp.gate_proj.weight,lang_model.model.layers.0.mlp.down_proj.weight,lang_model.model.layers.0.mlp.up_proj.weight,lang_model.model.layers.0.input_layernorm.weight,lang_model.model.layers.0.post_attention_layernorm.weight,lang_model.model.layers.1.self_attn.q_proj.weight,lang_model.model.layers.1.self_attn.k_proj.weight,lang_model.model.layers.1.self_attn.v_proj.weight,lang_model.model.layers.1.self_attn.o_proj.weight,lang_model.model.layers.1.mlp.gate_proj.weight,lang_model.model.layers.1.mlp.down_proj.weight,lang_model.model.layers.1.mlp.up_proj.weight,lang_model.model.layers.1.input_layernorm.weight,lang_model.model.layers.1.post_attention_layernorm.weight,lang_model.model.layers.2.self_attn.q_proj.weight,lang_model.model.layers.2.self_attn.k_proj.weight,lang_model.model.layers.2.self_attn.v_proj.weight,lang_model.model.layers.2.self_attn.o_proj.weight,lang_model.model.layers.2.mlp.gate_proj.weight,lang_model.model.layers.2.mlp.down_proj.weight,lang_model.model.layers.2.mlp.up_proj.weight,lang_model.model.layers.2.input_layernorm.weight,lang_model.model.layers.2.post_attention_layernorm.weight,lang_model.model.layers.3.self_attn.q_proj.weight,lang_model.model.layers.3.self_attn.k_proj.weight,lang_model.model.layers.3.self_attn.v_proj.weight,lang_model.model.layers.3.self_attn.o_proj.weight,lang_model.model.layers.3.mlp.gate_proj.weight,lang_model.model.layers.3.mlp.down_proj.weight,lang_model.model.layers.3.mlp.up_proj.weight,lang_model.model.layers.3.input_layernorm.weight,lang_model.model.layers.3.post_attention_layernorm.weight,lang_model.model.layers.4.self_attn.q_proj.weight,lang_model.model.layers.4.self_attn.k_proj.weight,lang_model.model.layers.4.self_attn.v_proj.weight,lang_model.model.layers.4.self_attn.o_proj.weight,lang_model.model.layers.4.mlp.gate_proj.weight,lang_model.model.layers.4.mlp.down_proj.weight,lang_model.model.layers.4.mlp.up_proj.weight,lang_model.model.layers.4.input_layernorm.weight,lang_model.model.layers.4.post_attention_layernorm.weight,lang_model.model.layers.5.self_attn.q_proj.weight,lang_model.model.layers.5.self_attn.k_proj.weight,lang_model.model.layers.5.self_attn.v_proj.weight,lang_model.model.layers.5.self_attn.o_proj.weight,lang_model.model.layers.5.mlp.gate_proj.weight,lang_model.model.layers.5.mlp.down_proj.weight,lang_model.model.layers.5.mlp.up_proj.weight,lang_model.model.layers.5.input_layernorm.weight,lang_model.model.layers.5.post_attention_layernorm.weight,lang_model.model.layers.6.self_attn.q_proj.weight,lang_model.model.layers.6.self_attn.k_proj.weight,lang_model.model.layers.6.self_attn.v_proj.weight,lang_model.model.layers.6.self_attn.o_proj.weight,lang_model.model.layers.6.mlp.gate_proj.weight,lang_model.model.layers.6.mlp.down_proj.weight,lang_model.model.layers.6.mlp.up_proj.weight,lang_model.model.layers.6.input_layernorm.weight,lang_model.model.layers.6.post_attention_layernorm.weight,lang_model.model.layers.7.self_attn.q_proj.weight,lang_model.model.layers.7.self_attn.k_proj.weight,lang_model.model.layers.7.self_attn.v_proj.weight,lang_model.model.layers.7.self_attn.o_proj.weight,lang_model.model.layers.7.mlp.gate_proj.weight,lang_model.model.layers.7.mlp.down_proj.weight,lang_model.model.layers.7.mlp.up_proj.weight,lang_model.model.layers.7.input_layernorm.weight,lang_model.model.layers.7.post_attention_layernorm.weight,lang_model.model.layers.8.self_attn.q_proj.weight,lang_model.model.layers.8.self_attn.k_proj.weight,lang_model.model.layers.8.self_attn.v_proj.weight,lang_model.model.layers.8.self_attn.o_proj.weight,lang_model.model.layers.8.mlp.gate_proj.weight,lang_model.model.layers.8.mlp.down_proj.weight,lang_model.model.layers.8.mlp.up_proj.weight,lang_model.model.layers.8.input_layernorm.weight,lang_model.model.layers.8.post_attention_layernorm.weight,lang_model.model.layers.9.self_attn.q_proj.weight,lang_model.model.layers.9.self_attn.k_proj.weight,lang_model.model.layers.9.self_attn.v_proj.weight,lang_model.model.layers.9.self_attn.o_proj.weight,lang_model.model.layers.9.mlp.gate_proj.weight,lang_model.model.layers.9.mlp.down_proj.weight,lang_model.model.layers.9.mlp.up_proj.weight,lang_model.model.layers.9.input_layernorm.weight,lang_model.model.layers.9.post_attention_layernorm.weight,lang_model.model.layers.10.self_attn.q_proj.weight,lang_model.model.layers.10.self_attn.k_proj.weight,lang_model.model.layers.10.self_attn.v_proj.weight,lang_model.model.layers.10.self_attn.o_proj.weight,lang_model.model.layers.10.mlp.gate_proj.weight,lang_model.model.layers.10.mlp.down_proj.weight,lang_model.model.layers.10.mlp.up_proj.weight,lang_model.model.layers.10.input_layernorm.weight,lang_model.model.layers.10.post_attention_layernorm.weight,lang_model.model.layers.11.self_attn.q_proj.weight,lang_model.model.layers.11.self_attn.k_proj.weight,lang_model.model.layers.11.self_attn.v_proj.weight,lang_model.model.layers.11.self_attn.o_proj.weight,lang_model.model.layers.11.mlp.gate_proj.weight,lang_model.model.layers.11.mlp.down_proj.weight,lang_model.model.layers.11.mlp.up_proj.weight,lang_model.model.layers.11.input_layernorm.weight,lang_model.model.layers.11.post_attention_layernorm.weight,lang_model.model.layers.12.self_attn.q_proj.weight,lang_model.model.layers.12.self_attn.k_proj.weight,lang_model.model.layers.12.self_attn.v_proj.weight,lang_model.model.layers.12.self_attn.o_proj.weight,lang_model.model.layers.12.mlp.gate_proj.weight,lang_model.model.layers.12.mlp.down_proj.weight,lang_model.model.layers.12.mlp.up_proj.weight,lang_model.model.layers.12.input_layernorm.weight,lang_model.model.layers.12.post_attention_layernorm.weight,lang_model.model.layers.13.self_attn.q_proj.weight,lang_model.model.layers.13.self_attn.k_proj.weight,lang_model.model.layers.13.self_attn.v_proj.weight,lang_model.model.layers.13.self_attn.o_proj.weight,lang_model.model.layers.13.mlp.gate_proj.weight,lang_model.model.layers.13.mlp.down_proj.weight,lang_model.model.layers.13.mlp.up_proj.weight,lang_model.model.layers.13.input_layernorm.weight,lang_model.model.layers.13.post_attention_layernorm.weight,lang_model.model.layers.14.self_attn.q_proj.weight,lang_model.model.layers.14.self_attn.k_proj.weight,lang_model.model.layers.14.self_attn.v_proj.weight,lang_model.model.layers.14.self_attn.o_proj.weight,lang_model.model.layers.14.mlp.gate_proj.weight,lang_model.model.layers.14.mlp.down_proj.weight,lang_model.model.layers.14.mlp.up_proj.weight,lang_model.model.layers.14.input_layernorm.weight,lang_model.model.layers.14.post_attention_layernorm.weight,lang_model.model.layers.15.self_attn.q_proj.weight,lang_model.model.layers.15.self_attn.k_proj.weight,lang_model.model.layers.15.self_attn.v_proj.weight,lang_model.model.layers.15.self_attn.o_proj.weight,lang_model.model.layers.15.mlp.gate_proj.weight,lang_model.model.layers.15.mlp.down_proj.weight,lang_model.model.layers.15.mlp.up_proj.weight,lang_model.model.layers.15.input_layernorm.weight,lang_model.model.layers.15.post_attention_layernorm.weight,lang_model.model.layers.16.self_attn.q_proj.weight,lang_model.model.layers.16.self_attn.k_proj.weight,lang_model.model.layers.16.self_attn.v_proj.weight,lang_model.model.layers.16.self_attn.o_proj.weight,lang_model.model.layers.16.mlp.gate_proj.weight,lang_model.model.layers.16.mlp.down_proj.weight,lang_model.model.layers.16.mlp.up_proj.weight,lang_model.model.layers.16.input_layernorm.weight,lang_model.model.layers.16.post_attention_layernorm.weight,lang_model.model.layers.17.self_attn.q_proj.weight,lang_model.model.layers.17.self_attn.k_proj.weight,lang_model.model.layers.17.self_attn.v_proj.weight,lang_model.model.layers.17.self_attn.o_proj.weight,lang_model.model.layers.17.mlp.gate_proj.weight,lang_model.model.layers.17.mlp.down_proj.weight,lang_model.model.layers.17.mlp.up_proj.weight,lang_model.model.layers.17.input_layernorm.weight,lang_model.model.layers.17.post_attention_layernorm.weight,lang_model.model.layers.18.self_attn.q_proj.weight,lang_model.model.layers.18.self_attn.k_proj.weight,lang_model.model.layers.18.self_attn.v_proj.weight,lang_model.model.layers.18.self_attn.o_proj.weight,lang_model.model.layers.18.mlp.gate_proj.weight,lang_model.model.layers.18.mlp.down_proj.weight,lang_model.model.layers.18.mlp.up_proj.weight,lang_model.model.layers.18.input_layernorm.weight,lang_model.model.layers.18.post_attention_layernorm.weight,lang_model.model.layers.19.self_attn.q_proj.weight,lang_model.model.layers.19.self_attn.k_proj.weight,lang_model.model.layers.19.self_attn.v_proj.weight,lang_model.model.layers.19.self_attn.o_proj.weight,lang_model.model.layers.19.mlp.gate_proj.weight,lang_model.model.layers.19.mlp.down_proj.weight,lang_model.model.layers.19.mlp.up_proj.weight,lang_model.model.layers.19.input_layernorm.weight,lang_model.model.layers.19.post_attention_layernorm.weight,lang_model.model.layers.20.self_attn.q_proj.weight,lang_model.model.layers.20.self_attn.k_proj.weight,lang_model.model.layers.20.self_attn.v_proj.weight,lang_model.model.layers.20.self_attn.o_proj.weight,lang_model.model.layers.20.mlp.gate_proj.weight,lang_model.model.layers.20.mlp.down_proj.weight,lang_model.model.layers.20.mlp.up_proj.weight,lang_model.model.layers.20.input_layernorm.weight,lang_model.model.layers.20.post_attention_layernorm.weight,lang_model.model.layers.21.self_attn.q_proj.weight,lang_model.model.layers.21.self_attn.k_proj.weight,lang_model.model.layers.21.self_attn.v_proj.weight,lang_model.model.layers.21.self_attn.o_proj.weight,lang_model.model.layers.21.mlp.gate_proj.weight,lang_model.model.layers.21.mlp.down_proj.weight,lang_model.model.layers.21.mlp.up_proj.weight,lang_model.model.layers.21.input_layernorm.weight,lang_model.model.layers.21.post_attention_layernorm.weight,lang_model.model.layers.22.self_attn.q_proj.weight,lang_model.model.layers.22.self_attn.k_proj.weight,lang_model.model.layers.22.self_attn.v_proj.weight,lang_model.model.layers.22.self_attn.o_proj.weight,lang_model.model.layers.22.mlp.gate_proj.weight,lang_model.model.layers.22.mlp.down_proj.weight,lang_model.model.layers.22.mlp.up_proj.weight,lang_model.model.layers.22.input_layernorm.weight,lang_model.model.layers.22.post_attention_layernorm.weight,lang_model.model.layers.23.self_attn.q_proj.weight,lang_model.model.layers.23.self_attn.k_proj.weight,lang_model.model.layers.23.self_attn.v_proj.weight,lang_model.model.layers.23.self_attn.o_proj.weight,lang_model.model.layers.23.mlp.gate_proj.weight,lang_model.model.layers.23.mlp.down_proj.weight,lang_model.model.layers.23.mlp.up_proj.weight,lang_model.model.layers.23.input_layernorm.weight,lang_model.model.layers.23.post_attention_layernorm.weight,lang_model.model.layers.24.self_attn.q_proj.weight,lang_model.model.layers.24.self_attn.k_proj.weight,lang_model.model.layers.24.self_attn.v_proj.weight,lang_model.model.layers.24.self_attn.o_proj.weight,lang_model.model.layers.24.mlp.gate_proj.weight,lang_model.model.layers.24.mlp.down_proj.weight,lang_model.model.layers.24.mlp.up_proj.weight,lang_model.model.layers.24.input_layernorm.weight,lang_model.model.layers.24.post_attention_layernorm.weight,lang_model.model.layers.25.self_attn.q_proj.weight,lang_model.model.layers.25.self_attn.k_proj.weight,lang_model.model.layers.25.self_attn.v_proj.weight,lang_model.model.layers.25.self_attn.o_proj.weight,lang_model.model.layers.25.mlp.gate_proj.weight,lang_model.model.layers.25.mlp.down_proj.weight,lang_model.model.layers.25.mlp.up_proj.weight,lang_model.model.layers.25.input_layernorm.weight,lang_model.model.layers.25.post_attention_layernorm.weight,lang_model.model.layers.26.self_attn.q_proj.weight,lang_model.model.layers.26.self_attn.k_proj.weight,lang_model.model.layers.26.self_attn.v_proj.weight,lang_model.model.layers.26.self_attn.o_proj.weight,lang_model.model.layers.26.mlp.gate_proj.weight,lang_model.model.layers.26.mlp.down_proj.weight,lang_model.model.layers.26.mlp.up_proj.weight,lang_model.model.layers.26.input_layernorm.weight,lang_model.model.layers.26.post_attention_layernorm.weight,lang_model.model.layers.27.self_attn.q_proj.weight,lang_model.model.layers.27.self_attn.k_proj.weight,lang_model.model.layers.27.self_attn.v_proj.weight,lang_model.model.layers.27.self_attn.o_proj.weight,lang_model.model.layers.27.mlp.gate_proj.weight,lang_model.model.layers.27.mlp.down_proj.weight,lang_model.model.layers.27.mlp.up_proj.weight,lang_model.model.layers.27.input_layernorm.weight,lang_model.model.layers.27.post_attention_layernorm.weight,lang_model.model.layers.28.self_attn.q_proj.weight,lang_model.model.layers.28.self_attn.k_proj.weight,lang_model.model.layers.28.self_attn.v_proj.weight,lang_model.model.layers.28.self_attn.o_proj.weight,lang_model.model.layers.28.mlp.gate_proj.weight,lang_model.model.layers.28.mlp.down_proj.weight,lang_model.model.layers.28.mlp.up_proj.weight,lang_model.model.layers.28.input_layernorm.weight,lang_model.model.layers.28.post_attention_layernorm.weight,lang_model.model.layers.29.self_attn.q_proj.weight,lang_model.model.layers.29.self_attn.k_proj.weight,lang_model.model.layers.29.self_attn.v_proj.weight,lang_model.model.layers.29.self_attn.o_proj.weight,lang_model.model.layers.29.mlp.gate_proj.weight,lang_model.model.layers.29.mlp.down_proj.weight,lang_model.model.layers.29.mlp.up_proj.weight,lang_model.model.layers.29.input_layernorm.weight,lang_model.model.layers.29.post_attention_layernorm.weight,lang_model.model.layers.30.self_attn.q_proj.weight,lang_model.model.layers.30.self_attn.k_proj.weight,lang_model.model.layers.30.self_attn.v_proj.weight,lang_model.model.layers.30.self_attn.o_proj.weight,lang_model.model.layers.30.mlp.gate_proj.weight,lang_model.model.layers.30.mlp.down_proj.weight,lang_model.model.layers.30.mlp.up_proj.weight,lang_model.model.layers.30.input_layernorm.weight,lang_model.model.layers.30.post_attention_layernorm.weight,lang_model.model.layers.31.self_attn.q_proj.weight,lang_model.model.layers.31.self_attn.k_proj.weight,lang_model.model.layers.31.self_attn.v_proj.weight,lang_model.model.layers.31.self_attn.o_proj.weight,lang_model.model.layers.31.mlp.gate_proj.weight,lang_model.model.layers.31.mlp.down_proj.weight,lang_model.model.layers.31.mlp.up_proj.weight,lang_model.model.layers.31.input_layernorm.weight,lang_model.model.layers.31.post_attention_layernorm.weight,lang_model.model.norm.weight,lang_model.lm_head.weight,img_embeddings.img_linear.weight,img_embeddings.img_linear.bias,img_embeddings.img_layer_norm.weight,img_embeddings.img_layer_norm.bias,img_embeddings.loc_linear.weight,img_embeddings.loc_linear.bias,img_embeddings.loc_layer_norm.weight,img_embeddings.loc_layer_norm.bias,img_embeddings.nav_type_embedding.weight,img_embeddings.layer_norm.weight,img_embeddings.layer_norm.bias,img_embeddings.pano_encoder.layers.0.self_attn.in_proj_weight,img_embeddings.pano_encoder.layers.0.self_attn.in_proj_bias,img_embeddings.pano_encoder.layers.0.self_attn.out_proj.weight,img_embeddings.pano_encoder.layers.0.self_attn.out_proj.bias,img_embeddings.pano_encoder.layers.0.linear1.weight,img_embeddings.pano_encoder.layers.0.linear1.bias,img_embeddings.pano_encoder.layers.0.linear2.weight,img_embeddings.pano_encoder.layers.0.linear2.bias,img_embeddings.pano_encoder.layers.0.norm1.weight,img_embeddings.pano_encoder.layers.0.norm1.bias,img_embeddings.pano_encoder.layers.0.norm2.weight,img_embeddings.pano_encoder.layers.0.norm2.bias,img_embeddings.pano_encoder.layers.1.self_attn.in_proj_weight,img_embeddings.pano_encoder.layers.1.self_attn.in_proj_bias,img_embeddings.pano_encoder.layers.1.self_attn.out_proj.weight,img_embeddings.pano_encoder.layers.1.self_attn.out_proj.bias,img_embeddings.pano_encoder.layers.1.linear1.weight,img_embeddings.pano_encoder.layers.1.linear1.bias,img_embeddings.pano_encoder.layers.1.linear2.weight,img_embeddings.pano_encoder.layers.1.linear2.bias,img_embeddings.pano_encoder.layers.1.norm1.weight,img_embeddings.pano_encoder.layers.1.norm1.bias,img_embeddings.pano_encoder.layers.1.norm2.weight,img_embeddings.pano_encoder.layers.1.norm2.bias,img_embeddings.pano_encoder.norm.weight,img_embeddings.pano_encoder.norm.bias,img_embeddings.mapper.weight,img_embeddings.mapper.bias,token_type_embeddings.weight,gmap_pos_embeddings.0.weight,gmap_pos_embeddings.0.bias,gmap_pos_embeddings.1.weight,gmap_pos_embeddings.1.bias,gmap_step_embeddings.weight,vp_pos_embeddings.0.weight,vp_pos_embeddings.0.bias,vp_pos_embeddings.1.weight,vp_pos_embeddings.1.bias,obj_pos_embeddings.0.weight,obj_pos_embeddings.0.bias,obj_pos_embeddings.1.weight,obj_pos_embeddings.1.bias,og_head.0.weight,og_head.0.bias,out_head.0.weight,out_head.0.bias
2026-01-05 16:52:01,135   INFO  *************** init model *************** 
2026-01-05 16:52:04,932   INFO  Loading checkpoint from /data/wanghaoxuan/model_with_pretrain.pt
2026-01-05 16:52:10,542   INFO  Ignore weight img_embeddings.obj_projector.0.weight: torch.Size([4096, 768])
2026-01-05 16:52:10,543   INFO  Ignore weight img_embeddings.obj_projector.0.bias: torch.Size([4096])
2026-01-05 16:52:10,543   INFO  Ignore weight img_embeddings.obj_projector.1.weight: torch.Size([4096])
2026-01-05 16:52:10,544   INFO  Ignore weight img_embeddings.obj_projector.1.bias: torch.Size([4096])
2026-01-05 16:52:11,993   INFO  <All keys matched successfully>
2026-01-05 16:52:12,347   INFO  model initialized with 6770.32 M trainable parameters
2026-01-05 16:52:12,348   INFO  Training with a single process
2026-01-05 16:52:12,348   INFO  **************************** Test ****************************
2026-01-05 16:52:12,350   INFO  ***** validate val_unseen split on CVDN task *****
2026-01-05 17:20:08,674   INFO  eval 907 predictions
2026-01-05 17:20:08,737   INFO  
[Eval] val_unseen epoch 0

 [Eval] dataset=[CVDN] 
, lengths: 46.32, nav_error: 13.51, oracle_sr: 58.21
[Eval] ||| sr: 15.66, spl: 11.11, oracle path_success_rate: 88.09, dist_to_end_reduction: 6.13
2026-01-05 17:46:33,078   INFO  **********************Start logging**********************
2026-01-05 17:46:33,078   INFO  CUDA_VISIBLE_DEVICES=0
2026-01-05 17:46:33,078   INFO  data_dir         /data/wanghaoxuan/data
2026-01-05 17:46:33,078   INFO  cfg_file         configs/multi.yaml
2026-01-05 17:46:33,078   INFO  pretrained_model_name_or_path /data/wanghaoxuan/data/models/Vicuna-7B
2026-01-05 17:46:33,078   INFO  off_batch_task   False
2026-01-05 17:46:33,078   INFO  debug            False
2026-01-05 17:46:33,079   INFO  few_shot         None
2026-01-05 17:46:33,079   INFO  tour3d_nav_head  False
2026-01-05 17:46:33,079   INFO  seed             0
2026-01-05 17:46:33,079   INFO  num_epochs       30
2026-01-05 17:46:33,079   INFO  resume_from_checkpoint /data/wanghaoxuan/model_with_pretrain.pt
2026-01-05 17:46:33,079   INFO  from_scratch     False
2026-01-05 17:46:33,079   INFO  batch_size       4
2026-01-05 17:46:33,079   INFO  val_batch_size   2
2026-01-05 17:46:33,079   INFO  lr               1e-05
2026-01-05 17:46:33,079   INFO  feat_dropout     0.4
2026-01-05 17:46:33,079   INFO  num_warmup_steps 0
2026-01-05 17:46:33,079   INFO  num_steps_per_epoch -1
2026-01-05 17:46:33,079   INFO  gradient_accumulation_step 2
2026-01-05 17:46:33,079   INFO  precision        amp_bf16
2026-01-05 17:46:33,079   INFO  workers          0
2026-01-05 17:46:33,079   INFO  gpu              0
2026-01-05 17:46:33,079   INFO  world_size       1
2026-01-05 17:46:33,079   INFO  local_rank       0
2026-01-05 17:46:33,079   INFO  dist_url         env://
2026-01-05 17:46:33,079   INFO  dist_backend     nccl
2026-01-05 17:46:33,080   INFO  horovod          False
2026-01-05 17:46:33,080   INFO  no_set_device_rank False
2026-01-05 17:46:33,080   INFO  output_dir       build/eval
2026-01-05 17:46:33,080   INFO  max_saved_checkpoints 0
2026-01-05 17:46:33,080   INFO  save_ckpt_per_epochs 10
2026-01-05 17:46:33,080   INFO  save_latest_states False
2026-01-05 17:46:33,080   INFO  save_pred_results False
2026-01-05 17:46:33,080   INFO  save_detail_results False
2026-01-05 17:46:33,080   INFO  mode             test
2026-01-05 17:46:33,080   INFO  stage            multi
2026-01-05 17:46:33,080   INFO  ignoreid         -100
2026-01-05 17:46:33,080   INFO  enable_og        False
2026-01-05 17:46:33,080   INFO  enable_summarize False
2026-01-05 17:46:33,080   INFO  enable_fgr2r     False
2026-01-05 17:46:33,080   INFO  disable_nav      False
2026-01-05 17:46:33,080   INFO  gen_loss_coef    1.0
2026-01-05 17:46:33,080   INFO  obj_loss_coef    1.0
2026-01-05 17:46:33,080   INFO  teacher_forcing_coef 1.0
2026-01-05 17:46:33,080   INFO  fuse_obj         False
2026-01-05 17:46:33,080   INFO  use_lora         False
2026-01-05 17:46:33,081   INFO  lora_rank        8
2026-01-05 17:46:33,081   INFO  lora_alpha       16
2026-01-05 17:46:33,081   INFO  lora_dropout     0.05
2026-01-05 17:46:33,081   INFO  lora_target      None
2026-01-05 17:46:33,081   INFO  freeze_llama     False
2026-01-05 17:46:33,081   INFO  tune_token_emb   False
2026-01-05 17:46:33,081   INFO  no_loc_fts       False
2026-01-05 17:46:33,081   INFO  multi_endpoints  1
2026-01-05 17:46:33,081   INFO  path_type        trusted_path
2026-01-05 17:46:33,081   INFO  test_datasets    ['CVDN']
2026-01-05 17:46:33,081   INFO  validation_split test
2026-01-05 17:46:33,081   INFO  do_sample        False
2026-01-05 17:46:33,081   INFO  temperature      1.0
2026-01-05 17:46:33,081   INFO  max_datapoints   None
2026-01-05 17:46:33,081   INFO  rank             0
2026-01-05 17:46:33,081   INFO  distributed      False
2026-01-05 17:46:33,081   INFO  device           cuda:0
2026-01-05 17:46:33,081   INFO  image_feat_size  1024
2026-01-05 17:46:33,081   INFO  obj_feat_size    768
2026-01-05 17:46:33,081   INFO  angle_feat_size  4
2026-01-05 17:46:33,082   INFO  enc_full_graph   True
2026-01-05 17:46:33,082   INFO  expert_policy    spl
2026-01-05 17:46:33,082   INFO  num_pano_layers  2
2026-01-05 17:46:33,082   INFO  ----------- Feature -----------
2026-01-05 17:46:33,082   INFO  cfg.Feature.object_feature_type: 
2026-01-05 17:46:33,082   INFO  cfg.Feature.angle_feat_size: 4
2026-01-05 17:46:33,082   INFO  cfg.Feature.max_objects: 70
2026-01-05 17:46:33,082   INFO  cfg.Feature.image_feat_size: 1024
2026-01-05 17:46:33,082   INFO  ----------- feature_database -----------
2026-01-05 17:46:33,082   INFO  cfg.Feature.feature_database.mp3d: eva_features/mp3d_EVA02-CLIP-L-14-336.hdf5
2026-01-05 17:46:33,082   INFO  cfg.Feature.feature_database.scan_qa: eva_features/scanqa_EVA02-CLIP-L-14-336.hdf5
2026-01-05 17:46:33,082   INFO  cfg.Feature.feature_database.room_tour: eva_features/web_obj_prog_p1_EVA02-CLIP-L-14-336.hdf5.bak
2026-01-05 17:46:33,082   INFO  cfg.Feature.feature_database.room3d_tour: eva_features/web_3d_obj_prog_crop_p1_EVA02-CLIP-L-14-336.hdf5
2026-01-05 17:46:33,082   INFO  cfg.Feature.feature_database.coco: eva_features/coco_EVA02-CLIP-L-14-336.hdf5
2026-01-05 17:46:33,082   INFO  cfg.Feature.obj_feat_size: 768
2026-01-05 17:46:33,082   INFO  ----------- object_database -----------
2026-01-05 17:46:33,082   INFO  cfg.Feature.object_database.reverie: obj_features/reverie_obj_feat
2026-01-05 17:46:33,082   INFO  cfg.Feature.object_database.soon: obj_features/soon_obj_feat
2026-01-05 17:46:33,082   INFO  ----------- Dataset -----------
2026-01-05 17:46:33,082   INFO  ----------- R2R -----------
2026-01-05 17:46:33,083   INFO  cfg.Dataset.R2R.DIR: R2R
2026-01-05 17:46:33,083   INFO  ----------- SPLIT -----------
2026-01-05 17:46:33,083   INFO  cfg.Dataset.R2R.SPLIT.train: FGR2R_train.json
2026-01-05 17:46:33,083   INFO  cfg.Dataset.R2R.SPLIT.val_seen: R2R_val_seen_enc.json
2026-01-05 17:46:33,083   INFO  cfg.Dataset.R2R.SPLIT.val_unseen: R2R_val_unseen_enc.json
2026-01-05 17:46:33,083   INFO  cfg.Dataset.R2R.SPLIT.test: R2R_test_enc.json
2026-01-05 17:46:33,083   INFO  ----------- REVERIE -----------
2026-01-05 17:46:33,083   INFO  cfg.Dataset.REVERIE.DIR: REVERIE
2026-01-05 17:46:33,083   INFO  cfg.Dataset.REVERIE.bbox_file: BBoxes.json
2026-01-05 17:46:33,083   INFO  ----------- SPLIT -----------
2026-01-05 17:46:33,083   INFO  cfg.Dataset.REVERIE.SPLIT.train: REVERIE_train_enc.json
2026-01-05 17:46:33,083   INFO  cfg.Dataset.REVERIE.SPLIT.val_seen: REVERIE_val_seen_enc.json
2026-01-05 17:46:33,083   INFO  cfg.Dataset.REVERIE.SPLIT.val_unseen: REVERIE_val_unseen_enc.json
2026-01-05 17:46:33,083   INFO  cfg.Dataset.REVERIE.SPLIT.test: REVERIE_test_enc.json
2026-01-05 17:46:33,083   INFO  ----------- CVDN -----------
2026-01-05 17:46:33,083   INFO  cfg.Dataset.CVDN.DIR: CVDN
2026-01-05 17:46:33,083   INFO  ----------- SPLIT -----------
2026-01-05 17:46:33,083   INFO  cfg.Dataset.CVDN.SPLIT.train: train.json
2026-01-05 17:46:33,083   INFO  cfg.Dataset.CVDN.SPLIT.val_seen: val_seen.json
2026-01-05 17:46:33,083   INFO  cfg.Dataset.CVDN.SPLIT.val_unseen: val_unseen.json
2026-01-05 17:46:33,084   INFO  cfg.Dataset.CVDN.SPLIT.test: test_cleaned.json
2026-01-05 17:46:33,084   INFO  ----------- SOON -----------
2026-01-05 17:46:33,084   INFO  cfg.Dataset.SOON.DIR: SOON
2026-01-05 17:46:33,084   INFO  ----------- SPLIT -----------
2026-01-05 17:46:33,084   INFO  cfg.Dataset.SOON.SPLIT.train: train_enc_pseudo_obj_ade30k_label.jsonl
2026-01-05 17:46:33,084   INFO  cfg.Dataset.SOON.SPLIT.val_seen: val_unseen_instrs_enc_pseudo_obj_ade30k_label.jsonl
2026-01-05 17:46:33,084   INFO  cfg.Dataset.SOON.SPLIT.val_unseen: val_unseen_house_enc_pseudo_obj_ade30k_label.jsonl
2026-01-05 17:46:33,084   INFO  cfg.Dataset.SOON.SPLIT.test: test_v2_enc.jsonl
2026-01-05 17:46:33,084   INFO  ----------- ScanQA -----------
2026-01-05 17:46:33,084   INFO  cfg.Dataset.ScanQA.DIR: ScanQA
2026-01-05 17:46:33,084   INFO  ----------- SPLIT -----------
2026-01-05 17:46:33,084   INFO  cfg.Dataset.ScanQA.SPLIT.train: ScanQA_v1.0_train_reformat.json
2026-01-05 17:46:33,084   INFO  cfg.Dataset.ScanQA.SPLIT.val_unseen: ScanQA_v1.0_val_reformat.json
2026-01-05 17:46:33,084   INFO  cfg.Dataset.ScanQA.SPLIT.test_wo_obj: ScanQA_v1.0_test_wo_obj_reformat.json
2026-01-05 17:46:33,084   INFO  cfg.Dataset.ScanQA.SPLIT.test_w_obj: ScanQA_v1.0_test_w_obj_reformat.json
2026-01-05 17:46:33,084   INFO  ----------- RoomTour -----------
2026-01-05 17:46:33,084   INFO  cfg.Dataset.RoomTour.DIR: RoomTour
2026-01-05 17:46:33,084   INFO  ----------- SPLIT -----------
2026-01-05 17:46:33,084   INFO  cfg.Dataset.RoomTour.SPLIT.train: p1_train_reformat.json
2026-01-05 17:46:33,084   INFO  ----------- Tour3D -----------
2026-01-05 17:46:33,084   INFO  cfg.Dataset.Tour3D.DIR: RoomTour
2026-01-05 17:46:33,085   INFO  ----------- SPLIT -----------
2026-01-05 17:46:33,085   INFO  cfg.Dataset.Tour3D.SPLIT.train: p1_train_colmap_trajectory_tour3d.json
2026-01-05 17:46:33,085   INFO  ----------- EQA -----------
2026-01-05 17:46:33,085   INFO  cfg.Dataset.EQA.DIR: EQA_MP3D
2026-01-05 17:46:33,085   INFO  ----------- SPLIT -----------
2026-01-05 17:46:33,085   INFO  cfg.Dataset.EQA.SPLIT.val_unseen: eqa_val_enc.json
2026-01-05 17:46:33,085   INFO  cfg.Dataset.EQA.ANSWER_VOCAB: eqa_answer_vocab.json
2026-01-05 17:46:33,085   INFO  ----------- R2R_AUG -----------
2026-01-05 17:46:33,085   INFO  cfg.Dataset.R2R_AUG.DIR: R2R
2026-01-05 17:46:33,085   INFO  ----------- SPLIT -----------
2026-01-05 17:46:33,085   INFO  cfg.Dataset.R2R_AUG.SPLIT.train: R2R_prevalent_aug_train_enc.jsonl
2026-01-05 17:46:33,085   INFO  ----------- REVERIE_AUG -----------
2026-01-05 17:46:33,085   INFO  cfg.Dataset.REVERIE_AUG.DIR: REVERIE
2026-01-05 17:46:33,085   INFO  cfg.Dataset.REVERIE_AUG.bbox_file: BBoxes.json
2026-01-05 17:46:33,085   INFO  ----------- SPLIT -----------
2026-01-05 17:46:33,085   INFO  cfg.Dataset.REVERIE_AUG.SPLIT.train: REVERIE_speaker_aug_enc.jsonl
2026-01-05 17:46:33,085   INFO  ----------- LLaVA -----------
2026-01-05 17:46:33,085   INFO  cfg.Dataset.LLaVA.DIR: LLaVA
2026-01-05 17:46:33,085   INFO  ----------- SPLIT -----------
2026-01-05 17:46:33,086   INFO  cfg.Dataset.LLaVA.SPLIT.train: detail_23k.json
2026-01-05 17:46:33,086   INFO  ----------- Pretrain -----------
2026-01-05 17:46:33,086   INFO  cfg.Pretrain.SOURCE: ['Tour3D', 'RoomTour', 'ScanQA', 'LLaVA']
2026-01-05 17:46:33,086   INFO  cfg.Pretrain.Ratio: [10, 20, 5, 2]
2026-01-05 17:46:33,086   INFO  ----------- LOSS_COEF -----------
2026-01-05 17:46:33,086   INFO  cfg.Pretrain.LOSS_COEF.R2R_AUG: 1
2026-01-05 17:46:33,086   INFO  cfg.Pretrain.LOSS_COEF.REVERIE_AUG: 1
2026-01-05 17:46:33,086   INFO  ----------- Multi -----------
2026-01-05 17:46:33,086   INFO  cfg.Multi.SOURCE: ['Tour3D', 'R2R', 'REVERIE', 'CVDN', 'SOON', 'ScanQA', 'LLaVA']
2026-01-05 17:46:33,086   INFO  cfg.Multi.Ratio: [10, 20, 5, 1, 5, 5, 5]
2026-01-05 17:46:33,086   INFO  ----------- LOSS_COEF -----------
2026-01-05 17:46:33,086   INFO  ----------- Model -----------
2026-01-05 17:46:33,086   INFO  cfg.Model.num_l_layers: 9
2026-01-05 17:46:33,086   INFO  cfg.Model.num_pano_layers: 2
2026-01-05 17:46:33,086   INFO  cfg.Model.num_x_layers: 4
2026-01-05 17:46:33,086   INFO  cfg.Model.graph_sprels: True
2026-01-05 17:46:33,086   INFO  cfg.Model.fusion: dynamic
2026-01-05 17:46:33,086   INFO  cfg.Model.enc_full_graph: True
2026-01-05 17:46:33,086   INFO  cfg.Model.expert_policy: spl
2026-01-05 17:46:33,086   INFO  ----------- Optim -----------
2026-01-05 17:46:33,087   INFO  ----------- val_max_action_len -----------
2026-01-05 17:46:33,087   INFO  cfg.Optim.val_max_action_len.R2R: 15
2026-01-05 17:46:33,087   INFO  cfg.Optim.val_max_action_len.REVERIE: 15
2026-01-05 17:46:33,087   INFO  cfg.Optim.val_max_action_len.CVDN: 30
2026-01-05 17:46:33,087   INFO  cfg.Optim.val_max_action_len.SOON: 20
2026-01-05 17:46:33,087   INFO  cfg.Optim.val_max_action_len.EQA: 15
2026-01-05 17:46:33,087   INFO  ----------- train_max_action_len -----------
2026-01-05 17:46:33,087   INFO  cfg.Optim.train_max_action_len.R2R: 15
2026-01-05 17:46:33,087   INFO  cfg.Optim.train_max_action_len.Tour3D: 15
2026-01-05 17:46:33,087   INFO  cfg.Optim.train_max_action_len.REVERIE: 15
2026-01-05 17:46:33,087   INFO  cfg.Optim.train_max_action_len.CVDN: 15
2026-01-05 17:46:33,087   INFO  cfg.Optim.train_max_action_len.SOON: 15
2026-01-05 17:46:33,087   INFO  cfg.Optim.train_max_action_len.EQA: 15
2026-01-05 17:46:33,087   INFO  cfg.Optim.train_max_action_len.R2R_AUG: 15
2026-01-05 17:46:33,087   INFO  cfg.Optim.train_max_action_len.REVERIE_AUG: 15
2026-01-05 17:46:35,961   INFO  [INFO] CVDNDataset loaded with 1384 instructions, using splits: test
2026-01-05 17:46:35,962   INFO  
- Dataset: load 1384 CVDN samples
- Dataset: load test split: 1384 samples in total
- Dataset: load test split: 16 scans in total
2026-01-05 17:46:35,962   INFO  CVDN: 1384 samples loaded
2026-01-05 17:46:36,093   INFO  Initialize the model from config.
2026-01-05 17:48:07,220   INFO  model type: torch.bfloat16
2026-01-05 17:48:07,223   INFO  Trainable params: lang_model.model.embed_tokens.weight,lang_model.model.layers.0.self_attn.q_proj.weight,lang_model.model.layers.0.self_attn.k_proj.weight,lang_model.model.layers.0.self_attn.v_proj.weight,lang_model.model.layers.0.self_attn.o_proj.weight,lang_model.model.layers.0.mlp.gate_proj.weight,lang_model.model.layers.0.mlp.down_proj.weight,lang_model.model.layers.0.mlp.up_proj.weight,lang_model.model.layers.0.input_layernorm.weight,lang_model.model.layers.0.post_attention_layernorm.weight,lang_model.model.layers.1.self_attn.q_proj.weight,lang_model.model.layers.1.self_attn.k_proj.weight,lang_model.model.layers.1.self_attn.v_proj.weight,lang_model.model.layers.1.self_attn.o_proj.weight,lang_model.model.layers.1.mlp.gate_proj.weight,lang_model.model.layers.1.mlp.down_proj.weight,lang_model.model.layers.1.mlp.up_proj.weight,lang_model.model.layers.1.input_layernorm.weight,lang_model.model.layers.1.post_attention_layernorm.weight,lang_model.model.layers.2.self_attn.q_proj.weight,lang_model.model.layers.2.self_attn.k_proj.weight,lang_model.model.layers.2.self_attn.v_proj.weight,lang_model.model.layers.2.self_attn.o_proj.weight,lang_model.model.layers.2.mlp.gate_proj.weight,lang_model.model.layers.2.mlp.down_proj.weight,lang_model.model.layers.2.mlp.up_proj.weight,lang_model.model.layers.2.input_layernorm.weight,lang_model.model.layers.2.post_attention_layernorm.weight,lang_model.model.layers.3.self_attn.q_proj.weight,lang_model.model.layers.3.self_attn.k_proj.weight,lang_model.model.layers.3.self_attn.v_proj.weight,lang_model.model.layers.3.self_attn.o_proj.weight,lang_model.model.layers.3.mlp.gate_proj.weight,lang_model.model.layers.3.mlp.down_proj.weight,lang_model.model.layers.3.mlp.up_proj.weight,lang_model.model.layers.3.input_layernorm.weight,lang_model.model.layers.3.post_attention_layernorm.weight,lang_model.model.layers.4.self_attn.q_proj.weight,lang_model.model.layers.4.self_attn.k_proj.weight,lang_model.model.layers.4.self_attn.v_proj.weight,lang_model.model.layers.4.self_attn.o_proj.weight,lang_model.model.layers.4.mlp.gate_proj.weight,lang_model.model.layers.4.mlp.down_proj.weight,lang_model.model.layers.4.mlp.up_proj.weight,lang_model.model.layers.4.input_layernorm.weight,lang_model.model.layers.4.post_attention_layernorm.weight,lang_model.model.layers.5.self_attn.q_proj.weight,lang_model.model.layers.5.self_attn.k_proj.weight,lang_model.model.layers.5.self_attn.v_proj.weight,lang_model.model.layers.5.self_attn.o_proj.weight,lang_model.model.layers.5.mlp.gate_proj.weight,lang_model.model.layers.5.mlp.down_proj.weight,lang_model.model.layers.5.mlp.up_proj.weight,lang_model.model.layers.5.input_layernorm.weight,lang_model.model.layers.5.post_attention_layernorm.weight,lang_model.model.layers.6.self_attn.q_proj.weight,lang_model.model.layers.6.self_attn.k_proj.weight,lang_model.model.layers.6.self_attn.v_proj.weight,lang_model.model.layers.6.self_attn.o_proj.weight,lang_model.model.layers.6.mlp.gate_proj.weight,lang_model.model.layers.6.mlp.down_proj.weight,lang_model.model.layers.6.mlp.up_proj.weight,lang_model.model.layers.6.input_layernorm.weight,lang_model.model.layers.6.post_attention_layernorm.weight,lang_model.model.layers.7.self_attn.q_proj.weight,lang_model.model.layers.7.self_attn.k_proj.weight,lang_model.model.layers.7.self_attn.v_proj.weight,lang_model.model.layers.7.self_attn.o_proj.weight,lang_model.model.layers.7.mlp.gate_proj.weight,lang_model.model.layers.7.mlp.down_proj.weight,lang_model.model.layers.7.mlp.up_proj.weight,lang_model.model.layers.7.input_layernorm.weight,lang_model.model.layers.7.post_attention_layernorm.weight,lang_model.model.layers.8.self_attn.q_proj.weight,lang_model.model.layers.8.self_attn.k_proj.weight,lang_model.model.layers.8.self_attn.v_proj.weight,lang_model.model.layers.8.self_attn.o_proj.weight,lang_model.model.layers.8.mlp.gate_proj.weight,lang_model.model.layers.8.mlp.down_proj.weight,lang_model.model.layers.8.mlp.up_proj.weight,lang_model.model.layers.8.input_layernorm.weight,lang_model.model.layers.8.post_attention_layernorm.weight,lang_model.model.layers.9.self_attn.q_proj.weight,lang_model.model.layers.9.self_attn.k_proj.weight,lang_model.model.layers.9.self_attn.v_proj.weight,lang_model.model.layers.9.self_attn.o_proj.weight,lang_model.model.layers.9.mlp.gate_proj.weight,lang_model.model.layers.9.mlp.down_proj.weight,lang_model.model.layers.9.mlp.up_proj.weight,lang_model.model.layers.9.input_layernorm.weight,lang_model.model.layers.9.post_attention_layernorm.weight,lang_model.model.layers.10.self_attn.q_proj.weight,lang_model.model.layers.10.self_attn.k_proj.weight,lang_model.model.layers.10.self_attn.v_proj.weight,lang_model.model.layers.10.self_attn.o_proj.weight,lang_model.model.layers.10.mlp.gate_proj.weight,lang_model.model.layers.10.mlp.down_proj.weight,lang_model.model.layers.10.mlp.up_proj.weight,lang_model.model.layers.10.input_layernorm.weight,lang_model.model.layers.10.post_attention_layernorm.weight,lang_model.model.layers.11.self_attn.q_proj.weight,lang_model.model.layers.11.self_attn.k_proj.weight,lang_model.model.layers.11.self_attn.v_proj.weight,lang_model.model.layers.11.self_attn.o_proj.weight,lang_model.model.layers.11.mlp.gate_proj.weight,lang_model.model.layers.11.mlp.down_proj.weight,lang_model.model.layers.11.mlp.up_proj.weight,lang_model.model.layers.11.input_layernorm.weight,lang_model.model.layers.11.post_attention_layernorm.weight,lang_model.model.layers.12.self_attn.q_proj.weight,lang_model.model.layers.12.self_attn.k_proj.weight,lang_model.model.layers.12.self_attn.v_proj.weight,lang_model.model.layers.12.self_attn.o_proj.weight,lang_model.model.layers.12.mlp.gate_proj.weight,lang_model.model.layers.12.mlp.down_proj.weight,lang_model.model.layers.12.mlp.up_proj.weight,lang_model.model.layers.12.input_layernorm.weight,lang_model.model.layers.12.post_attention_layernorm.weight,lang_model.model.layers.13.self_attn.q_proj.weight,lang_model.model.layers.13.self_attn.k_proj.weight,lang_model.model.layers.13.self_attn.v_proj.weight,lang_model.model.layers.13.self_attn.o_proj.weight,lang_model.model.layers.13.mlp.gate_proj.weight,lang_model.model.layers.13.mlp.down_proj.weight,lang_model.model.layers.13.mlp.up_proj.weight,lang_model.model.layers.13.input_layernorm.weight,lang_model.model.layers.13.post_attention_layernorm.weight,lang_model.model.layers.14.self_attn.q_proj.weight,lang_model.model.layers.14.self_attn.k_proj.weight,lang_model.model.layers.14.self_attn.v_proj.weight,lang_model.model.layers.14.self_attn.o_proj.weight,lang_model.model.layers.14.mlp.gate_proj.weight,lang_model.model.layers.14.mlp.down_proj.weight,lang_model.model.layers.14.mlp.up_proj.weight,lang_model.model.layers.14.input_layernorm.weight,lang_model.model.layers.14.post_attention_layernorm.weight,lang_model.model.layers.15.self_attn.q_proj.weight,lang_model.model.layers.15.self_attn.k_proj.weight,lang_model.model.layers.15.self_attn.v_proj.weight,lang_model.model.layers.15.self_attn.o_proj.weight,lang_model.model.layers.15.mlp.gate_proj.weight,lang_model.model.layers.15.mlp.down_proj.weight,lang_model.model.layers.15.mlp.up_proj.weight,lang_model.model.layers.15.input_layernorm.weight,lang_model.model.layers.15.post_attention_layernorm.weight,lang_model.model.layers.16.self_attn.q_proj.weight,lang_model.model.layers.16.self_attn.k_proj.weight,lang_model.model.layers.16.self_attn.v_proj.weight,lang_model.model.layers.16.self_attn.o_proj.weight,lang_model.model.layers.16.mlp.gate_proj.weight,lang_model.model.layers.16.mlp.down_proj.weight,lang_model.model.layers.16.mlp.up_proj.weight,lang_model.model.layers.16.input_layernorm.weight,lang_model.model.layers.16.post_attention_layernorm.weight,lang_model.model.layers.17.self_attn.q_proj.weight,lang_model.model.layers.17.self_attn.k_proj.weight,lang_model.model.layers.17.self_attn.v_proj.weight,lang_model.model.layers.17.self_attn.o_proj.weight,lang_model.model.layers.17.mlp.gate_proj.weight,lang_model.model.layers.17.mlp.down_proj.weight,lang_model.model.layers.17.mlp.up_proj.weight,lang_model.model.layers.17.input_layernorm.weight,lang_model.model.layers.17.post_attention_layernorm.weight,lang_model.model.layers.18.self_attn.q_proj.weight,lang_model.model.layers.18.self_attn.k_proj.weight,lang_model.model.layers.18.self_attn.v_proj.weight,lang_model.model.layers.18.self_attn.o_proj.weight,lang_model.model.layers.18.mlp.gate_proj.weight,lang_model.model.layers.18.mlp.down_proj.weight,lang_model.model.layers.18.mlp.up_proj.weight,lang_model.model.layers.18.input_layernorm.weight,lang_model.model.layers.18.post_attention_layernorm.weight,lang_model.model.layers.19.self_attn.q_proj.weight,lang_model.model.layers.19.self_attn.k_proj.weight,lang_model.model.layers.19.self_attn.v_proj.weight,lang_model.model.layers.19.self_attn.o_proj.weight,lang_model.model.layers.19.mlp.gate_proj.weight,lang_model.model.layers.19.mlp.down_proj.weight,lang_model.model.layers.19.mlp.up_proj.weight,lang_model.model.layers.19.input_layernorm.weight,lang_model.model.layers.19.post_attention_layernorm.weight,lang_model.model.layers.20.self_attn.q_proj.weight,lang_model.model.layers.20.self_attn.k_proj.weight,lang_model.model.layers.20.self_attn.v_proj.weight,lang_model.model.layers.20.self_attn.o_proj.weight,lang_model.model.layers.20.mlp.gate_proj.weight,lang_model.model.layers.20.mlp.down_proj.weight,lang_model.model.layers.20.mlp.up_proj.weight,lang_model.model.layers.20.input_layernorm.weight,lang_model.model.layers.20.post_attention_layernorm.weight,lang_model.model.layers.21.self_attn.q_proj.weight,lang_model.model.layers.21.self_attn.k_proj.weight,lang_model.model.layers.21.self_attn.v_proj.weight,lang_model.model.layers.21.self_attn.o_proj.weight,lang_model.model.layers.21.mlp.gate_proj.weight,lang_model.model.layers.21.mlp.down_proj.weight,lang_model.model.layers.21.mlp.up_proj.weight,lang_model.model.layers.21.input_layernorm.weight,lang_model.model.layers.21.post_attention_layernorm.weight,lang_model.model.layers.22.self_attn.q_proj.weight,lang_model.model.layers.22.self_attn.k_proj.weight,lang_model.model.layers.22.self_attn.v_proj.weight,lang_model.model.layers.22.self_attn.o_proj.weight,lang_model.model.layers.22.mlp.gate_proj.weight,lang_model.model.layers.22.mlp.down_proj.weight,lang_model.model.layers.22.mlp.up_proj.weight,lang_model.model.layers.22.input_layernorm.weight,lang_model.model.layers.22.post_attention_layernorm.weight,lang_model.model.layers.23.self_attn.q_proj.weight,lang_model.model.layers.23.self_attn.k_proj.weight,lang_model.model.layers.23.self_attn.v_proj.weight,lang_model.model.layers.23.self_attn.o_proj.weight,lang_model.model.layers.23.mlp.gate_proj.weight,lang_model.model.layers.23.mlp.down_proj.weight,lang_model.model.layers.23.mlp.up_proj.weight,lang_model.model.layers.23.input_layernorm.weight,lang_model.model.layers.23.post_attention_layernorm.weight,lang_model.model.layers.24.self_attn.q_proj.weight,lang_model.model.layers.24.self_attn.k_proj.weight,lang_model.model.layers.24.self_attn.v_proj.weight,lang_model.model.layers.24.self_attn.o_proj.weight,lang_model.model.layers.24.mlp.gate_proj.weight,lang_model.model.layers.24.mlp.down_proj.weight,lang_model.model.layers.24.mlp.up_proj.weight,lang_model.model.layers.24.input_layernorm.weight,lang_model.model.layers.24.post_attention_layernorm.weight,lang_model.model.layers.25.self_attn.q_proj.weight,lang_model.model.layers.25.self_attn.k_proj.weight,lang_model.model.layers.25.self_attn.v_proj.weight,lang_model.model.layers.25.self_attn.o_proj.weight,lang_model.model.layers.25.mlp.gate_proj.weight,lang_model.model.layers.25.mlp.down_proj.weight,lang_model.model.layers.25.mlp.up_proj.weight,lang_model.model.layers.25.input_layernorm.weight,lang_model.model.layers.25.post_attention_layernorm.weight,lang_model.model.layers.26.self_attn.q_proj.weight,lang_model.model.layers.26.self_attn.k_proj.weight,lang_model.model.layers.26.self_attn.v_proj.weight,lang_model.model.layers.26.self_attn.o_proj.weight,lang_model.model.layers.26.mlp.gate_proj.weight,lang_model.model.layers.26.mlp.down_proj.weight,lang_model.model.layers.26.mlp.up_proj.weight,lang_model.model.layers.26.input_layernorm.weight,lang_model.model.layers.26.post_attention_layernorm.weight,lang_model.model.layers.27.self_attn.q_proj.weight,lang_model.model.layers.27.self_attn.k_proj.weight,lang_model.model.layers.27.self_attn.v_proj.weight,lang_model.model.layers.27.self_attn.o_proj.weight,lang_model.model.layers.27.mlp.gate_proj.weight,lang_model.model.layers.27.mlp.down_proj.weight,lang_model.model.layers.27.mlp.up_proj.weight,lang_model.model.layers.27.input_layernorm.weight,lang_model.model.layers.27.post_attention_layernorm.weight,lang_model.model.layers.28.self_attn.q_proj.weight,lang_model.model.layers.28.self_attn.k_proj.weight,lang_model.model.layers.28.self_attn.v_proj.weight,lang_model.model.layers.28.self_attn.o_proj.weight,lang_model.model.layers.28.mlp.gate_proj.weight,lang_model.model.layers.28.mlp.down_proj.weight,lang_model.model.layers.28.mlp.up_proj.weight,lang_model.model.layers.28.input_layernorm.weight,lang_model.model.layers.28.post_attention_layernorm.weight,lang_model.model.layers.29.self_attn.q_proj.weight,lang_model.model.layers.29.self_attn.k_proj.weight,lang_model.model.layers.29.self_attn.v_proj.weight,lang_model.model.layers.29.self_attn.o_proj.weight,lang_model.model.layers.29.mlp.gate_proj.weight,lang_model.model.layers.29.mlp.down_proj.weight,lang_model.model.layers.29.mlp.up_proj.weight,lang_model.model.layers.29.input_layernorm.weight,lang_model.model.layers.29.post_attention_layernorm.weight,lang_model.model.layers.30.self_attn.q_proj.weight,lang_model.model.layers.30.self_attn.k_proj.weight,lang_model.model.layers.30.self_attn.v_proj.weight,lang_model.model.layers.30.self_attn.o_proj.weight,lang_model.model.layers.30.mlp.gate_proj.weight,lang_model.model.layers.30.mlp.down_proj.weight,lang_model.model.layers.30.mlp.up_proj.weight,lang_model.model.layers.30.input_layernorm.weight,lang_model.model.layers.30.post_attention_layernorm.weight,lang_model.model.layers.31.self_attn.q_proj.weight,lang_model.model.layers.31.self_attn.k_proj.weight,lang_model.model.layers.31.self_attn.v_proj.weight,lang_model.model.layers.31.self_attn.o_proj.weight,lang_model.model.layers.31.mlp.gate_proj.weight,lang_model.model.layers.31.mlp.down_proj.weight,lang_model.model.layers.31.mlp.up_proj.weight,lang_model.model.layers.31.input_layernorm.weight,lang_model.model.layers.31.post_attention_layernorm.weight,lang_model.model.norm.weight,lang_model.lm_head.weight,img_embeddings.img_linear.weight,img_embeddings.img_linear.bias,img_embeddings.img_layer_norm.weight,img_embeddings.img_layer_norm.bias,img_embeddings.loc_linear.weight,img_embeddings.loc_linear.bias,img_embeddings.loc_layer_norm.weight,img_embeddings.loc_layer_norm.bias,img_embeddings.nav_type_embedding.weight,img_embeddings.layer_norm.weight,img_embeddings.layer_norm.bias,img_embeddings.pano_encoder.layers.0.self_attn.in_proj_weight,img_embeddings.pano_encoder.layers.0.self_attn.in_proj_bias,img_embeddings.pano_encoder.layers.0.self_attn.out_proj.weight,img_embeddings.pano_encoder.layers.0.self_attn.out_proj.bias,img_embeddings.pano_encoder.layers.0.linear1.weight,img_embeddings.pano_encoder.layers.0.linear1.bias,img_embeddings.pano_encoder.layers.0.linear2.weight,img_embeddings.pano_encoder.layers.0.linear2.bias,img_embeddings.pano_encoder.layers.0.norm1.weight,img_embeddings.pano_encoder.layers.0.norm1.bias,img_embeddings.pano_encoder.layers.0.norm2.weight,img_embeddings.pano_encoder.layers.0.norm2.bias,img_embeddings.pano_encoder.layers.1.self_attn.in_proj_weight,img_embeddings.pano_encoder.layers.1.self_attn.in_proj_bias,img_embeddings.pano_encoder.layers.1.self_attn.out_proj.weight,img_embeddings.pano_encoder.layers.1.self_attn.out_proj.bias,img_embeddings.pano_encoder.layers.1.linear1.weight,img_embeddings.pano_encoder.layers.1.linear1.bias,img_embeddings.pano_encoder.layers.1.linear2.weight,img_embeddings.pano_encoder.layers.1.linear2.bias,img_embeddings.pano_encoder.layers.1.norm1.weight,img_embeddings.pano_encoder.layers.1.norm1.bias,img_embeddings.pano_encoder.layers.1.norm2.weight,img_embeddings.pano_encoder.layers.1.norm2.bias,img_embeddings.pano_encoder.norm.weight,img_embeddings.pano_encoder.norm.bias,img_embeddings.mapper.weight,img_embeddings.mapper.bias,token_type_embeddings.weight,gmap_pos_embeddings.0.weight,gmap_pos_embeddings.0.bias,gmap_pos_embeddings.1.weight,gmap_pos_embeddings.1.bias,gmap_step_embeddings.weight,vp_pos_embeddings.0.weight,vp_pos_embeddings.0.bias,vp_pos_embeddings.1.weight,vp_pos_embeddings.1.bias,obj_pos_embeddings.0.weight,obj_pos_embeddings.0.bias,obj_pos_embeddings.1.weight,obj_pos_embeddings.1.bias,og_head.0.weight,og_head.0.bias,out_head.0.weight,out_head.0.bias
2026-01-05 17:48:07,223   INFO  *************** init model *************** 
2026-01-05 17:48:11,677   INFO  Loading checkpoint from /data/wanghaoxuan/model_with_pretrain.pt
2026-01-05 17:48:17,044   INFO  Ignore weight img_embeddings.obj_projector.0.weight: torch.Size([4096, 768])
2026-01-05 17:48:17,045   INFO  Ignore weight img_embeddings.obj_projector.0.bias: torch.Size([4096])
2026-01-05 17:48:17,045   INFO  Ignore weight img_embeddings.obj_projector.1.weight: torch.Size([4096])
2026-01-05 17:48:17,045   INFO  Ignore weight img_embeddings.obj_projector.1.bias: torch.Size([4096])
2026-01-05 17:48:18,254   INFO  <All keys matched successfully>
2026-01-05 17:48:18,607   INFO  model initialized with 6770.32 M trainable parameters
2026-01-05 17:48:18,608   INFO  Training with a single process
2026-01-05 17:48:18,608   INFO  **************************** Test ****************************
2026-01-05 17:48:18,611   INFO  ***** validate test split on CVDN task *****
2026-01-05 18:31:41,236   INFO  eval 1384 predictions
2026-01-05 18:43:48,996   INFO  **********************Start logging**********************
2026-01-05 18:43:48,997   INFO  CUDA_VISIBLE_DEVICES=0
2026-01-05 18:43:48,997   INFO  data_dir         /data/wanghaoxuan/data
2026-01-05 18:43:48,997   INFO  cfg_file         configs/multi.yaml
2026-01-05 18:43:48,997   INFO  pretrained_model_name_or_path /data/wanghaoxuan/data/models/Vicuna-7B
2026-01-05 18:43:48,997   INFO  off_batch_task   False
2026-01-05 18:43:48,997   INFO  debug            False
2026-01-05 18:43:48,997   INFO  few_shot         None
2026-01-05 18:43:48,997   INFO  tour3d_nav_head  False
2026-01-05 18:43:48,997   INFO  seed             0
2026-01-05 18:43:48,997   INFO  num_epochs       30
2026-01-05 18:43:48,997   INFO  resume_from_checkpoint /data/wanghaoxuan/model_with_pretrain.pt
2026-01-05 18:43:48,997   INFO  from_scratch     False
2026-01-05 18:43:48,997   INFO  batch_size       4
2026-01-05 18:43:48,997   INFO  val_batch_size   2
2026-01-05 18:43:48,998   INFO  lr               1e-05
2026-01-05 18:43:48,998   INFO  feat_dropout     0.4
2026-01-05 18:43:48,998   INFO  num_warmup_steps 0
2026-01-05 18:43:48,998   INFO  num_steps_per_epoch -1
2026-01-05 18:43:48,998   INFO  gradient_accumulation_step 2
2026-01-05 18:43:48,998   INFO  precision        amp_bf16
2026-01-05 18:43:48,998   INFO  workers          0
2026-01-05 18:43:48,998   INFO  gpu              0
2026-01-05 18:43:48,998   INFO  world_size       1
2026-01-05 18:43:48,998   INFO  local_rank       0
2026-01-05 18:43:48,998   INFO  dist_url         env://
2026-01-05 18:43:48,998   INFO  dist_backend     nccl
2026-01-05 18:43:48,998   INFO  horovod          False
2026-01-05 18:43:48,998   INFO  no_set_device_rank False
2026-01-05 18:43:48,998   INFO  output_dir       build/eval
2026-01-05 18:43:48,998   INFO  max_saved_checkpoints 0
2026-01-05 18:43:48,998   INFO  save_ckpt_per_epochs 10
2026-01-05 18:43:48,998   INFO  save_latest_states False
2026-01-05 18:43:48,998   INFO  save_pred_results False
2026-01-05 18:43:48,998   INFO  save_detail_results False
2026-01-05 18:43:48,999   INFO  mode             test
2026-01-05 18:43:48,999   INFO  stage            multi
2026-01-05 18:43:48,999   INFO  ignoreid         -100
2026-01-05 18:43:48,999   INFO  enable_og        False
2026-01-05 18:43:48,999   INFO  enable_summarize False
2026-01-05 18:43:48,999   INFO  enable_fgr2r     False
2026-01-05 18:43:48,999   INFO  disable_nav      False
2026-01-05 18:43:48,999   INFO  gen_loss_coef    1.0
2026-01-05 18:43:48,999   INFO  obj_loss_coef    1.0
2026-01-05 18:43:48,999   INFO  teacher_forcing_coef 1.0
2026-01-05 18:43:48,999   INFO  fuse_obj         False
2026-01-05 18:43:48,999   INFO  use_lora         False
2026-01-05 18:43:48,999   INFO  lora_rank        8
2026-01-05 18:43:48,999   INFO  lora_alpha       16
2026-01-05 18:43:48,999   INFO  lora_dropout     0.05
2026-01-05 18:43:48,999   INFO  lora_target      None
2026-01-05 18:43:48,999   INFO  freeze_llama     False
2026-01-05 18:43:48,999   INFO  tune_token_emb   False
2026-01-05 18:43:48,999   INFO  no_loc_fts       False
2026-01-05 18:43:49,000   INFO  multi_endpoints  1
2026-01-05 18:43:49,000   INFO  path_type        trusted_path
2026-01-05 18:43:49,000   INFO  test_datasets    ['R2R']
2026-01-05 18:43:49,000   INFO  validation_split val_unseen
2026-01-05 18:43:49,000   INFO  do_sample        False
2026-01-05 18:43:49,000   INFO  temperature      1.0
2026-01-05 18:43:49,000   INFO  max_datapoints   None
2026-01-05 18:43:49,000   INFO  rank             0
2026-01-05 18:43:49,000   INFO  distributed      False
2026-01-05 18:43:49,000   INFO  device           cuda:0
2026-01-05 18:43:49,000   INFO  image_feat_size  1024
2026-01-05 18:43:49,000   INFO  obj_feat_size    768
2026-01-05 18:43:49,000   INFO  angle_feat_size  4
2026-01-05 18:43:49,000   INFO  enc_full_graph   True
2026-01-05 18:43:49,000   INFO  expert_policy    spl
2026-01-05 18:43:49,000   INFO  num_pano_layers  2
2026-01-05 18:43:49,000   INFO  ----------- Feature -----------
2026-01-05 18:43:49,000   INFO  cfg.Feature.object_feature_type: 
2026-01-05 18:43:49,000   INFO  cfg.Feature.angle_feat_size: 4
2026-01-05 18:43:49,001   INFO  cfg.Feature.max_objects: 70
2026-01-05 18:43:49,001   INFO  cfg.Feature.image_feat_size: 1024
2026-01-05 18:43:49,001   INFO  ----------- feature_database -----------
2026-01-05 18:43:49,001   INFO  cfg.Feature.feature_database.mp3d: eva_features/mp3d_EVA02-CLIP-L-14-336.hdf5
2026-01-05 18:43:49,001   INFO  cfg.Feature.feature_database.scan_qa: eva_features/scanqa_EVA02-CLIP-L-14-336.hdf5
2026-01-05 18:43:49,001   INFO  cfg.Feature.feature_database.room_tour: eva_features/web_obj_prog_p1_EVA02-CLIP-L-14-336.hdf5.bak
2026-01-05 18:43:49,001   INFO  cfg.Feature.feature_database.room3d_tour: eva_features/web_3d_obj_prog_crop_p1_EVA02-CLIP-L-14-336.hdf5
2026-01-05 18:43:49,001   INFO  cfg.Feature.feature_database.coco: eva_features/coco_EVA02-CLIP-L-14-336.hdf5
2026-01-05 18:43:49,001   INFO  cfg.Feature.obj_feat_size: 768
2026-01-05 18:43:49,001   INFO  ----------- object_database -----------
2026-01-05 18:43:49,001   INFO  cfg.Feature.object_database.reverie: obj_features/reverie_obj_feat
2026-01-05 18:43:49,001   INFO  cfg.Feature.object_database.soon: obj_features/soon_obj_feat
2026-01-05 18:43:49,001   INFO  ----------- Dataset -----------
2026-01-05 18:43:49,001   INFO  ----------- R2R -----------
2026-01-05 18:43:49,001   INFO  cfg.Dataset.R2R.DIR: R2R
2026-01-05 18:43:49,001   INFO  ----------- SPLIT -----------
2026-01-05 18:43:49,001   INFO  cfg.Dataset.R2R.SPLIT.train: FGR2R_train.json
2026-01-05 18:43:49,001   INFO  cfg.Dataset.R2R.SPLIT.val_seen: R2R_val_seen_enc.json
2026-01-05 18:43:49,001   INFO  cfg.Dataset.R2R.SPLIT.val_unseen: R2R_val_unseen_enc.json
2026-01-05 18:43:49,002   INFO  cfg.Dataset.R2R.SPLIT.test: R2R_test_enc.json
2026-01-05 18:43:49,002   INFO  ----------- REVERIE -----------
2026-01-05 18:43:49,002   INFO  cfg.Dataset.REVERIE.DIR: REVERIE
2026-01-05 18:43:49,002   INFO  cfg.Dataset.REVERIE.bbox_file: BBoxes.json
2026-01-05 18:43:49,002   INFO  ----------- SPLIT -----------
2026-01-05 18:43:49,002   INFO  cfg.Dataset.REVERIE.SPLIT.train: REVERIE_train_enc.json
2026-01-05 18:43:49,002   INFO  cfg.Dataset.REVERIE.SPLIT.val_seen: REVERIE_val_seen_enc.json
2026-01-05 18:43:49,002   INFO  cfg.Dataset.REVERIE.SPLIT.val_unseen: REVERIE_val_unseen_enc.json
2026-01-05 18:43:49,002   INFO  cfg.Dataset.REVERIE.SPLIT.test: REVERIE_test_enc.json
2026-01-05 18:43:49,002   INFO  ----------- CVDN -----------
2026-01-05 18:43:49,002   INFO  cfg.Dataset.CVDN.DIR: CVDN
2026-01-05 18:43:49,002   INFO  ----------- SPLIT -----------
2026-01-05 18:43:49,002   INFO  cfg.Dataset.CVDN.SPLIT.train: train.json
2026-01-05 18:43:49,002   INFO  cfg.Dataset.CVDN.SPLIT.val_seen: val_seen.json
2026-01-05 18:43:49,002   INFO  cfg.Dataset.CVDN.SPLIT.val_unseen: val_unseen.json
2026-01-05 18:43:49,002   INFO  cfg.Dataset.CVDN.SPLIT.test: test_cleaned.json
2026-01-05 18:43:49,002   INFO  ----------- SOON -----------
2026-01-05 18:43:49,002   INFO  cfg.Dataset.SOON.DIR: SOON
2026-01-05 18:43:49,002   INFO  ----------- SPLIT -----------
2026-01-05 18:43:49,002   INFO  cfg.Dataset.SOON.SPLIT.train: train_enc_pseudo_obj_ade30k_label.jsonl
2026-01-05 18:43:49,003   INFO  cfg.Dataset.SOON.SPLIT.val_seen: val_unseen_instrs_enc_pseudo_obj_ade30k_label.jsonl
2026-01-05 18:43:49,003   INFO  cfg.Dataset.SOON.SPLIT.val_unseen: val_unseen_house_enc_pseudo_obj_ade30k_label.jsonl
2026-01-05 18:43:49,003   INFO  cfg.Dataset.SOON.SPLIT.test: test_v2_enc.jsonl
2026-01-05 18:43:49,003   INFO  ----------- ScanQA -----------
2026-01-05 18:43:49,003   INFO  cfg.Dataset.ScanQA.DIR: ScanQA
2026-01-05 18:43:49,003   INFO  ----------- SPLIT -----------
2026-01-05 18:43:49,003   INFO  cfg.Dataset.ScanQA.SPLIT.train: ScanQA_v1.0_train_reformat.json
2026-01-05 18:43:49,003   INFO  cfg.Dataset.ScanQA.SPLIT.val_unseen: ScanQA_v1.0_val_reformat.json
2026-01-05 18:43:49,003   INFO  cfg.Dataset.ScanQA.SPLIT.test_wo_obj: ScanQA_v1.0_test_wo_obj_reformat.json
2026-01-05 18:43:49,003   INFO  cfg.Dataset.ScanQA.SPLIT.test_w_obj: ScanQA_v1.0_test_w_obj_reformat.json
2026-01-05 18:43:49,003   INFO  ----------- RoomTour -----------
2026-01-05 18:43:49,003   INFO  cfg.Dataset.RoomTour.DIR: RoomTour
2026-01-05 18:43:49,003   INFO  ----------- SPLIT -----------
2026-01-05 18:43:49,003   INFO  cfg.Dataset.RoomTour.SPLIT.train: p1_train_reformat.json
2026-01-05 18:43:49,003   INFO  ----------- Tour3D -----------
2026-01-05 18:43:49,003   INFO  cfg.Dataset.Tour3D.DIR: RoomTour
2026-01-05 18:43:49,003   INFO  ----------- SPLIT -----------
2026-01-05 18:43:49,003   INFO  cfg.Dataset.Tour3D.SPLIT.train: p1_train_colmap_trajectory_tour3d.json
2026-01-05 18:43:49,003   INFO  ----------- EQA -----------
2026-01-05 18:43:49,004   INFO  cfg.Dataset.EQA.DIR: EQA_MP3D
2026-01-05 18:43:49,004   INFO  ----------- SPLIT -----------
2026-01-05 18:43:49,004   INFO  cfg.Dataset.EQA.SPLIT.val_unseen: eqa_val_enc.json
2026-01-05 18:43:49,004   INFO  cfg.Dataset.EQA.ANSWER_VOCAB: eqa_answer_vocab.json
2026-01-05 18:43:49,004   INFO  ----------- R2R_AUG -----------
2026-01-05 18:43:49,004   INFO  cfg.Dataset.R2R_AUG.DIR: R2R
2026-01-05 18:43:49,004   INFO  ----------- SPLIT -----------
2026-01-05 18:43:49,004   INFO  cfg.Dataset.R2R_AUG.SPLIT.train: R2R_prevalent_aug_train_enc.jsonl
2026-01-05 18:43:49,004   INFO  ----------- REVERIE_AUG -----------
2026-01-05 18:43:49,004   INFO  cfg.Dataset.REVERIE_AUG.DIR: REVERIE
2026-01-05 18:43:49,004   INFO  cfg.Dataset.REVERIE_AUG.bbox_file: BBoxes.json
2026-01-05 18:43:49,004   INFO  ----------- SPLIT -----------
2026-01-05 18:43:49,004   INFO  cfg.Dataset.REVERIE_AUG.SPLIT.train: REVERIE_speaker_aug_enc.jsonl
2026-01-05 18:43:49,004   INFO  ----------- LLaVA -----------
2026-01-05 18:43:49,004   INFO  cfg.Dataset.LLaVA.DIR: LLaVA
2026-01-05 18:43:49,004   INFO  ----------- SPLIT -----------
2026-01-05 18:43:49,004   INFO  cfg.Dataset.LLaVA.SPLIT.train: detail_23k.json
2026-01-05 18:43:49,004   INFO  ----------- Pretrain -----------
2026-01-05 18:43:49,004   INFO  cfg.Pretrain.SOURCE: ['Tour3D', 'RoomTour', 'ScanQA', 'LLaVA']
2026-01-05 18:43:49,004   INFO  cfg.Pretrain.Ratio: [10, 20, 5, 2]
2026-01-05 18:43:49,005   INFO  ----------- LOSS_COEF -----------
2026-01-05 18:43:49,005   INFO  cfg.Pretrain.LOSS_COEF.R2R_AUG: 1
2026-01-05 18:43:49,005   INFO  cfg.Pretrain.LOSS_COEF.REVERIE_AUG: 1
2026-01-05 18:43:49,005   INFO  ----------- Multi -----------
2026-01-05 18:43:49,005   INFO  cfg.Multi.SOURCE: ['Tour3D', 'R2R', 'REVERIE', 'CVDN', 'SOON', 'ScanQA', 'LLaVA']
2026-01-05 18:43:49,005   INFO  cfg.Multi.Ratio: [10, 20, 5, 1, 5, 5, 5]
2026-01-05 18:43:49,005   INFO  ----------- LOSS_COEF -----------
2026-01-05 18:43:49,005   INFO  ----------- Model -----------
2026-01-05 18:43:49,005   INFO  cfg.Model.num_l_layers: 9
2026-01-05 18:43:49,005   INFO  cfg.Model.num_pano_layers: 2
2026-01-05 18:43:49,005   INFO  cfg.Model.num_x_layers: 4
2026-01-05 18:43:49,005   INFO  cfg.Model.graph_sprels: True
2026-01-05 18:43:49,005   INFO  cfg.Model.fusion: dynamic
2026-01-05 18:43:49,005   INFO  cfg.Model.enc_full_graph: True
2026-01-05 18:43:49,005   INFO  cfg.Model.expert_policy: spl
2026-01-05 18:43:49,005   INFO  ----------- Optim -----------
2026-01-05 18:43:49,005   INFO  ----------- val_max_action_len -----------
2026-01-05 18:43:49,005   INFO  cfg.Optim.val_max_action_len.R2R: 15
2026-01-05 18:43:49,005   INFO  cfg.Optim.val_max_action_len.REVERIE: 15
2026-01-05 18:43:49,006   INFO  cfg.Optim.val_max_action_len.CVDN: 30
2026-01-05 18:43:49,006   INFO  cfg.Optim.val_max_action_len.SOON: 20
2026-01-05 18:43:49,006   INFO  cfg.Optim.val_max_action_len.EQA: 15
2026-01-05 18:43:49,006   INFO  ----------- train_max_action_len -----------
2026-01-05 18:43:49,006   INFO  cfg.Optim.train_max_action_len.R2R: 15
2026-01-05 18:43:49,006   INFO  cfg.Optim.train_max_action_len.Tour3D: 15
2026-01-05 18:43:49,006   INFO  cfg.Optim.train_max_action_len.REVERIE: 15
2026-01-05 18:43:49,006   INFO  cfg.Optim.train_max_action_len.CVDN: 15
2026-01-05 18:43:49,006   INFO  cfg.Optim.train_max_action_len.SOON: 15
2026-01-05 18:43:49,006   INFO  cfg.Optim.train_max_action_len.EQA: 15
2026-01-05 18:43:49,006   INFO  cfg.Optim.train_max_action_len.R2R_AUG: 15
2026-01-05 18:43:49,006   INFO  cfg.Optim.train_max_action_len.REVERIE_AUG: 15
2026-01-05 18:43:51,270   INFO  [INFO] R2RDataset loaded with 2349 instructions, using splits: val_unseen
2026-01-05 18:43:51,271   INFO  
- Dataset: load 2349 R2R samples
- Dataset: load val_unseen split: 2349 samples in total
- Dataset: load val_unseen split: 11 scans in total
2026-01-05 18:43:51,271   INFO  R2R: 2349 samples loaded
2026-01-05 18:43:51,345   INFO  Initialize the model from config.
2026-01-05 18:45:21,294   INFO  model type: torch.bfloat16
2026-01-05 18:45:21,297   INFO  Trainable params: lang_model.model.embed_tokens.weight,lang_model.model.layers.0.self_attn.q_proj.weight,lang_model.model.layers.0.self_attn.k_proj.weight,lang_model.model.layers.0.self_attn.v_proj.weight,lang_model.model.layers.0.self_attn.o_proj.weight,lang_model.model.layers.0.mlp.gate_proj.weight,lang_model.model.layers.0.mlp.down_proj.weight,lang_model.model.layers.0.mlp.up_proj.weight,lang_model.model.layers.0.input_layernorm.weight,lang_model.model.layers.0.post_attention_layernorm.weight,lang_model.model.layers.1.self_attn.q_proj.weight,lang_model.model.layers.1.self_attn.k_proj.weight,lang_model.model.layers.1.self_attn.v_proj.weight,lang_model.model.layers.1.self_attn.o_proj.weight,lang_model.model.layers.1.mlp.gate_proj.weight,lang_model.model.layers.1.mlp.down_proj.weight,lang_model.model.layers.1.mlp.up_proj.weight,lang_model.model.layers.1.input_layernorm.weight,lang_model.model.layers.1.post_attention_layernorm.weight,lang_model.model.layers.2.self_attn.q_proj.weight,lang_model.model.layers.2.self_attn.k_proj.weight,lang_model.model.layers.2.self_attn.v_proj.weight,lang_model.model.layers.2.self_attn.o_proj.weight,lang_model.model.layers.2.mlp.gate_proj.weight,lang_model.model.layers.2.mlp.down_proj.weight,lang_model.model.layers.2.mlp.up_proj.weight,lang_model.model.layers.2.input_layernorm.weight,lang_model.model.layers.2.post_attention_layernorm.weight,lang_model.model.layers.3.self_attn.q_proj.weight,lang_model.model.layers.3.self_attn.k_proj.weight,lang_model.model.layers.3.self_attn.v_proj.weight,lang_model.model.layers.3.self_attn.o_proj.weight,lang_model.model.layers.3.mlp.gate_proj.weight,lang_model.model.layers.3.mlp.down_proj.weight,lang_model.model.layers.3.mlp.up_proj.weight,lang_model.model.layers.3.input_layernorm.weight,lang_model.model.layers.3.post_attention_layernorm.weight,lang_model.model.layers.4.self_attn.q_proj.weight,lang_model.model.layers.4.self_attn.k_proj.weight,lang_model.model.layers.4.self_attn.v_proj.weight,lang_model.model.layers.4.self_attn.o_proj.weight,lang_model.model.layers.4.mlp.gate_proj.weight,lang_model.model.layers.4.mlp.down_proj.weight,lang_model.model.layers.4.mlp.up_proj.weight,lang_model.model.layers.4.input_layernorm.weight,lang_model.model.layers.4.post_attention_layernorm.weight,lang_model.model.layers.5.self_attn.q_proj.weight,lang_model.model.layers.5.self_attn.k_proj.weight,lang_model.model.layers.5.self_attn.v_proj.weight,lang_model.model.layers.5.self_attn.o_proj.weight,lang_model.model.layers.5.mlp.gate_proj.weight,lang_model.model.layers.5.mlp.down_proj.weight,lang_model.model.layers.5.mlp.up_proj.weight,lang_model.model.layers.5.input_layernorm.weight,lang_model.model.layers.5.post_attention_layernorm.weight,lang_model.model.layers.6.self_attn.q_proj.weight,lang_model.model.layers.6.self_attn.k_proj.weight,lang_model.model.layers.6.self_attn.v_proj.weight,lang_model.model.layers.6.self_attn.o_proj.weight,lang_model.model.layers.6.mlp.gate_proj.weight,lang_model.model.layers.6.mlp.down_proj.weight,lang_model.model.layers.6.mlp.up_proj.weight,lang_model.model.layers.6.input_layernorm.weight,lang_model.model.layers.6.post_attention_layernorm.weight,lang_model.model.layers.7.self_attn.q_proj.weight,lang_model.model.layers.7.self_attn.k_proj.weight,lang_model.model.layers.7.self_attn.v_proj.weight,lang_model.model.layers.7.self_attn.o_proj.weight,lang_model.model.layers.7.mlp.gate_proj.weight,lang_model.model.layers.7.mlp.down_proj.weight,lang_model.model.layers.7.mlp.up_proj.weight,lang_model.model.layers.7.input_layernorm.weight,lang_model.model.layers.7.post_attention_layernorm.weight,lang_model.model.layers.8.self_attn.q_proj.weight,lang_model.model.layers.8.self_attn.k_proj.weight,lang_model.model.layers.8.self_attn.v_proj.weight,lang_model.model.layers.8.self_attn.o_proj.weight,lang_model.model.layers.8.mlp.gate_proj.weight,lang_model.model.layers.8.mlp.down_proj.weight,lang_model.model.layers.8.mlp.up_proj.weight,lang_model.model.layers.8.input_layernorm.weight,lang_model.model.layers.8.post_attention_layernorm.weight,lang_model.model.layers.9.self_attn.q_proj.weight,lang_model.model.layers.9.self_attn.k_proj.weight,lang_model.model.layers.9.self_attn.v_proj.weight,lang_model.model.layers.9.self_attn.o_proj.weight,lang_model.model.layers.9.mlp.gate_proj.weight,lang_model.model.layers.9.mlp.down_proj.weight,lang_model.model.layers.9.mlp.up_proj.weight,lang_model.model.layers.9.input_layernorm.weight,lang_model.model.layers.9.post_attention_layernorm.weight,lang_model.model.layers.10.self_attn.q_proj.weight,lang_model.model.layers.10.self_attn.k_proj.weight,lang_model.model.layers.10.self_attn.v_proj.weight,lang_model.model.layers.10.self_attn.o_proj.weight,lang_model.model.layers.10.mlp.gate_proj.weight,lang_model.model.layers.10.mlp.down_proj.weight,lang_model.model.layers.10.mlp.up_proj.weight,lang_model.model.layers.10.input_layernorm.weight,lang_model.model.layers.10.post_attention_layernorm.weight,lang_model.model.layers.11.self_attn.q_proj.weight,lang_model.model.layers.11.self_attn.k_proj.weight,lang_model.model.layers.11.self_attn.v_proj.weight,lang_model.model.layers.11.self_attn.o_proj.weight,lang_model.model.layers.11.mlp.gate_proj.weight,lang_model.model.layers.11.mlp.down_proj.weight,lang_model.model.layers.11.mlp.up_proj.weight,lang_model.model.layers.11.input_layernorm.weight,lang_model.model.layers.11.post_attention_layernorm.weight,lang_model.model.layers.12.self_attn.q_proj.weight,lang_model.model.layers.12.self_attn.k_proj.weight,lang_model.model.layers.12.self_attn.v_proj.weight,lang_model.model.layers.12.self_attn.o_proj.weight,lang_model.model.layers.12.mlp.gate_proj.weight,lang_model.model.layers.12.mlp.down_proj.weight,lang_model.model.layers.12.mlp.up_proj.weight,lang_model.model.layers.12.input_layernorm.weight,lang_model.model.layers.12.post_attention_layernorm.weight,lang_model.model.layers.13.self_attn.q_proj.weight,lang_model.model.layers.13.self_attn.k_proj.weight,lang_model.model.layers.13.self_attn.v_proj.weight,lang_model.model.layers.13.self_attn.o_proj.weight,lang_model.model.layers.13.mlp.gate_proj.weight,lang_model.model.layers.13.mlp.down_proj.weight,lang_model.model.layers.13.mlp.up_proj.weight,lang_model.model.layers.13.input_layernorm.weight,lang_model.model.layers.13.post_attention_layernorm.weight,lang_model.model.layers.14.self_attn.q_proj.weight,lang_model.model.layers.14.self_attn.k_proj.weight,lang_model.model.layers.14.self_attn.v_proj.weight,lang_model.model.layers.14.self_attn.o_proj.weight,lang_model.model.layers.14.mlp.gate_proj.weight,lang_model.model.layers.14.mlp.down_proj.weight,lang_model.model.layers.14.mlp.up_proj.weight,lang_model.model.layers.14.input_layernorm.weight,lang_model.model.layers.14.post_attention_layernorm.weight,lang_model.model.layers.15.self_attn.q_proj.weight,lang_model.model.layers.15.self_attn.k_proj.weight,lang_model.model.layers.15.self_attn.v_proj.weight,lang_model.model.layers.15.self_attn.o_proj.weight,lang_model.model.layers.15.mlp.gate_proj.weight,lang_model.model.layers.15.mlp.down_proj.weight,lang_model.model.layers.15.mlp.up_proj.weight,lang_model.model.layers.15.input_layernorm.weight,lang_model.model.layers.15.post_attention_layernorm.weight,lang_model.model.layers.16.self_attn.q_proj.weight,lang_model.model.layers.16.self_attn.k_proj.weight,lang_model.model.layers.16.self_attn.v_proj.weight,lang_model.model.layers.16.self_attn.o_proj.weight,lang_model.model.layers.16.mlp.gate_proj.weight,lang_model.model.layers.16.mlp.down_proj.weight,lang_model.model.layers.16.mlp.up_proj.weight,lang_model.model.layers.16.input_layernorm.weight,lang_model.model.layers.16.post_attention_layernorm.weight,lang_model.model.layers.17.self_attn.q_proj.weight,lang_model.model.layers.17.self_attn.k_proj.weight,lang_model.model.layers.17.self_attn.v_proj.weight,lang_model.model.layers.17.self_attn.o_proj.weight,lang_model.model.layers.17.mlp.gate_proj.weight,lang_model.model.layers.17.mlp.down_proj.weight,lang_model.model.layers.17.mlp.up_proj.weight,lang_model.model.layers.17.input_layernorm.weight,lang_model.model.layers.17.post_attention_layernorm.weight,lang_model.model.layers.18.self_attn.q_proj.weight,lang_model.model.layers.18.self_attn.k_proj.weight,lang_model.model.layers.18.self_attn.v_proj.weight,lang_model.model.layers.18.self_attn.o_proj.weight,lang_model.model.layers.18.mlp.gate_proj.weight,lang_model.model.layers.18.mlp.down_proj.weight,lang_model.model.layers.18.mlp.up_proj.weight,lang_model.model.layers.18.input_layernorm.weight,lang_model.model.layers.18.post_attention_layernorm.weight,lang_model.model.layers.19.self_attn.q_proj.weight,lang_model.model.layers.19.self_attn.k_proj.weight,lang_model.model.layers.19.self_attn.v_proj.weight,lang_model.model.layers.19.self_attn.o_proj.weight,lang_model.model.layers.19.mlp.gate_proj.weight,lang_model.model.layers.19.mlp.down_proj.weight,lang_model.model.layers.19.mlp.up_proj.weight,lang_model.model.layers.19.input_layernorm.weight,lang_model.model.layers.19.post_attention_layernorm.weight,lang_model.model.layers.20.self_attn.q_proj.weight,lang_model.model.layers.20.self_attn.k_proj.weight,lang_model.model.layers.20.self_attn.v_proj.weight,lang_model.model.layers.20.self_attn.o_proj.weight,lang_model.model.layers.20.mlp.gate_proj.weight,lang_model.model.layers.20.mlp.down_proj.weight,lang_model.model.layers.20.mlp.up_proj.weight,lang_model.model.layers.20.input_layernorm.weight,lang_model.model.layers.20.post_attention_layernorm.weight,lang_model.model.layers.21.self_attn.q_proj.weight,lang_model.model.layers.21.self_attn.k_proj.weight,lang_model.model.layers.21.self_attn.v_proj.weight,lang_model.model.layers.21.self_attn.o_proj.weight,lang_model.model.layers.21.mlp.gate_proj.weight,lang_model.model.layers.21.mlp.down_proj.weight,lang_model.model.layers.21.mlp.up_proj.weight,lang_model.model.layers.21.input_layernorm.weight,lang_model.model.layers.21.post_attention_layernorm.weight,lang_model.model.layers.22.self_attn.q_proj.weight,lang_model.model.layers.22.self_attn.k_proj.weight,lang_model.model.layers.22.self_attn.v_proj.weight,lang_model.model.layers.22.self_attn.o_proj.weight,lang_model.model.layers.22.mlp.gate_proj.weight,lang_model.model.layers.22.mlp.down_proj.weight,lang_model.model.layers.22.mlp.up_proj.weight,lang_model.model.layers.22.input_layernorm.weight,lang_model.model.layers.22.post_attention_layernorm.weight,lang_model.model.layers.23.self_attn.q_proj.weight,lang_model.model.layers.23.self_attn.k_proj.weight,lang_model.model.layers.23.self_attn.v_proj.weight,lang_model.model.layers.23.self_attn.o_proj.weight,lang_model.model.layers.23.mlp.gate_proj.weight,lang_model.model.layers.23.mlp.down_proj.weight,lang_model.model.layers.23.mlp.up_proj.weight,lang_model.model.layers.23.input_layernorm.weight,lang_model.model.layers.23.post_attention_layernorm.weight,lang_model.model.layers.24.self_attn.q_proj.weight,lang_model.model.layers.24.self_attn.k_proj.weight,lang_model.model.layers.24.self_attn.v_proj.weight,lang_model.model.layers.24.self_attn.o_proj.weight,lang_model.model.layers.24.mlp.gate_proj.weight,lang_model.model.layers.24.mlp.down_proj.weight,lang_model.model.layers.24.mlp.up_proj.weight,lang_model.model.layers.24.input_layernorm.weight,lang_model.model.layers.24.post_attention_layernorm.weight,lang_model.model.layers.25.self_attn.q_proj.weight,lang_model.model.layers.25.self_attn.k_proj.weight,lang_model.model.layers.25.self_attn.v_proj.weight,lang_model.model.layers.25.self_attn.o_proj.weight,lang_model.model.layers.25.mlp.gate_proj.weight,lang_model.model.layers.25.mlp.down_proj.weight,lang_model.model.layers.25.mlp.up_proj.weight,lang_model.model.layers.25.input_layernorm.weight,lang_model.model.layers.25.post_attention_layernorm.weight,lang_model.model.layers.26.self_attn.q_proj.weight,lang_model.model.layers.26.self_attn.k_proj.weight,lang_model.model.layers.26.self_attn.v_proj.weight,lang_model.model.layers.26.self_attn.o_proj.weight,lang_model.model.layers.26.mlp.gate_proj.weight,lang_model.model.layers.26.mlp.down_proj.weight,lang_model.model.layers.26.mlp.up_proj.weight,lang_model.model.layers.26.input_layernorm.weight,lang_model.model.layers.26.post_attention_layernorm.weight,lang_model.model.layers.27.self_attn.q_proj.weight,lang_model.model.layers.27.self_attn.k_proj.weight,lang_model.model.layers.27.self_attn.v_proj.weight,lang_model.model.layers.27.self_attn.o_proj.weight,lang_model.model.layers.27.mlp.gate_proj.weight,lang_model.model.layers.27.mlp.down_proj.weight,lang_model.model.layers.27.mlp.up_proj.weight,lang_model.model.layers.27.input_layernorm.weight,lang_model.model.layers.27.post_attention_layernorm.weight,lang_model.model.layers.28.self_attn.q_proj.weight,lang_model.model.layers.28.self_attn.k_proj.weight,lang_model.model.layers.28.self_attn.v_proj.weight,lang_model.model.layers.28.self_attn.o_proj.weight,lang_model.model.layers.28.mlp.gate_proj.weight,lang_model.model.layers.28.mlp.down_proj.weight,lang_model.model.layers.28.mlp.up_proj.weight,lang_model.model.layers.28.input_layernorm.weight,lang_model.model.layers.28.post_attention_layernorm.weight,lang_model.model.layers.29.self_attn.q_proj.weight,lang_model.model.layers.29.self_attn.k_proj.weight,lang_model.model.layers.29.self_attn.v_proj.weight,lang_model.model.layers.29.self_attn.o_proj.weight,lang_model.model.layers.29.mlp.gate_proj.weight,lang_model.model.layers.29.mlp.down_proj.weight,lang_model.model.layers.29.mlp.up_proj.weight,lang_model.model.layers.29.input_layernorm.weight,lang_model.model.layers.29.post_attention_layernorm.weight,lang_model.model.layers.30.self_attn.q_proj.weight,lang_model.model.layers.30.self_attn.k_proj.weight,lang_model.model.layers.30.self_attn.v_proj.weight,lang_model.model.layers.30.self_attn.o_proj.weight,lang_model.model.layers.30.mlp.gate_proj.weight,lang_model.model.layers.30.mlp.down_proj.weight,lang_model.model.layers.30.mlp.up_proj.weight,lang_model.model.layers.30.input_layernorm.weight,lang_model.model.layers.30.post_attention_layernorm.weight,lang_model.model.layers.31.self_attn.q_proj.weight,lang_model.model.layers.31.self_attn.k_proj.weight,lang_model.model.layers.31.self_attn.v_proj.weight,lang_model.model.layers.31.self_attn.o_proj.weight,lang_model.model.layers.31.mlp.gate_proj.weight,lang_model.model.layers.31.mlp.down_proj.weight,lang_model.model.layers.31.mlp.up_proj.weight,lang_model.model.layers.31.input_layernorm.weight,lang_model.model.layers.31.post_attention_layernorm.weight,lang_model.model.norm.weight,lang_model.lm_head.weight,img_embeddings.img_linear.weight,img_embeddings.img_linear.bias,img_embeddings.img_layer_norm.weight,img_embeddings.img_layer_norm.bias,img_embeddings.loc_linear.weight,img_embeddings.loc_linear.bias,img_embeddings.loc_layer_norm.weight,img_embeddings.loc_layer_norm.bias,img_embeddings.nav_type_embedding.weight,img_embeddings.layer_norm.weight,img_embeddings.layer_norm.bias,img_embeddings.pano_encoder.layers.0.self_attn.in_proj_weight,img_embeddings.pano_encoder.layers.0.self_attn.in_proj_bias,img_embeddings.pano_encoder.layers.0.self_attn.out_proj.weight,img_embeddings.pano_encoder.layers.0.self_attn.out_proj.bias,img_embeddings.pano_encoder.layers.0.linear1.weight,img_embeddings.pano_encoder.layers.0.linear1.bias,img_embeddings.pano_encoder.layers.0.linear2.weight,img_embeddings.pano_encoder.layers.0.linear2.bias,img_embeddings.pano_encoder.layers.0.norm1.weight,img_embeddings.pano_encoder.layers.0.norm1.bias,img_embeddings.pano_encoder.layers.0.norm2.weight,img_embeddings.pano_encoder.layers.0.norm2.bias,img_embeddings.pano_encoder.layers.1.self_attn.in_proj_weight,img_embeddings.pano_encoder.layers.1.self_attn.in_proj_bias,img_embeddings.pano_encoder.layers.1.self_attn.out_proj.weight,img_embeddings.pano_encoder.layers.1.self_attn.out_proj.bias,img_embeddings.pano_encoder.layers.1.linear1.weight,img_embeddings.pano_encoder.layers.1.linear1.bias,img_embeddings.pano_encoder.layers.1.linear2.weight,img_embeddings.pano_encoder.layers.1.linear2.bias,img_embeddings.pano_encoder.layers.1.norm1.weight,img_embeddings.pano_encoder.layers.1.norm1.bias,img_embeddings.pano_encoder.layers.1.norm2.weight,img_embeddings.pano_encoder.layers.1.norm2.bias,img_embeddings.pano_encoder.norm.weight,img_embeddings.pano_encoder.norm.bias,img_embeddings.mapper.weight,img_embeddings.mapper.bias,token_type_embeddings.weight,gmap_pos_embeddings.0.weight,gmap_pos_embeddings.0.bias,gmap_pos_embeddings.1.weight,gmap_pos_embeddings.1.bias,gmap_step_embeddings.weight,vp_pos_embeddings.0.weight,vp_pos_embeddings.0.bias,vp_pos_embeddings.1.weight,vp_pos_embeddings.1.bias,obj_pos_embeddings.0.weight,obj_pos_embeddings.0.bias,obj_pos_embeddings.1.weight,obj_pos_embeddings.1.bias,og_head.0.weight,og_head.0.bias,out_head.0.weight,out_head.0.bias
2026-01-05 18:45:21,297   INFO  *************** init model *************** 
2026-01-05 18:45:25,492   INFO  Loading checkpoint from /data/wanghaoxuan/model_with_pretrain.pt
2026-01-05 18:45:30,810   INFO  Ignore weight img_embeddings.obj_projector.0.weight: torch.Size([4096, 768])
2026-01-05 18:45:30,811   INFO  Ignore weight img_embeddings.obj_projector.0.bias: torch.Size([4096])
2026-01-05 18:45:30,811   INFO  Ignore weight img_embeddings.obj_projector.1.weight: torch.Size([4096])
2026-01-05 18:45:30,811   INFO  Ignore weight img_embeddings.obj_projector.1.bias: torch.Size([4096])
2026-01-05 18:45:32,325   INFO  <All keys matched successfully>
2026-01-05 18:45:32,674   INFO  model initialized with 6770.32 M trainable parameters
2026-01-05 18:45:32,675   INFO  Training with a single process
2026-01-05 18:45:32,675   INFO  **************************** Test ****************************
2026-01-05 18:45:32,676   INFO  ***** validate val_unseen split on R2R task *****
2026-01-05 19:04:38,789   INFO  eval 2349 predictions
2026-01-05 19:04:38,848   INFO  
[Eval] val_unseen epoch 0

 [Eval] dataset=[R2R] 
, action_steps: 5.91, steps: 6.61, lengths: 12.92, nav_error: 3.62, oracle_error: 1.91
[Eval] ||| sr: 66.92, oracle_sr: 77.74, spl: 58.58
2026-01-05 19:07:30,774   INFO  **********************Start logging**********************
2026-01-05 19:07:30,774   INFO  CUDA_VISIBLE_DEVICES=0
2026-01-05 19:07:30,774   INFO  data_dir         /data/wanghaoxuan/data
2026-01-05 19:07:30,774   INFO  cfg_file         configs/multi.yaml
2026-01-05 19:07:30,774   INFO  pretrained_model_name_or_path /data/wanghaoxuan/data/models/Vicuna-7B
2026-01-05 19:07:30,774   INFO  off_batch_task   False
2026-01-05 19:07:30,774   INFO  debug            False
2026-01-05 19:07:30,774   INFO  few_shot         None
2026-01-05 19:07:30,774   INFO  tour3d_nav_head  False
2026-01-05 19:07:30,774   INFO  seed             0
2026-01-05 19:07:30,774   INFO  num_epochs       30
2026-01-05 19:07:30,774   INFO  resume_from_checkpoint /data/wanghaoxuan/model_with_pretrain.pt
2026-01-05 19:07:30,774   INFO  from_scratch     False
2026-01-05 19:07:30,774   INFO  batch_size       4
2026-01-05 19:07:30,774   INFO  val_batch_size   2
2026-01-05 19:07:30,774   INFO  lr               1e-05
2026-01-05 19:07:30,775   INFO  feat_dropout     0.4
2026-01-05 19:07:30,775   INFO  num_warmup_steps 0
2026-01-05 19:07:30,775   INFO  num_steps_per_epoch -1
2026-01-05 19:07:30,775   INFO  gradient_accumulation_step 2
2026-01-05 19:07:30,775   INFO  precision        amp_bf16
2026-01-05 19:07:30,775   INFO  workers          0
2026-01-05 19:07:30,775   INFO  gpu              0
2026-01-05 19:07:30,775   INFO  world_size       1
2026-01-05 19:07:30,775   INFO  local_rank       0
2026-01-05 19:07:30,775   INFO  dist_url         env://
2026-01-05 19:07:30,775   INFO  dist_backend     nccl
2026-01-05 19:07:30,775   INFO  horovod          False
2026-01-05 19:07:30,775   INFO  no_set_device_rank False
2026-01-05 19:07:30,775   INFO  output_dir       build/eval
2026-01-05 19:07:30,775   INFO  max_saved_checkpoints 0
2026-01-05 19:07:30,775   INFO  save_ckpt_per_epochs 10
2026-01-05 19:07:30,775   INFO  save_latest_states False
2026-01-05 19:07:30,775   INFO  save_pred_results True
2026-01-05 19:07:30,775   INFO  save_detail_results False
2026-01-05 19:07:30,775   INFO  mode             test
2026-01-05 19:07:30,776   INFO  stage            multi
2026-01-05 19:07:30,776   INFO  ignoreid         -100
2026-01-05 19:07:30,776   INFO  enable_og        False
2026-01-05 19:07:30,776   INFO  enable_summarize False
2026-01-05 19:07:30,776   INFO  enable_fgr2r     False
2026-01-05 19:07:30,776   INFO  disable_nav      False
2026-01-05 19:07:30,776   INFO  gen_loss_coef    1.0
2026-01-05 19:07:30,776   INFO  obj_loss_coef    1.0
2026-01-05 19:07:30,776   INFO  teacher_forcing_coef 1.0
2026-01-05 19:07:30,776   INFO  fuse_obj         False
2026-01-05 19:07:30,776   INFO  use_lora         False
2026-01-05 19:07:30,776   INFO  lora_rank        8
2026-01-05 19:07:30,776   INFO  lora_alpha       16
2026-01-05 19:07:30,776   INFO  lora_dropout     0.05
2026-01-05 19:07:30,776   INFO  lora_target      None
2026-01-05 19:07:30,776   INFO  freeze_llama     False
2026-01-05 19:07:30,776   INFO  tune_token_emb   False
2026-01-05 19:07:30,776   INFO  no_loc_fts       False
2026-01-05 19:07:30,776   INFO  multi_endpoints  1
2026-01-05 19:07:30,776   INFO  path_type        trusted_path
2026-01-05 19:07:30,777   INFO  test_datasets    ['R2R']
2026-01-05 19:07:30,777   INFO  validation_split test
2026-01-05 19:07:30,777   INFO  do_sample        False
2026-01-05 19:07:30,777   INFO  temperature      1.0
2026-01-05 19:07:30,777   INFO  max_datapoints   None
2026-01-05 19:07:30,777   INFO  rank             0
2026-01-05 19:07:30,777   INFO  distributed      False
2026-01-05 19:07:30,777   INFO  device           cuda:0
2026-01-05 19:07:30,777   INFO  image_feat_size  1024
2026-01-05 19:07:30,777   INFO  obj_feat_size    768
2026-01-05 19:07:30,777   INFO  angle_feat_size  4
2026-01-05 19:07:30,777   INFO  enc_full_graph   True
2026-01-05 19:07:30,777   INFO  expert_policy    spl
2026-01-05 19:07:30,777   INFO  num_pano_layers  2
2026-01-05 19:07:30,777   INFO  ----------- Feature -----------
2026-01-05 19:07:30,777   INFO  cfg.Feature.object_feature_type: 
2026-01-05 19:07:30,777   INFO  cfg.Feature.angle_feat_size: 4
2026-01-05 19:07:30,777   INFO  cfg.Feature.max_objects: 70
2026-01-05 19:07:30,777   INFO  cfg.Feature.image_feat_size: 1024
2026-01-05 19:07:30,777   INFO  ----------- feature_database -----------
2026-01-05 19:07:30,778   INFO  cfg.Feature.feature_database.mp3d: eva_features/mp3d_EVA02-CLIP-L-14-336.hdf5
2026-01-05 19:07:30,778   INFO  cfg.Feature.feature_database.scan_qa: eva_features/scanqa_EVA02-CLIP-L-14-336.hdf5
2026-01-05 19:07:30,778   INFO  cfg.Feature.feature_database.room_tour: eva_features/web_obj_prog_p1_EVA02-CLIP-L-14-336.hdf5.bak
2026-01-05 19:07:30,778   INFO  cfg.Feature.feature_database.room3d_tour: eva_features/web_3d_obj_prog_crop_p1_EVA02-CLIP-L-14-336.hdf5
2026-01-05 19:07:30,778   INFO  cfg.Feature.feature_database.coco: eva_features/coco_EVA02-CLIP-L-14-336.hdf5
2026-01-05 19:07:30,778   INFO  cfg.Feature.obj_feat_size: 768
2026-01-05 19:07:30,778   INFO  ----------- object_database -----------
2026-01-05 19:07:30,778   INFO  cfg.Feature.object_database.reverie: obj_features/reverie_obj_feat
2026-01-05 19:07:30,778   INFO  cfg.Feature.object_database.soon: obj_features/soon_obj_feat
2026-01-05 19:07:30,778   INFO  ----------- Dataset -----------
2026-01-05 19:07:30,778   INFO  ----------- R2R -----------
2026-01-05 19:07:30,778   INFO  cfg.Dataset.R2R.DIR: R2R
2026-01-05 19:07:30,778   INFO  ----------- SPLIT -----------
2026-01-05 19:07:30,778   INFO  cfg.Dataset.R2R.SPLIT.train: FGR2R_train.json
2026-01-05 19:07:30,778   INFO  cfg.Dataset.R2R.SPLIT.val_seen: R2R_val_seen_enc.json
2026-01-05 19:07:30,778   INFO  cfg.Dataset.R2R.SPLIT.val_unseen: R2R_val_unseen_enc.json
2026-01-05 19:07:30,778   INFO  cfg.Dataset.R2R.SPLIT.test: R2R_test_enc.json
2026-01-05 19:07:30,778   INFO  ----------- REVERIE -----------
2026-01-05 19:07:30,778   INFO  cfg.Dataset.REVERIE.DIR: REVERIE
2026-01-05 19:07:30,778   INFO  cfg.Dataset.REVERIE.bbox_file: BBoxes.json
2026-01-05 19:07:30,779   INFO  ----------- SPLIT -----------
2026-01-05 19:07:30,779   INFO  cfg.Dataset.REVERIE.SPLIT.train: REVERIE_train_enc.json
2026-01-05 19:07:30,779   INFO  cfg.Dataset.REVERIE.SPLIT.val_seen: REVERIE_val_seen_enc.json
2026-01-05 19:07:30,779   INFO  cfg.Dataset.REVERIE.SPLIT.val_unseen: REVERIE_val_unseen_enc.json
2026-01-05 19:07:30,779   INFO  cfg.Dataset.REVERIE.SPLIT.test: REVERIE_test_enc.json
2026-01-05 19:07:30,779   INFO  ----------- CVDN -----------
2026-01-05 19:07:30,779   INFO  cfg.Dataset.CVDN.DIR: CVDN
2026-01-05 19:07:30,779   INFO  ----------- SPLIT -----------
2026-01-05 19:07:30,779   INFO  cfg.Dataset.CVDN.SPLIT.train: train.json
2026-01-05 19:07:30,779   INFO  cfg.Dataset.CVDN.SPLIT.val_seen: val_seen.json
2026-01-05 19:07:30,779   INFO  cfg.Dataset.CVDN.SPLIT.val_unseen: val_unseen.json
2026-01-05 19:07:30,779   INFO  cfg.Dataset.CVDN.SPLIT.test: test_cleaned.json
2026-01-05 19:07:30,779   INFO  ----------- SOON -----------
2026-01-05 19:07:30,779   INFO  cfg.Dataset.SOON.DIR: SOON
2026-01-05 19:07:30,779   INFO  ----------- SPLIT -----------
2026-01-05 19:07:30,779   INFO  cfg.Dataset.SOON.SPLIT.train: train_enc_pseudo_obj_ade30k_label.jsonl
2026-01-05 19:07:30,779   INFO  cfg.Dataset.SOON.SPLIT.val_seen: val_unseen_instrs_enc_pseudo_obj_ade30k_label.jsonl
2026-01-05 19:07:30,779   INFO  cfg.Dataset.SOON.SPLIT.val_unseen: val_unseen_house_enc_pseudo_obj_ade30k_label.jsonl
2026-01-05 19:07:30,779   INFO  cfg.Dataset.SOON.SPLIT.test: test_v2_enc.jsonl
2026-01-05 19:07:30,779   INFO  ----------- ScanQA -----------
2026-01-05 19:07:30,780   INFO  cfg.Dataset.ScanQA.DIR: ScanQA
2026-01-05 19:07:30,780   INFO  ----------- SPLIT -----------
2026-01-05 19:07:30,780   INFO  cfg.Dataset.ScanQA.SPLIT.train: ScanQA_v1.0_train_reformat.json
2026-01-05 19:07:30,780   INFO  cfg.Dataset.ScanQA.SPLIT.val_unseen: ScanQA_v1.0_val_reformat.json
2026-01-05 19:07:30,780   INFO  cfg.Dataset.ScanQA.SPLIT.test_wo_obj: ScanQA_v1.0_test_wo_obj_reformat.json
2026-01-05 19:07:30,780   INFO  cfg.Dataset.ScanQA.SPLIT.test_w_obj: ScanQA_v1.0_test_w_obj_reformat.json
2026-01-05 19:07:30,780   INFO  ----------- RoomTour -----------
2026-01-05 19:07:30,780   INFO  cfg.Dataset.RoomTour.DIR: RoomTour
2026-01-05 19:07:30,780   INFO  ----------- SPLIT -----------
2026-01-05 19:07:30,780   INFO  cfg.Dataset.RoomTour.SPLIT.train: p1_train_reformat.json
2026-01-05 19:07:30,780   INFO  ----------- Tour3D -----------
2026-01-05 19:07:30,780   INFO  cfg.Dataset.Tour3D.DIR: RoomTour
2026-01-05 19:07:30,780   INFO  ----------- SPLIT -----------
2026-01-05 19:07:30,780   INFO  cfg.Dataset.Tour3D.SPLIT.train: p1_train_colmap_trajectory_tour3d.json
2026-01-05 19:07:30,780   INFO  ----------- EQA -----------
2026-01-05 19:07:30,780   INFO  cfg.Dataset.EQA.DIR: EQA_MP3D
2026-01-05 19:07:30,780   INFO  ----------- SPLIT -----------
2026-01-05 19:07:30,780   INFO  cfg.Dataset.EQA.SPLIT.val_unseen: eqa_val_enc.json
2026-01-05 19:07:30,780   INFO  cfg.Dataset.EQA.ANSWER_VOCAB: eqa_answer_vocab.json
2026-01-05 19:07:30,780   INFO  ----------- R2R_AUG -----------
2026-01-05 19:07:30,781   INFO  cfg.Dataset.R2R_AUG.DIR: R2R
2026-01-05 19:07:30,781   INFO  ----------- SPLIT -----------
2026-01-05 19:07:30,781   INFO  cfg.Dataset.R2R_AUG.SPLIT.train: R2R_prevalent_aug_train_enc.jsonl
2026-01-05 19:07:30,781   INFO  ----------- REVERIE_AUG -----------
2026-01-05 19:07:30,781   INFO  cfg.Dataset.REVERIE_AUG.DIR: REVERIE
2026-01-05 19:07:30,781   INFO  cfg.Dataset.REVERIE_AUG.bbox_file: BBoxes.json
2026-01-05 19:07:30,781   INFO  ----------- SPLIT -----------
2026-01-05 19:07:30,781   INFO  cfg.Dataset.REVERIE_AUG.SPLIT.train: REVERIE_speaker_aug_enc.jsonl
2026-01-05 19:07:30,781   INFO  ----------- LLaVA -----------
2026-01-05 19:07:30,781   INFO  cfg.Dataset.LLaVA.DIR: LLaVA
2026-01-05 19:07:30,781   INFO  ----------- SPLIT -----------
2026-01-05 19:07:30,781   INFO  cfg.Dataset.LLaVA.SPLIT.train: detail_23k.json
2026-01-05 19:07:30,781   INFO  ----------- Pretrain -----------
2026-01-05 19:07:30,781   INFO  cfg.Pretrain.SOURCE: ['Tour3D', 'RoomTour', 'ScanQA', 'LLaVA']
2026-01-05 19:07:30,781   INFO  cfg.Pretrain.Ratio: [10, 20, 5, 2]
2026-01-05 19:07:30,781   INFO  ----------- LOSS_COEF -----------
2026-01-05 19:07:30,781   INFO  cfg.Pretrain.LOSS_COEF.R2R_AUG: 1
2026-01-05 19:07:30,781   INFO  cfg.Pretrain.LOSS_COEF.REVERIE_AUG: 1
2026-01-05 19:07:30,781   INFO  ----------- Multi -----------
2026-01-05 19:07:30,782   INFO  cfg.Multi.SOURCE: ['Tour3D', 'R2R', 'REVERIE', 'CVDN', 'SOON', 'ScanQA', 'LLaVA']
2026-01-05 19:07:30,782   INFO  cfg.Multi.Ratio: [10, 20, 5, 1, 5, 5, 5]
2026-01-05 19:07:30,782   INFO  ----------- LOSS_COEF -----------
2026-01-05 19:07:30,782   INFO  ----------- Model -----------
2026-01-05 19:07:30,782   INFO  cfg.Model.num_l_layers: 9
2026-01-05 19:07:30,782   INFO  cfg.Model.num_pano_layers: 2
2026-01-05 19:07:30,782   INFO  cfg.Model.num_x_layers: 4
2026-01-05 19:07:30,782   INFO  cfg.Model.graph_sprels: True
2026-01-05 19:07:30,782   INFO  cfg.Model.fusion: dynamic
2026-01-05 19:07:30,782   INFO  cfg.Model.enc_full_graph: True
2026-01-05 19:07:30,782   INFO  cfg.Model.expert_policy: spl
2026-01-05 19:07:30,782   INFO  ----------- Optim -----------
2026-01-05 19:07:30,782   INFO  ----------- val_max_action_len -----------
2026-01-05 19:07:30,782   INFO  cfg.Optim.val_max_action_len.R2R: 15
2026-01-05 19:07:30,782   INFO  cfg.Optim.val_max_action_len.REVERIE: 15
2026-01-05 19:07:30,782   INFO  cfg.Optim.val_max_action_len.CVDN: 30
2026-01-05 19:07:30,782   INFO  cfg.Optim.val_max_action_len.SOON: 20
2026-01-05 19:07:30,782   INFO  cfg.Optim.val_max_action_len.EQA: 15
2026-01-05 19:07:30,782   INFO  ----------- train_max_action_len -----------
2026-01-05 19:07:30,782   INFO  cfg.Optim.train_max_action_len.R2R: 15
2026-01-05 19:07:30,783   INFO  cfg.Optim.train_max_action_len.Tour3D: 15
2026-01-05 19:07:30,783   INFO  cfg.Optim.train_max_action_len.REVERIE: 15
2026-01-05 19:07:30,783   INFO  cfg.Optim.train_max_action_len.CVDN: 15
2026-01-05 19:07:30,783   INFO  cfg.Optim.train_max_action_len.SOON: 15
2026-01-05 19:07:30,783   INFO  cfg.Optim.train_max_action_len.EQA: 15
2026-01-05 19:07:30,783   INFO  cfg.Optim.train_max_action_len.R2R_AUG: 15
2026-01-05 19:07:30,783   INFO  cfg.Optim.train_max_action_len.REVERIE_AUG: 15
2026-01-05 19:07:33,774   INFO  [INFO] R2RDataset loaded with 4173 instructions, using splits: test
2026-01-05 19:07:33,775   INFO  
- Dataset: load 4173 R2R samples
- Dataset: load test split: 4173 samples in total
- Dataset: load test split: 18 scans in total
2026-01-05 19:07:33,775   INFO  R2R: 4173 samples loaded
2026-01-05 19:07:33,867   INFO  Initialize the model from config.
2026-01-05 19:09:05,360   INFO  model type: torch.bfloat16
2026-01-05 19:09:05,363   INFO  Trainable params: lang_model.model.embed_tokens.weight,lang_model.model.layers.0.self_attn.q_proj.weight,lang_model.model.layers.0.self_attn.k_proj.weight,lang_model.model.layers.0.self_attn.v_proj.weight,lang_model.model.layers.0.self_attn.o_proj.weight,lang_model.model.layers.0.mlp.gate_proj.weight,lang_model.model.layers.0.mlp.down_proj.weight,lang_model.model.layers.0.mlp.up_proj.weight,lang_model.model.layers.0.input_layernorm.weight,lang_model.model.layers.0.post_attention_layernorm.weight,lang_model.model.layers.1.self_attn.q_proj.weight,lang_model.model.layers.1.self_attn.k_proj.weight,lang_model.model.layers.1.self_attn.v_proj.weight,lang_model.model.layers.1.self_attn.o_proj.weight,lang_model.model.layers.1.mlp.gate_proj.weight,lang_model.model.layers.1.mlp.down_proj.weight,lang_model.model.layers.1.mlp.up_proj.weight,lang_model.model.layers.1.input_layernorm.weight,lang_model.model.layers.1.post_attention_layernorm.weight,lang_model.model.layers.2.self_attn.q_proj.weight,lang_model.model.layers.2.self_attn.k_proj.weight,lang_model.model.layers.2.self_attn.v_proj.weight,lang_model.model.layers.2.self_attn.o_proj.weight,lang_model.model.layers.2.mlp.gate_proj.weight,lang_model.model.layers.2.mlp.down_proj.weight,lang_model.model.layers.2.mlp.up_proj.weight,lang_model.model.layers.2.input_layernorm.weight,lang_model.model.layers.2.post_attention_layernorm.weight,lang_model.model.layers.3.self_attn.q_proj.weight,lang_model.model.layers.3.self_attn.k_proj.weight,lang_model.model.layers.3.self_attn.v_proj.weight,lang_model.model.layers.3.self_attn.o_proj.weight,lang_model.model.layers.3.mlp.gate_proj.weight,lang_model.model.layers.3.mlp.down_proj.weight,lang_model.model.layers.3.mlp.up_proj.weight,lang_model.model.layers.3.input_layernorm.weight,lang_model.model.layers.3.post_attention_layernorm.weight,lang_model.model.layers.4.self_attn.q_proj.weight,lang_model.model.layers.4.self_attn.k_proj.weight,lang_model.model.layers.4.self_attn.v_proj.weight,lang_model.model.layers.4.self_attn.o_proj.weight,lang_model.model.layers.4.mlp.gate_proj.weight,lang_model.model.layers.4.mlp.down_proj.weight,lang_model.model.layers.4.mlp.up_proj.weight,lang_model.model.layers.4.input_layernorm.weight,lang_model.model.layers.4.post_attention_layernorm.weight,lang_model.model.layers.5.self_attn.q_proj.weight,lang_model.model.layers.5.self_attn.k_proj.weight,lang_model.model.layers.5.self_attn.v_proj.weight,lang_model.model.layers.5.self_attn.o_proj.weight,lang_model.model.layers.5.mlp.gate_proj.weight,lang_model.model.layers.5.mlp.down_proj.weight,lang_model.model.layers.5.mlp.up_proj.weight,lang_model.model.layers.5.input_layernorm.weight,lang_model.model.layers.5.post_attention_layernorm.weight,lang_model.model.layers.6.self_attn.q_proj.weight,lang_model.model.layers.6.self_attn.k_proj.weight,lang_model.model.layers.6.self_attn.v_proj.weight,lang_model.model.layers.6.self_attn.o_proj.weight,lang_model.model.layers.6.mlp.gate_proj.weight,lang_model.model.layers.6.mlp.down_proj.weight,lang_model.model.layers.6.mlp.up_proj.weight,lang_model.model.layers.6.input_layernorm.weight,lang_model.model.layers.6.post_attention_layernorm.weight,lang_model.model.layers.7.self_attn.q_proj.weight,lang_model.model.layers.7.self_attn.k_proj.weight,lang_model.model.layers.7.self_attn.v_proj.weight,lang_model.model.layers.7.self_attn.o_proj.weight,lang_model.model.layers.7.mlp.gate_proj.weight,lang_model.model.layers.7.mlp.down_proj.weight,lang_model.model.layers.7.mlp.up_proj.weight,lang_model.model.layers.7.input_layernorm.weight,lang_model.model.layers.7.post_attention_layernorm.weight,lang_model.model.layers.8.self_attn.q_proj.weight,lang_model.model.layers.8.self_attn.k_proj.weight,lang_model.model.layers.8.self_attn.v_proj.weight,lang_model.model.layers.8.self_attn.o_proj.weight,lang_model.model.layers.8.mlp.gate_proj.weight,lang_model.model.layers.8.mlp.down_proj.weight,lang_model.model.layers.8.mlp.up_proj.weight,lang_model.model.layers.8.input_layernorm.weight,lang_model.model.layers.8.post_attention_layernorm.weight,lang_model.model.layers.9.self_attn.q_proj.weight,lang_model.model.layers.9.self_attn.k_proj.weight,lang_model.model.layers.9.self_attn.v_proj.weight,lang_model.model.layers.9.self_attn.o_proj.weight,lang_model.model.layers.9.mlp.gate_proj.weight,lang_model.model.layers.9.mlp.down_proj.weight,lang_model.model.layers.9.mlp.up_proj.weight,lang_model.model.layers.9.input_layernorm.weight,lang_model.model.layers.9.post_attention_layernorm.weight,lang_model.model.layers.10.self_attn.q_proj.weight,lang_model.model.layers.10.self_attn.k_proj.weight,lang_model.model.layers.10.self_attn.v_proj.weight,lang_model.model.layers.10.self_attn.o_proj.weight,lang_model.model.layers.10.mlp.gate_proj.weight,lang_model.model.layers.10.mlp.down_proj.weight,lang_model.model.layers.10.mlp.up_proj.weight,lang_model.model.layers.10.input_layernorm.weight,lang_model.model.layers.10.post_attention_layernorm.weight,lang_model.model.layers.11.self_attn.q_proj.weight,lang_model.model.layers.11.self_attn.k_proj.weight,lang_model.model.layers.11.self_attn.v_proj.weight,lang_model.model.layers.11.self_attn.o_proj.weight,lang_model.model.layers.11.mlp.gate_proj.weight,lang_model.model.layers.11.mlp.down_proj.weight,lang_model.model.layers.11.mlp.up_proj.weight,lang_model.model.layers.11.input_layernorm.weight,lang_model.model.layers.11.post_attention_layernorm.weight,lang_model.model.layers.12.self_attn.q_proj.weight,lang_model.model.layers.12.self_attn.k_proj.weight,lang_model.model.layers.12.self_attn.v_proj.weight,lang_model.model.layers.12.self_attn.o_proj.weight,lang_model.model.layers.12.mlp.gate_proj.weight,lang_model.model.layers.12.mlp.down_proj.weight,lang_model.model.layers.12.mlp.up_proj.weight,lang_model.model.layers.12.input_layernorm.weight,lang_model.model.layers.12.post_attention_layernorm.weight,lang_model.model.layers.13.self_attn.q_proj.weight,lang_model.model.layers.13.self_attn.k_proj.weight,lang_model.model.layers.13.self_attn.v_proj.weight,lang_model.model.layers.13.self_attn.o_proj.weight,lang_model.model.layers.13.mlp.gate_proj.weight,lang_model.model.layers.13.mlp.down_proj.weight,lang_model.model.layers.13.mlp.up_proj.weight,lang_model.model.layers.13.input_layernorm.weight,lang_model.model.layers.13.post_attention_layernorm.weight,lang_model.model.layers.14.self_attn.q_proj.weight,lang_model.model.layers.14.self_attn.k_proj.weight,lang_model.model.layers.14.self_attn.v_proj.weight,lang_model.model.layers.14.self_attn.o_proj.weight,lang_model.model.layers.14.mlp.gate_proj.weight,lang_model.model.layers.14.mlp.down_proj.weight,lang_model.model.layers.14.mlp.up_proj.weight,lang_model.model.layers.14.input_layernorm.weight,lang_model.model.layers.14.post_attention_layernorm.weight,lang_model.model.layers.15.self_attn.q_proj.weight,lang_model.model.layers.15.self_attn.k_proj.weight,lang_model.model.layers.15.self_attn.v_proj.weight,lang_model.model.layers.15.self_attn.o_proj.weight,lang_model.model.layers.15.mlp.gate_proj.weight,lang_model.model.layers.15.mlp.down_proj.weight,lang_model.model.layers.15.mlp.up_proj.weight,lang_model.model.layers.15.input_layernorm.weight,lang_model.model.layers.15.post_attention_layernorm.weight,lang_model.model.layers.16.self_attn.q_proj.weight,lang_model.model.layers.16.self_attn.k_proj.weight,lang_model.model.layers.16.self_attn.v_proj.weight,lang_model.model.layers.16.self_attn.o_proj.weight,lang_model.model.layers.16.mlp.gate_proj.weight,lang_model.model.layers.16.mlp.down_proj.weight,lang_model.model.layers.16.mlp.up_proj.weight,lang_model.model.layers.16.input_layernorm.weight,lang_model.model.layers.16.post_attention_layernorm.weight,lang_model.model.layers.17.self_attn.q_proj.weight,lang_model.model.layers.17.self_attn.k_proj.weight,lang_model.model.layers.17.self_attn.v_proj.weight,lang_model.model.layers.17.self_attn.o_proj.weight,lang_model.model.layers.17.mlp.gate_proj.weight,lang_model.model.layers.17.mlp.down_proj.weight,lang_model.model.layers.17.mlp.up_proj.weight,lang_model.model.layers.17.input_layernorm.weight,lang_model.model.layers.17.post_attention_layernorm.weight,lang_model.model.layers.18.self_attn.q_proj.weight,lang_model.model.layers.18.self_attn.k_proj.weight,lang_model.model.layers.18.self_attn.v_proj.weight,lang_model.model.layers.18.self_attn.o_proj.weight,lang_model.model.layers.18.mlp.gate_proj.weight,lang_model.model.layers.18.mlp.down_proj.weight,lang_model.model.layers.18.mlp.up_proj.weight,lang_model.model.layers.18.input_layernorm.weight,lang_model.model.layers.18.post_attention_layernorm.weight,lang_model.model.layers.19.self_attn.q_proj.weight,lang_model.model.layers.19.self_attn.k_proj.weight,lang_model.model.layers.19.self_attn.v_proj.weight,lang_model.model.layers.19.self_attn.o_proj.weight,lang_model.model.layers.19.mlp.gate_proj.weight,lang_model.model.layers.19.mlp.down_proj.weight,lang_model.model.layers.19.mlp.up_proj.weight,lang_model.model.layers.19.input_layernorm.weight,lang_model.model.layers.19.post_attention_layernorm.weight,lang_model.model.layers.20.self_attn.q_proj.weight,lang_model.model.layers.20.self_attn.k_proj.weight,lang_model.model.layers.20.self_attn.v_proj.weight,lang_model.model.layers.20.self_attn.o_proj.weight,lang_model.model.layers.20.mlp.gate_proj.weight,lang_model.model.layers.20.mlp.down_proj.weight,lang_model.model.layers.20.mlp.up_proj.weight,lang_model.model.layers.20.input_layernorm.weight,lang_model.model.layers.20.post_attention_layernorm.weight,lang_model.model.layers.21.self_attn.q_proj.weight,lang_model.model.layers.21.self_attn.k_proj.weight,lang_model.model.layers.21.self_attn.v_proj.weight,lang_model.model.layers.21.self_attn.o_proj.weight,lang_model.model.layers.21.mlp.gate_proj.weight,lang_model.model.layers.21.mlp.down_proj.weight,lang_model.model.layers.21.mlp.up_proj.weight,lang_model.model.layers.21.input_layernorm.weight,lang_model.model.layers.21.post_attention_layernorm.weight,lang_model.model.layers.22.self_attn.q_proj.weight,lang_model.model.layers.22.self_attn.k_proj.weight,lang_model.model.layers.22.self_attn.v_proj.weight,lang_model.model.layers.22.self_attn.o_proj.weight,lang_model.model.layers.22.mlp.gate_proj.weight,lang_model.model.layers.22.mlp.down_proj.weight,lang_model.model.layers.22.mlp.up_proj.weight,lang_model.model.layers.22.input_layernorm.weight,lang_model.model.layers.22.post_attention_layernorm.weight,lang_model.model.layers.23.self_attn.q_proj.weight,lang_model.model.layers.23.self_attn.k_proj.weight,lang_model.model.layers.23.self_attn.v_proj.weight,lang_model.model.layers.23.self_attn.o_proj.weight,lang_model.model.layers.23.mlp.gate_proj.weight,lang_model.model.layers.23.mlp.down_proj.weight,lang_model.model.layers.23.mlp.up_proj.weight,lang_model.model.layers.23.input_layernorm.weight,lang_model.model.layers.23.post_attention_layernorm.weight,lang_model.model.layers.24.self_attn.q_proj.weight,lang_model.model.layers.24.self_attn.k_proj.weight,lang_model.model.layers.24.self_attn.v_proj.weight,lang_model.model.layers.24.self_attn.o_proj.weight,lang_model.model.layers.24.mlp.gate_proj.weight,lang_model.model.layers.24.mlp.down_proj.weight,lang_model.model.layers.24.mlp.up_proj.weight,lang_model.model.layers.24.input_layernorm.weight,lang_model.model.layers.24.post_attention_layernorm.weight,lang_model.model.layers.25.self_attn.q_proj.weight,lang_model.model.layers.25.self_attn.k_proj.weight,lang_model.model.layers.25.self_attn.v_proj.weight,lang_model.model.layers.25.self_attn.o_proj.weight,lang_model.model.layers.25.mlp.gate_proj.weight,lang_model.model.layers.25.mlp.down_proj.weight,lang_model.model.layers.25.mlp.up_proj.weight,lang_model.model.layers.25.input_layernorm.weight,lang_model.model.layers.25.post_attention_layernorm.weight,lang_model.model.layers.26.self_attn.q_proj.weight,lang_model.model.layers.26.self_attn.k_proj.weight,lang_model.model.layers.26.self_attn.v_proj.weight,lang_model.model.layers.26.self_attn.o_proj.weight,lang_model.model.layers.26.mlp.gate_proj.weight,lang_model.model.layers.26.mlp.down_proj.weight,lang_model.model.layers.26.mlp.up_proj.weight,lang_model.model.layers.26.input_layernorm.weight,lang_model.model.layers.26.post_attention_layernorm.weight,lang_model.model.layers.27.self_attn.q_proj.weight,lang_model.model.layers.27.self_attn.k_proj.weight,lang_model.model.layers.27.self_attn.v_proj.weight,lang_model.model.layers.27.self_attn.o_proj.weight,lang_model.model.layers.27.mlp.gate_proj.weight,lang_model.model.layers.27.mlp.down_proj.weight,lang_model.model.layers.27.mlp.up_proj.weight,lang_model.model.layers.27.input_layernorm.weight,lang_model.model.layers.27.post_attention_layernorm.weight,lang_model.model.layers.28.self_attn.q_proj.weight,lang_model.model.layers.28.self_attn.k_proj.weight,lang_model.model.layers.28.self_attn.v_proj.weight,lang_model.model.layers.28.self_attn.o_proj.weight,lang_model.model.layers.28.mlp.gate_proj.weight,lang_model.model.layers.28.mlp.down_proj.weight,lang_model.model.layers.28.mlp.up_proj.weight,lang_model.model.layers.28.input_layernorm.weight,lang_model.model.layers.28.post_attention_layernorm.weight,lang_model.model.layers.29.self_attn.q_proj.weight,lang_model.model.layers.29.self_attn.k_proj.weight,lang_model.model.layers.29.self_attn.v_proj.weight,lang_model.model.layers.29.self_attn.o_proj.weight,lang_model.model.layers.29.mlp.gate_proj.weight,lang_model.model.layers.29.mlp.down_proj.weight,lang_model.model.layers.29.mlp.up_proj.weight,lang_model.model.layers.29.input_layernorm.weight,lang_model.model.layers.29.post_attention_layernorm.weight,lang_model.model.layers.30.self_attn.q_proj.weight,lang_model.model.layers.30.self_attn.k_proj.weight,lang_model.model.layers.30.self_attn.v_proj.weight,lang_model.model.layers.30.self_attn.o_proj.weight,lang_model.model.layers.30.mlp.gate_proj.weight,lang_model.model.layers.30.mlp.down_proj.weight,lang_model.model.layers.30.mlp.up_proj.weight,lang_model.model.layers.30.input_layernorm.weight,lang_model.model.layers.30.post_attention_layernorm.weight,lang_model.model.layers.31.self_attn.q_proj.weight,lang_model.model.layers.31.self_attn.k_proj.weight,lang_model.model.layers.31.self_attn.v_proj.weight,lang_model.model.layers.31.self_attn.o_proj.weight,lang_model.model.layers.31.mlp.gate_proj.weight,lang_model.model.layers.31.mlp.down_proj.weight,lang_model.model.layers.31.mlp.up_proj.weight,lang_model.model.layers.31.input_layernorm.weight,lang_model.model.layers.31.post_attention_layernorm.weight,lang_model.model.norm.weight,lang_model.lm_head.weight,img_embeddings.img_linear.weight,img_embeddings.img_linear.bias,img_embeddings.img_layer_norm.weight,img_embeddings.img_layer_norm.bias,img_embeddings.loc_linear.weight,img_embeddings.loc_linear.bias,img_embeddings.loc_layer_norm.weight,img_embeddings.loc_layer_norm.bias,img_embeddings.nav_type_embedding.weight,img_embeddings.layer_norm.weight,img_embeddings.layer_norm.bias,img_embeddings.pano_encoder.layers.0.self_attn.in_proj_weight,img_embeddings.pano_encoder.layers.0.self_attn.in_proj_bias,img_embeddings.pano_encoder.layers.0.self_attn.out_proj.weight,img_embeddings.pano_encoder.layers.0.self_attn.out_proj.bias,img_embeddings.pano_encoder.layers.0.linear1.weight,img_embeddings.pano_encoder.layers.0.linear1.bias,img_embeddings.pano_encoder.layers.0.linear2.weight,img_embeddings.pano_encoder.layers.0.linear2.bias,img_embeddings.pano_encoder.layers.0.norm1.weight,img_embeddings.pano_encoder.layers.0.norm1.bias,img_embeddings.pano_encoder.layers.0.norm2.weight,img_embeddings.pano_encoder.layers.0.norm2.bias,img_embeddings.pano_encoder.layers.1.self_attn.in_proj_weight,img_embeddings.pano_encoder.layers.1.self_attn.in_proj_bias,img_embeddings.pano_encoder.layers.1.self_attn.out_proj.weight,img_embeddings.pano_encoder.layers.1.self_attn.out_proj.bias,img_embeddings.pano_encoder.layers.1.linear1.weight,img_embeddings.pano_encoder.layers.1.linear1.bias,img_embeddings.pano_encoder.layers.1.linear2.weight,img_embeddings.pano_encoder.layers.1.linear2.bias,img_embeddings.pano_encoder.layers.1.norm1.weight,img_embeddings.pano_encoder.layers.1.norm1.bias,img_embeddings.pano_encoder.layers.1.norm2.weight,img_embeddings.pano_encoder.layers.1.norm2.bias,img_embeddings.pano_encoder.norm.weight,img_embeddings.pano_encoder.norm.bias,img_embeddings.mapper.weight,img_embeddings.mapper.bias,token_type_embeddings.weight,gmap_pos_embeddings.0.weight,gmap_pos_embeddings.0.bias,gmap_pos_embeddings.1.weight,gmap_pos_embeddings.1.bias,gmap_step_embeddings.weight,vp_pos_embeddings.0.weight,vp_pos_embeddings.0.bias,vp_pos_embeddings.1.weight,vp_pos_embeddings.1.bias,obj_pos_embeddings.0.weight,obj_pos_embeddings.0.bias,obj_pos_embeddings.1.weight,obj_pos_embeddings.1.bias,og_head.0.weight,og_head.0.bias,out_head.0.weight,out_head.0.bias
2026-01-05 19:09:05,363   INFO  *************** init model *************** 
2026-01-05 19:09:09,734   INFO  Loading checkpoint from /data/wanghaoxuan/model_with_pretrain.pt
2026-01-05 19:09:14,173   INFO  Ignore weight img_embeddings.obj_projector.0.weight: torch.Size([4096, 768])
2026-01-05 19:09:14,174   INFO  Ignore weight img_embeddings.obj_projector.0.bias: torch.Size([4096])
2026-01-05 19:09:14,174   INFO  Ignore weight img_embeddings.obj_projector.1.weight: torch.Size([4096])
2026-01-05 19:09:14,174   INFO  Ignore weight img_embeddings.obj_projector.1.bias: torch.Size([4096])
2026-01-05 19:09:15,182   INFO  <All keys matched successfully>
2026-01-05 19:09:15,523   INFO  model initialized with 6770.32 M trainable parameters
2026-01-05 19:09:15,525   INFO  Training with a single process
2026-01-05 19:09:15,525   INFO  **************************** Test ****************************
2026-01-05 19:09:15,527   INFO  ***** validate test split on R2R task *****
2026-01-05 19:43:29,546   INFO  
[Eval] test epoch 0

2026-01-05 20:03:43,449   INFO  **********************Start logging**********************
2026-01-05 20:03:43,449   INFO  CUDA_VISIBLE_DEVICES=0
2026-01-05 20:03:43,449   INFO  data_dir         /data/wanghaoxuan/data
2026-01-05 20:03:43,450   INFO  cfg_file         configs/multi.yaml
2026-01-05 20:03:43,450   INFO  pretrained_model_name_or_path /data/wanghaoxuan/data/models/Vicuna-7B
2026-01-05 20:03:43,450   INFO  off_batch_task   False
2026-01-05 20:03:43,450   INFO  debug            False
2026-01-05 20:03:43,450   INFO  few_shot         None
2026-01-05 20:03:43,450   INFO  tour3d_nav_head  False
2026-01-05 20:03:43,450   INFO  seed             0
2026-01-05 20:03:43,450   INFO  num_epochs       30
2026-01-05 20:03:43,450   INFO  resume_from_checkpoint /data/wanghaoxuan/model_with_pretrain.pt
2026-01-05 20:03:43,450   INFO  from_scratch     False
2026-01-05 20:03:43,450   INFO  batch_size       4
2026-01-05 20:03:43,450   INFO  val_batch_size   2
2026-01-05 20:03:43,450   INFO  lr               1e-05
2026-01-05 20:03:43,450   INFO  feat_dropout     0.4
2026-01-05 20:03:43,450   INFO  num_warmup_steps 0
2026-01-05 20:03:43,450   INFO  num_steps_per_epoch -1
2026-01-05 20:03:43,450   INFO  gradient_accumulation_step 2
2026-01-05 20:03:43,450   INFO  precision        amp_bf16
2026-01-05 20:03:43,450   INFO  workers          0
2026-01-05 20:03:43,451   INFO  gpu              0
2026-01-05 20:03:43,451   INFO  world_size       1
2026-01-05 20:03:43,451   INFO  local_rank       0
2026-01-05 20:03:43,451   INFO  dist_url         env://
2026-01-05 20:03:43,451   INFO  dist_backend     nccl
2026-01-05 20:03:43,451   INFO  horovod          False
2026-01-05 20:03:43,451   INFO  no_set_device_rank False
2026-01-05 20:03:43,451   INFO  output_dir       build/eval
2026-01-05 20:03:43,451   INFO  max_saved_checkpoints 0
2026-01-05 20:03:43,451   INFO  save_ckpt_per_epochs 10
2026-01-05 20:03:43,451   INFO  save_latest_states False
2026-01-05 20:03:43,451   INFO  save_pred_results True
2026-01-05 20:03:43,451   INFO  save_detail_results False
2026-01-05 20:03:43,451   INFO  mode             test
2026-01-05 20:03:43,451   INFO  stage            multi
2026-01-05 20:03:43,451   INFO  ignoreid         -100
2026-01-05 20:03:43,451   INFO  enable_og        True
2026-01-05 20:03:43,451   INFO  enable_summarize False
2026-01-05 20:03:43,451   INFO  enable_fgr2r     False
2026-01-05 20:03:43,452   INFO  disable_nav      False
2026-01-05 20:03:43,452   INFO  gen_loss_coef    1.0
2026-01-05 20:03:43,452   INFO  obj_loss_coef    1.0
2026-01-05 20:03:43,452   INFO  teacher_forcing_coef 1.0
2026-01-05 20:03:43,452   INFO  fuse_obj         False
2026-01-05 20:03:43,452   INFO  use_lora         False
2026-01-05 20:03:43,452   INFO  lora_rank        8
2026-01-05 20:03:43,452   INFO  lora_alpha       16
2026-01-05 20:03:43,452   INFO  lora_dropout     0.05
2026-01-05 20:03:43,452   INFO  lora_target      None
2026-01-05 20:03:43,452   INFO  freeze_llama     False
2026-01-05 20:03:43,452   INFO  tune_token_emb   False
2026-01-05 20:03:43,452   INFO  no_loc_fts       False
2026-01-05 20:03:43,452   INFO  multi_endpoints  1
2026-01-05 20:03:43,452   INFO  path_type        trusted_path
2026-01-05 20:03:43,452   INFO  test_datasets    ['SOON']
2026-01-05 20:03:43,452   INFO  validation_split test
2026-01-05 20:03:43,452   INFO  do_sample        True
2026-01-05 20:03:43,452   INFO  temperature      0.01
2026-01-05 20:03:43,453   INFO  max_datapoints   None
2026-01-05 20:03:43,453   INFO  rank             0
2026-01-05 20:03:43,453   INFO  distributed      False
2026-01-05 20:03:43,453   INFO  device           cuda:0
2026-01-05 20:03:43,453   INFO  image_feat_size  1024
2026-01-05 20:03:43,453   INFO  obj_feat_size    768
2026-01-05 20:03:43,453   INFO  angle_feat_size  4
2026-01-05 20:03:43,453   INFO  enc_full_graph   True
2026-01-05 20:03:43,453   INFO  expert_policy    spl
2026-01-05 20:03:43,453   INFO  num_pano_layers  2
2026-01-05 20:03:43,453   INFO  ----------- Feature -----------
2026-01-05 20:03:43,453   INFO  cfg.Feature.object_feature_type: 
2026-01-05 20:03:43,453   INFO  cfg.Feature.angle_feat_size: 4
2026-01-05 20:03:43,453   INFO  cfg.Feature.max_objects: 70
2026-01-05 20:03:43,453   INFO  cfg.Feature.image_feat_size: 1024
2026-01-05 20:03:43,453   INFO  ----------- feature_database -----------
2026-01-05 20:03:43,453   INFO  cfg.Feature.feature_database.mp3d: eva_features/mp3d_EVA02-CLIP-L-14-336.hdf5
2026-01-05 20:03:43,453   INFO  cfg.Feature.feature_database.scan_qa: eva_features/scanqa_EVA02-CLIP-L-14-336.hdf5
2026-01-05 20:03:43,454   INFO  cfg.Feature.feature_database.room_tour: eva_features/web_obj_prog_p1_EVA02-CLIP-L-14-336.hdf5.bak
2026-01-05 20:03:43,454   INFO  cfg.Feature.feature_database.room3d_tour: eva_features/web_3d_obj_prog_crop_p1_EVA02-CLIP-L-14-336.hdf5
2026-01-05 20:03:43,454   INFO  cfg.Feature.feature_database.coco: eva_features/coco_EVA02-CLIP-L-14-336.hdf5
2026-01-05 20:03:43,454   INFO  cfg.Feature.obj_feat_size: 768
2026-01-05 20:03:43,454   INFO  ----------- object_database -----------
2026-01-05 20:03:43,454   INFO  cfg.Feature.object_database.reverie: obj_features/reverie_obj_feat
2026-01-05 20:03:43,454   INFO  cfg.Feature.object_database.soon: obj_features/soon_obj_feat
2026-01-05 20:03:43,454   INFO  ----------- Dataset -----------
2026-01-05 20:03:43,454   INFO  ----------- R2R -----------
2026-01-05 20:03:43,454   INFO  cfg.Dataset.R2R.DIR: R2R
2026-01-05 20:03:43,454   INFO  ----------- SPLIT -----------
2026-01-05 20:03:43,454   INFO  cfg.Dataset.R2R.SPLIT.train: FGR2R_train.json
2026-01-05 20:03:43,454   INFO  cfg.Dataset.R2R.SPLIT.val_seen: R2R_val_seen_enc.json
2026-01-05 20:03:43,454   INFO  cfg.Dataset.R2R.SPLIT.val_unseen: R2R_val_unseen_enc.json
2026-01-05 20:03:43,454   INFO  cfg.Dataset.R2R.SPLIT.test: R2R_test_enc.json
2026-01-05 20:03:43,454   INFO  ----------- REVERIE -----------
2026-01-05 20:03:43,454   INFO  cfg.Dataset.REVERIE.DIR: REVERIE
2026-01-05 20:03:43,454   INFO  cfg.Dataset.REVERIE.bbox_file: BBoxes.json
2026-01-05 20:03:43,454   INFO  ----------- SPLIT -----------
2026-01-05 20:03:43,454   INFO  cfg.Dataset.REVERIE.SPLIT.train: REVERIE_train_enc.json
2026-01-05 20:03:43,455   INFO  cfg.Dataset.REVERIE.SPLIT.val_seen: REVERIE_val_seen_enc.json
2026-01-05 20:03:43,455   INFO  cfg.Dataset.REVERIE.SPLIT.val_unseen: REVERIE_val_unseen_enc.json
2026-01-05 20:03:43,455   INFO  cfg.Dataset.REVERIE.SPLIT.test: REVERIE_test_enc.json
2026-01-05 20:03:43,455   INFO  ----------- CVDN -----------
2026-01-05 20:03:43,455   INFO  cfg.Dataset.CVDN.DIR: CVDN
2026-01-05 20:03:43,455   INFO  ----------- SPLIT -----------
2026-01-05 20:03:43,455   INFO  cfg.Dataset.CVDN.SPLIT.train: train.json
2026-01-05 20:03:43,455   INFO  cfg.Dataset.CVDN.SPLIT.val_seen: val_seen.json
2026-01-05 20:03:43,455   INFO  cfg.Dataset.CVDN.SPLIT.val_unseen: val_unseen.json
2026-01-05 20:03:43,455   INFO  cfg.Dataset.CVDN.SPLIT.test: test_cleaned.json
2026-01-05 20:03:43,455   INFO  ----------- SOON -----------
2026-01-05 20:03:43,455   INFO  cfg.Dataset.SOON.DIR: SOON
2026-01-05 20:03:43,455   INFO  ----------- SPLIT -----------
2026-01-05 20:03:43,455   INFO  cfg.Dataset.SOON.SPLIT.train: train_enc_pseudo_obj_ade30k_label.jsonl
2026-01-05 20:03:43,455   INFO  cfg.Dataset.SOON.SPLIT.val_seen: val_unseen_instrs_enc_pseudo_obj_ade30k_label.jsonl
2026-01-05 20:03:43,455   INFO  cfg.Dataset.SOON.SPLIT.val_unseen: val_unseen_house_enc_pseudo_obj_ade30k_label.jsonl
2026-01-05 20:03:43,455   INFO  cfg.Dataset.SOON.SPLIT.test: test_v2_enc.jsonl
2026-01-05 20:03:43,455   INFO  ----------- ScanQA -----------
2026-01-05 20:03:43,456   INFO  cfg.Dataset.ScanQA.DIR: ScanQA
2026-01-05 20:03:43,456   INFO  ----------- SPLIT -----------
2026-01-05 20:03:43,456   INFO  cfg.Dataset.ScanQA.SPLIT.train: ScanQA_v1.0_train_reformat.json
2026-01-05 20:03:43,456   INFO  cfg.Dataset.ScanQA.SPLIT.val_unseen: ScanQA_v1.0_val_reformat.json
2026-01-05 20:03:43,456   INFO  cfg.Dataset.ScanQA.SPLIT.test_wo_obj: ScanQA_v1.0_test_wo_obj_reformat.json
2026-01-05 20:03:43,456   INFO  cfg.Dataset.ScanQA.SPLIT.test_w_obj: ScanQA_v1.0_test_w_obj_reformat.json
2026-01-05 20:03:43,456   INFO  ----------- RoomTour -----------
2026-01-05 20:03:43,456   INFO  cfg.Dataset.RoomTour.DIR: RoomTour
2026-01-05 20:03:43,456   INFO  ----------- SPLIT -----------
2026-01-05 20:03:43,456   INFO  cfg.Dataset.RoomTour.SPLIT.train: p1_train_reformat.json
2026-01-05 20:03:43,456   INFO  ----------- Tour3D -----------
2026-01-05 20:03:43,456   INFO  cfg.Dataset.Tour3D.DIR: RoomTour
2026-01-05 20:03:43,456   INFO  ----------- SPLIT -----------
2026-01-05 20:03:43,456   INFO  cfg.Dataset.Tour3D.SPLIT.train: p1_train_colmap_trajectory_tour3d.json
2026-01-05 20:03:43,456   INFO  ----------- EQA -----------
2026-01-05 20:03:43,456   INFO  cfg.Dataset.EQA.DIR: EQA_MP3D
2026-01-05 20:03:43,456   INFO  ----------- SPLIT -----------
2026-01-05 20:03:43,456   INFO  cfg.Dataset.EQA.SPLIT.val_unseen: eqa_val_enc.json
2026-01-05 20:03:43,456   INFO  cfg.Dataset.EQA.ANSWER_VOCAB: eqa_answer_vocab.json
2026-01-05 20:03:43,456   INFO  ----------- R2R_AUG -----------
2026-01-05 20:03:43,457   INFO  cfg.Dataset.R2R_AUG.DIR: R2R
2026-01-05 20:03:43,457   INFO  ----------- SPLIT -----------
2026-01-05 20:03:43,457   INFO  cfg.Dataset.R2R_AUG.SPLIT.train: R2R_prevalent_aug_train_enc.jsonl
2026-01-05 20:03:43,457   INFO  ----------- REVERIE_AUG -----------
2026-01-05 20:03:43,457   INFO  cfg.Dataset.REVERIE_AUG.DIR: REVERIE
2026-01-05 20:03:43,457   INFO  cfg.Dataset.REVERIE_AUG.bbox_file: BBoxes.json
2026-01-05 20:03:43,457   INFO  ----------- SPLIT -----------
2026-01-05 20:03:43,457   INFO  cfg.Dataset.REVERIE_AUG.SPLIT.train: REVERIE_speaker_aug_enc.jsonl
2026-01-05 20:03:43,457   INFO  ----------- LLaVA -----------
2026-01-05 20:03:43,457   INFO  cfg.Dataset.LLaVA.DIR: LLaVA
2026-01-05 20:03:43,457   INFO  ----------- SPLIT -----------
2026-01-05 20:03:43,457   INFO  cfg.Dataset.LLaVA.SPLIT.train: detail_23k.json
2026-01-05 20:03:43,457   INFO  ----------- Pretrain -----------
2026-01-05 20:03:43,457   INFO  cfg.Pretrain.SOURCE: ['Tour3D', 'RoomTour', 'ScanQA', 'LLaVA']
2026-01-05 20:03:43,457   INFO  cfg.Pretrain.Ratio: [10, 20, 5, 2]
2026-01-05 20:03:43,457   INFO  ----------- LOSS_COEF -----------
2026-01-05 20:03:43,457   INFO  cfg.Pretrain.LOSS_COEF.R2R_AUG: 1
2026-01-05 20:03:43,457   INFO  cfg.Pretrain.LOSS_COEF.REVERIE_AUG: 1
2026-01-05 20:03:43,457   INFO  ----------- Multi -----------
2026-01-05 20:03:43,457   INFO  cfg.Multi.SOURCE: ['Tour3D', 'R2R', 'REVERIE', 'CVDN', 'SOON', 'ScanQA', 'LLaVA']
2026-01-05 20:03:43,458   INFO  cfg.Multi.Ratio: [10, 20, 5, 1, 5, 5, 5]
2026-01-05 20:03:43,458   INFO  ----------- LOSS_COEF -----------
2026-01-05 20:03:43,458   INFO  ----------- Model -----------
2026-01-05 20:03:43,458   INFO  cfg.Model.num_l_layers: 9
2026-01-05 20:03:43,458   INFO  cfg.Model.num_pano_layers: 2
2026-01-05 20:03:43,458   INFO  cfg.Model.num_x_layers: 4
2026-01-05 20:03:43,458   INFO  cfg.Model.graph_sprels: True
2026-01-05 20:03:43,458   INFO  cfg.Model.fusion: dynamic
2026-01-05 20:03:43,458   INFO  cfg.Model.enc_full_graph: True
2026-01-05 20:03:43,458   INFO  cfg.Model.expert_policy: spl
2026-01-05 20:03:43,458   INFO  ----------- Optim -----------
2026-01-05 20:03:43,458   INFO  ----------- val_max_action_len -----------
2026-01-05 20:03:43,458   INFO  cfg.Optim.val_max_action_len.R2R: 15
2026-01-05 20:03:43,458   INFO  cfg.Optim.val_max_action_len.REVERIE: 15
2026-01-05 20:03:43,458   INFO  cfg.Optim.val_max_action_len.CVDN: 30
2026-01-05 20:03:43,458   INFO  cfg.Optim.val_max_action_len.SOON: 20
2026-01-05 20:03:43,458   INFO  cfg.Optim.val_max_action_len.EQA: 15
2026-01-05 20:03:43,458   INFO  ----------- train_max_action_len -----------
2026-01-05 20:03:43,458   INFO  cfg.Optim.train_max_action_len.R2R: 15
2026-01-05 20:03:43,458   INFO  cfg.Optim.train_max_action_len.Tour3D: 15
2026-01-05 20:03:43,459   INFO  cfg.Optim.train_max_action_len.REVERIE: 15
2026-01-05 20:03:43,459   INFO  cfg.Optim.train_max_action_len.CVDN: 15
2026-01-05 20:03:43,459   INFO  cfg.Optim.train_max_action_len.SOON: 15
2026-01-05 20:03:43,459   INFO  cfg.Optim.train_max_action_len.EQA: 15
2026-01-05 20:03:43,459   INFO  cfg.Optim.train_max_action_len.R2R_AUG: 15
2026-01-05 20:03:43,459   INFO  cfg.Optim.train_max_action_len.REVERIE_AUG: 15
2026-01-05 20:03:48,387   INFO  [INFO] SOONDataset loaded with 14110 instructions, using splits: test
2026-01-05 20:03:48,388   INFO  
- Dataset: load 14110 SOON samples
- Dataset: load test split: 14110 samples in total
- Dataset: load test split: 14 scans in total
2026-01-05 20:03:48,388   INFO  SOON: 14110 samples loaded
2026-01-05 20:03:48,566   INFO  Initialize the model from config.
2026-01-05 20:05:17,859   INFO  model type: torch.bfloat16
2026-01-05 20:05:17,862   INFO  Trainable params: lang_model.model.embed_tokens.weight,lang_model.model.layers.0.self_attn.q_proj.weight,lang_model.model.layers.0.self_attn.k_proj.weight,lang_model.model.layers.0.self_attn.v_proj.weight,lang_model.model.layers.0.self_attn.o_proj.weight,lang_model.model.layers.0.mlp.gate_proj.weight,lang_model.model.layers.0.mlp.down_proj.weight,lang_model.model.layers.0.mlp.up_proj.weight,lang_model.model.layers.0.input_layernorm.weight,lang_model.model.layers.0.post_attention_layernorm.weight,lang_model.model.layers.1.self_attn.q_proj.weight,lang_model.model.layers.1.self_attn.k_proj.weight,lang_model.model.layers.1.self_attn.v_proj.weight,lang_model.model.layers.1.self_attn.o_proj.weight,lang_model.model.layers.1.mlp.gate_proj.weight,lang_model.model.layers.1.mlp.down_proj.weight,lang_model.model.layers.1.mlp.up_proj.weight,lang_model.model.layers.1.input_layernorm.weight,lang_model.model.layers.1.post_attention_layernorm.weight,lang_model.model.layers.2.self_attn.q_proj.weight,lang_model.model.layers.2.self_attn.k_proj.weight,lang_model.model.layers.2.self_attn.v_proj.weight,lang_model.model.layers.2.self_attn.o_proj.weight,lang_model.model.layers.2.mlp.gate_proj.weight,lang_model.model.layers.2.mlp.down_proj.weight,lang_model.model.layers.2.mlp.up_proj.weight,lang_model.model.layers.2.input_layernorm.weight,lang_model.model.layers.2.post_attention_layernorm.weight,lang_model.model.layers.3.self_attn.q_proj.weight,lang_model.model.layers.3.self_attn.k_proj.weight,lang_model.model.layers.3.self_attn.v_proj.weight,lang_model.model.layers.3.self_attn.o_proj.weight,lang_model.model.layers.3.mlp.gate_proj.weight,lang_model.model.layers.3.mlp.down_proj.weight,lang_model.model.layers.3.mlp.up_proj.weight,lang_model.model.layers.3.input_layernorm.weight,lang_model.model.layers.3.post_attention_layernorm.weight,lang_model.model.layers.4.self_attn.q_proj.weight,lang_model.model.layers.4.self_attn.k_proj.weight,lang_model.model.layers.4.self_attn.v_proj.weight,lang_model.model.layers.4.self_attn.o_proj.weight,lang_model.model.layers.4.mlp.gate_proj.weight,lang_model.model.layers.4.mlp.down_proj.weight,lang_model.model.layers.4.mlp.up_proj.weight,lang_model.model.layers.4.input_layernorm.weight,lang_model.model.layers.4.post_attention_layernorm.weight,lang_model.model.layers.5.self_attn.q_proj.weight,lang_model.model.layers.5.self_attn.k_proj.weight,lang_model.model.layers.5.self_attn.v_proj.weight,lang_model.model.layers.5.self_attn.o_proj.weight,lang_model.model.layers.5.mlp.gate_proj.weight,lang_model.model.layers.5.mlp.down_proj.weight,lang_model.model.layers.5.mlp.up_proj.weight,lang_model.model.layers.5.input_layernorm.weight,lang_model.model.layers.5.post_attention_layernorm.weight,lang_model.model.layers.6.self_attn.q_proj.weight,lang_model.model.layers.6.self_attn.k_proj.weight,lang_model.model.layers.6.self_attn.v_proj.weight,lang_model.model.layers.6.self_attn.o_proj.weight,lang_model.model.layers.6.mlp.gate_proj.weight,lang_model.model.layers.6.mlp.down_proj.weight,lang_model.model.layers.6.mlp.up_proj.weight,lang_model.model.layers.6.input_layernorm.weight,lang_model.model.layers.6.post_attention_layernorm.weight,lang_model.model.layers.7.self_attn.q_proj.weight,lang_model.model.layers.7.self_attn.k_proj.weight,lang_model.model.layers.7.self_attn.v_proj.weight,lang_model.model.layers.7.self_attn.o_proj.weight,lang_model.model.layers.7.mlp.gate_proj.weight,lang_model.model.layers.7.mlp.down_proj.weight,lang_model.model.layers.7.mlp.up_proj.weight,lang_model.model.layers.7.input_layernorm.weight,lang_model.model.layers.7.post_attention_layernorm.weight,lang_model.model.layers.8.self_attn.q_proj.weight,lang_model.model.layers.8.self_attn.k_proj.weight,lang_model.model.layers.8.self_attn.v_proj.weight,lang_model.model.layers.8.self_attn.o_proj.weight,lang_model.model.layers.8.mlp.gate_proj.weight,lang_model.model.layers.8.mlp.down_proj.weight,lang_model.model.layers.8.mlp.up_proj.weight,lang_model.model.layers.8.input_layernorm.weight,lang_model.model.layers.8.post_attention_layernorm.weight,lang_model.model.layers.9.self_attn.q_proj.weight,lang_model.model.layers.9.self_attn.k_proj.weight,lang_model.model.layers.9.self_attn.v_proj.weight,lang_model.model.layers.9.self_attn.o_proj.weight,lang_model.model.layers.9.mlp.gate_proj.weight,lang_model.model.layers.9.mlp.down_proj.weight,lang_model.model.layers.9.mlp.up_proj.weight,lang_model.model.layers.9.input_layernorm.weight,lang_model.model.layers.9.post_attention_layernorm.weight,lang_model.model.layers.10.self_attn.q_proj.weight,lang_model.model.layers.10.self_attn.k_proj.weight,lang_model.model.layers.10.self_attn.v_proj.weight,lang_model.model.layers.10.self_attn.o_proj.weight,lang_model.model.layers.10.mlp.gate_proj.weight,lang_model.model.layers.10.mlp.down_proj.weight,lang_model.model.layers.10.mlp.up_proj.weight,lang_model.model.layers.10.input_layernorm.weight,lang_model.model.layers.10.post_attention_layernorm.weight,lang_model.model.layers.11.self_attn.q_proj.weight,lang_model.model.layers.11.self_attn.k_proj.weight,lang_model.model.layers.11.self_attn.v_proj.weight,lang_model.model.layers.11.self_attn.o_proj.weight,lang_model.model.layers.11.mlp.gate_proj.weight,lang_model.model.layers.11.mlp.down_proj.weight,lang_model.model.layers.11.mlp.up_proj.weight,lang_model.model.layers.11.input_layernorm.weight,lang_model.model.layers.11.post_attention_layernorm.weight,lang_model.model.layers.12.self_attn.q_proj.weight,lang_model.model.layers.12.self_attn.k_proj.weight,lang_model.model.layers.12.self_attn.v_proj.weight,lang_model.model.layers.12.self_attn.o_proj.weight,lang_model.model.layers.12.mlp.gate_proj.weight,lang_model.model.layers.12.mlp.down_proj.weight,lang_model.model.layers.12.mlp.up_proj.weight,lang_model.model.layers.12.input_layernorm.weight,lang_model.model.layers.12.post_attention_layernorm.weight,lang_model.model.layers.13.self_attn.q_proj.weight,lang_model.model.layers.13.self_attn.k_proj.weight,lang_model.model.layers.13.self_attn.v_proj.weight,lang_model.model.layers.13.self_attn.o_proj.weight,lang_model.model.layers.13.mlp.gate_proj.weight,lang_model.model.layers.13.mlp.down_proj.weight,lang_model.model.layers.13.mlp.up_proj.weight,lang_model.model.layers.13.input_layernorm.weight,lang_model.model.layers.13.post_attention_layernorm.weight,lang_model.model.layers.14.self_attn.q_proj.weight,lang_model.model.layers.14.self_attn.k_proj.weight,lang_model.model.layers.14.self_attn.v_proj.weight,lang_model.model.layers.14.self_attn.o_proj.weight,lang_model.model.layers.14.mlp.gate_proj.weight,lang_model.model.layers.14.mlp.down_proj.weight,lang_model.model.layers.14.mlp.up_proj.weight,lang_model.model.layers.14.input_layernorm.weight,lang_model.model.layers.14.post_attention_layernorm.weight,lang_model.model.layers.15.self_attn.q_proj.weight,lang_model.model.layers.15.self_attn.k_proj.weight,lang_model.model.layers.15.self_attn.v_proj.weight,lang_model.model.layers.15.self_attn.o_proj.weight,lang_model.model.layers.15.mlp.gate_proj.weight,lang_model.model.layers.15.mlp.down_proj.weight,lang_model.model.layers.15.mlp.up_proj.weight,lang_model.model.layers.15.input_layernorm.weight,lang_model.model.layers.15.post_attention_layernorm.weight,lang_model.model.layers.16.self_attn.q_proj.weight,lang_model.model.layers.16.self_attn.k_proj.weight,lang_model.model.layers.16.self_attn.v_proj.weight,lang_model.model.layers.16.self_attn.o_proj.weight,lang_model.model.layers.16.mlp.gate_proj.weight,lang_model.model.layers.16.mlp.down_proj.weight,lang_model.model.layers.16.mlp.up_proj.weight,lang_model.model.layers.16.input_layernorm.weight,lang_model.model.layers.16.post_attention_layernorm.weight,lang_model.model.layers.17.self_attn.q_proj.weight,lang_model.model.layers.17.self_attn.k_proj.weight,lang_model.model.layers.17.self_attn.v_proj.weight,lang_model.model.layers.17.self_attn.o_proj.weight,lang_model.model.layers.17.mlp.gate_proj.weight,lang_model.model.layers.17.mlp.down_proj.weight,lang_model.model.layers.17.mlp.up_proj.weight,lang_model.model.layers.17.input_layernorm.weight,lang_model.model.layers.17.post_attention_layernorm.weight,lang_model.model.layers.18.self_attn.q_proj.weight,lang_model.model.layers.18.self_attn.k_proj.weight,lang_model.model.layers.18.self_attn.v_proj.weight,lang_model.model.layers.18.self_attn.o_proj.weight,lang_model.model.layers.18.mlp.gate_proj.weight,lang_model.model.layers.18.mlp.down_proj.weight,lang_model.model.layers.18.mlp.up_proj.weight,lang_model.model.layers.18.input_layernorm.weight,lang_model.model.layers.18.post_attention_layernorm.weight,lang_model.model.layers.19.self_attn.q_proj.weight,lang_model.model.layers.19.self_attn.k_proj.weight,lang_model.model.layers.19.self_attn.v_proj.weight,lang_model.model.layers.19.self_attn.o_proj.weight,lang_model.model.layers.19.mlp.gate_proj.weight,lang_model.model.layers.19.mlp.down_proj.weight,lang_model.model.layers.19.mlp.up_proj.weight,lang_model.model.layers.19.input_layernorm.weight,lang_model.model.layers.19.post_attention_layernorm.weight,lang_model.model.layers.20.self_attn.q_proj.weight,lang_model.model.layers.20.self_attn.k_proj.weight,lang_model.model.layers.20.self_attn.v_proj.weight,lang_model.model.layers.20.self_attn.o_proj.weight,lang_model.model.layers.20.mlp.gate_proj.weight,lang_model.model.layers.20.mlp.down_proj.weight,lang_model.model.layers.20.mlp.up_proj.weight,lang_model.model.layers.20.input_layernorm.weight,lang_model.model.layers.20.post_attention_layernorm.weight,lang_model.model.layers.21.self_attn.q_proj.weight,lang_model.model.layers.21.self_attn.k_proj.weight,lang_model.model.layers.21.self_attn.v_proj.weight,lang_model.model.layers.21.self_attn.o_proj.weight,lang_model.model.layers.21.mlp.gate_proj.weight,lang_model.model.layers.21.mlp.down_proj.weight,lang_model.model.layers.21.mlp.up_proj.weight,lang_model.model.layers.21.input_layernorm.weight,lang_model.model.layers.21.post_attention_layernorm.weight,lang_model.model.layers.22.self_attn.q_proj.weight,lang_model.model.layers.22.self_attn.k_proj.weight,lang_model.model.layers.22.self_attn.v_proj.weight,lang_model.model.layers.22.self_attn.o_proj.weight,lang_model.model.layers.22.mlp.gate_proj.weight,lang_model.model.layers.22.mlp.down_proj.weight,lang_model.model.layers.22.mlp.up_proj.weight,lang_model.model.layers.22.input_layernorm.weight,lang_model.model.layers.22.post_attention_layernorm.weight,lang_model.model.layers.23.self_attn.q_proj.weight,lang_model.model.layers.23.self_attn.k_proj.weight,lang_model.model.layers.23.self_attn.v_proj.weight,lang_model.model.layers.23.self_attn.o_proj.weight,lang_model.model.layers.23.mlp.gate_proj.weight,lang_model.model.layers.23.mlp.down_proj.weight,lang_model.model.layers.23.mlp.up_proj.weight,lang_model.model.layers.23.input_layernorm.weight,lang_model.model.layers.23.post_attention_layernorm.weight,lang_model.model.layers.24.self_attn.q_proj.weight,lang_model.model.layers.24.self_attn.k_proj.weight,lang_model.model.layers.24.self_attn.v_proj.weight,lang_model.model.layers.24.self_attn.o_proj.weight,lang_model.model.layers.24.mlp.gate_proj.weight,lang_model.model.layers.24.mlp.down_proj.weight,lang_model.model.layers.24.mlp.up_proj.weight,lang_model.model.layers.24.input_layernorm.weight,lang_model.model.layers.24.post_attention_layernorm.weight,lang_model.model.layers.25.self_attn.q_proj.weight,lang_model.model.layers.25.self_attn.k_proj.weight,lang_model.model.layers.25.self_attn.v_proj.weight,lang_model.model.layers.25.self_attn.o_proj.weight,lang_model.model.layers.25.mlp.gate_proj.weight,lang_model.model.layers.25.mlp.down_proj.weight,lang_model.model.layers.25.mlp.up_proj.weight,lang_model.model.layers.25.input_layernorm.weight,lang_model.model.layers.25.post_attention_layernorm.weight,lang_model.model.layers.26.self_attn.q_proj.weight,lang_model.model.layers.26.self_attn.k_proj.weight,lang_model.model.layers.26.self_attn.v_proj.weight,lang_model.model.layers.26.self_attn.o_proj.weight,lang_model.model.layers.26.mlp.gate_proj.weight,lang_model.model.layers.26.mlp.down_proj.weight,lang_model.model.layers.26.mlp.up_proj.weight,lang_model.model.layers.26.input_layernorm.weight,lang_model.model.layers.26.post_attention_layernorm.weight,lang_model.model.layers.27.self_attn.q_proj.weight,lang_model.model.layers.27.self_attn.k_proj.weight,lang_model.model.layers.27.self_attn.v_proj.weight,lang_model.model.layers.27.self_attn.o_proj.weight,lang_model.model.layers.27.mlp.gate_proj.weight,lang_model.model.layers.27.mlp.down_proj.weight,lang_model.model.layers.27.mlp.up_proj.weight,lang_model.model.layers.27.input_layernorm.weight,lang_model.model.layers.27.post_attention_layernorm.weight,lang_model.model.layers.28.self_attn.q_proj.weight,lang_model.model.layers.28.self_attn.k_proj.weight,lang_model.model.layers.28.self_attn.v_proj.weight,lang_model.model.layers.28.self_attn.o_proj.weight,lang_model.model.layers.28.mlp.gate_proj.weight,lang_model.model.layers.28.mlp.down_proj.weight,lang_model.model.layers.28.mlp.up_proj.weight,lang_model.model.layers.28.input_layernorm.weight,lang_model.model.layers.28.post_attention_layernorm.weight,lang_model.model.layers.29.self_attn.q_proj.weight,lang_model.model.layers.29.self_attn.k_proj.weight,lang_model.model.layers.29.self_attn.v_proj.weight,lang_model.model.layers.29.self_attn.o_proj.weight,lang_model.model.layers.29.mlp.gate_proj.weight,lang_model.model.layers.29.mlp.down_proj.weight,lang_model.model.layers.29.mlp.up_proj.weight,lang_model.model.layers.29.input_layernorm.weight,lang_model.model.layers.29.post_attention_layernorm.weight,lang_model.model.layers.30.self_attn.q_proj.weight,lang_model.model.layers.30.self_attn.k_proj.weight,lang_model.model.layers.30.self_attn.v_proj.weight,lang_model.model.layers.30.self_attn.o_proj.weight,lang_model.model.layers.30.mlp.gate_proj.weight,lang_model.model.layers.30.mlp.down_proj.weight,lang_model.model.layers.30.mlp.up_proj.weight,lang_model.model.layers.30.input_layernorm.weight,lang_model.model.layers.30.post_attention_layernorm.weight,lang_model.model.layers.31.self_attn.q_proj.weight,lang_model.model.layers.31.self_attn.k_proj.weight,lang_model.model.layers.31.self_attn.v_proj.weight,lang_model.model.layers.31.self_attn.o_proj.weight,lang_model.model.layers.31.mlp.gate_proj.weight,lang_model.model.layers.31.mlp.down_proj.weight,lang_model.model.layers.31.mlp.up_proj.weight,lang_model.model.layers.31.input_layernorm.weight,lang_model.model.layers.31.post_attention_layernorm.weight,lang_model.model.norm.weight,lang_model.lm_head.weight,img_embeddings.img_linear.weight,img_embeddings.img_linear.bias,img_embeddings.img_layer_norm.weight,img_embeddings.img_layer_norm.bias,img_embeddings.loc_linear.weight,img_embeddings.loc_linear.bias,img_embeddings.loc_layer_norm.weight,img_embeddings.loc_layer_norm.bias,img_embeddings.obj_projector.0.weight,img_embeddings.obj_projector.0.bias,img_embeddings.obj_projector.1.weight,img_embeddings.obj_projector.1.bias,img_embeddings.nav_type_embedding.weight,img_embeddings.layer_norm.weight,img_embeddings.layer_norm.bias,img_embeddings.pano_encoder.layers.0.self_attn.in_proj_weight,img_embeddings.pano_encoder.layers.0.self_attn.in_proj_bias,img_embeddings.pano_encoder.layers.0.self_attn.out_proj.weight,img_embeddings.pano_encoder.layers.0.self_attn.out_proj.bias,img_embeddings.pano_encoder.layers.0.linear1.weight,img_embeddings.pano_encoder.layers.0.linear1.bias,img_embeddings.pano_encoder.layers.0.linear2.weight,img_embeddings.pano_encoder.layers.0.linear2.bias,img_embeddings.pano_encoder.layers.0.norm1.weight,img_embeddings.pano_encoder.layers.0.norm1.bias,img_embeddings.pano_encoder.layers.0.norm2.weight,img_embeddings.pano_encoder.layers.0.norm2.bias,img_embeddings.pano_encoder.layers.1.self_attn.in_proj_weight,img_embeddings.pano_encoder.layers.1.self_attn.in_proj_bias,img_embeddings.pano_encoder.layers.1.self_attn.out_proj.weight,img_embeddings.pano_encoder.layers.1.self_attn.out_proj.bias,img_embeddings.pano_encoder.layers.1.linear1.weight,img_embeddings.pano_encoder.layers.1.linear1.bias,img_embeddings.pano_encoder.layers.1.linear2.weight,img_embeddings.pano_encoder.layers.1.linear2.bias,img_embeddings.pano_encoder.layers.1.norm1.weight,img_embeddings.pano_encoder.layers.1.norm1.bias,img_embeddings.pano_encoder.layers.1.norm2.weight,img_embeddings.pano_encoder.layers.1.norm2.bias,img_embeddings.pano_encoder.norm.weight,img_embeddings.pano_encoder.norm.bias,img_embeddings.mapper.weight,img_embeddings.mapper.bias,token_type_embeddings.weight,gmap_pos_embeddings.0.weight,gmap_pos_embeddings.0.bias,gmap_pos_embeddings.1.weight,gmap_pos_embeddings.1.bias,gmap_step_embeddings.weight,vp_pos_embeddings.0.weight,vp_pos_embeddings.0.bias,vp_pos_embeddings.1.weight,vp_pos_embeddings.1.bias,obj_pos_embeddings.0.weight,obj_pos_embeddings.0.bias,obj_pos_embeddings.1.weight,obj_pos_embeddings.1.bias,og_head.0.weight,og_head.0.bias,out_head.0.weight,out_head.0.bias
2026-01-05 20:05:17,862   INFO  *************** init model *************** 
2026-01-05 20:05:20,549   INFO  Loading checkpoint from /data/wanghaoxuan/model_with_pretrain.pt
2026-01-05 20:05:26,046   INFO  <All keys matched successfully>
2026-01-05 20:05:26,381   INFO  model initialized with 6773.48 M trainable parameters
2026-01-05 20:05:26,381   INFO  Training with a single process
2026-01-05 20:05:26,381   INFO  **************************** Test ****************************
2026-01-05 20:05:26,383   INFO  ***** validate test split on SOON task *****
2026-01-05 20:10:20,131   INFO  **********************Start logging**********************
2026-01-05 20:10:20,132   INFO  CUDA_VISIBLE_DEVICES=0
2026-01-05 20:10:20,132   INFO  data_dir         /data/wanghaoxuan/data
2026-01-05 20:10:20,132   INFO  cfg_file         configs/multi.yaml
2026-01-05 20:10:20,132   INFO  pretrained_model_name_or_path /data/wanghaoxuan/data/models/Vicuna-7B
2026-01-05 20:10:20,132   INFO  off_batch_task   False
2026-01-05 20:10:20,132   INFO  debug            False
2026-01-05 20:10:20,132   INFO  few_shot         None
2026-01-05 20:10:20,132   INFO  tour3d_nav_head  False
2026-01-05 20:10:20,132   INFO  seed             0
2026-01-05 20:10:20,132   INFO  num_epochs       30
2026-01-05 20:10:20,132   INFO  resume_from_checkpoint /data/wanghaoxuan/model_with_pretrain.pt
2026-01-05 20:10:20,132   INFO  from_scratch     False
2026-01-05 20:10:20,132   INFO  batch_size       4
2026-01-05 20:10:20,132   INFO  val_batch_size   2
2026-01-05 20:10:20,132   INFO  lr               1e-05
2026-01-05 20:10:20,133   INFO  feat_dropout     0.4
2026-01-05 20:10:20,133   INFO  num_warmup_steps 0
2026-01-05 20:10:20,133   INFO  num_steps_per_epoch -1
2026-01-05 20:10:20,133   INFO  gradient_accumulation_step 2
2026-01-05 20:10:20,133   INFO  precision        amp_bf16
2026-01-05 20:10:20,133   INFO  workers          0
2026-01-05 20:10:20,133   INFO  gpu              0
2026-01-05 20:10:20,133   INFO  world_size       1
2026-01-05 20:10:20,133   INFO  local_rank       0
2026-01-05 20:10:20,133   INFO  dist_url         env://
2026-01-05 20:10:20,133   INFO  dist_backend     nccl
2026-01-05 20:10:20,133   INFO  horovod          False
2026-01-05 20:10:20,133   INFO  no_set_device_rank False
2026-01-05 20:10:20,133   INFO  output_dir       build/eval
2026-01-05 20:10:20,133   INFO  max_saved_checkpoints 0
2026-01-05 20:10:20,133   INFO  save_ckpt_per_epochs 10
2026-01-05 20:10:20,133   INFO  save_latest_states False
2026-01-05 20:10:20,133   INFO  save_pred_results False
2026-01-05 20:10:20,133   INFO  save_detail_results False
2026-01-05 20:10:20,133   INFO  mode             test
2026-01-05 20:10:20,134   INFO  stage            multi
2026-01-05 20:10:20,134   INFO  ignoreid         -100
2026-01-05 20:10:20,134   INFO  enable_og        True
2026-01-05 20:10:20,134   INFO  enable_summarize False
2026-01-05 20:10:20,134   INFO  enable_fgr2r     False
2026-01-05 20:10:20,134   INFO  disable_nav      False
2026-01-05 20:10:20,134   INFO  gen_loss_coef    1.0
2026-01-05 20:10:20,134   INFO  obj_loss_coef    1.0
2026-01-05 20:10:20,134   INFO  teacher_forcing_coef 1.0
2026-01-05 20:10:20,134   INFO  fuse_obj         False
2026-01-05 20:10:20,134   INFO  use_lora         False
2026-01-05 20:10:20,134   INFO  lora_rank        8
2026-01-05 20:10:20,134   INFO  lora_alpha       16
2026-01-05 20:10:20,134   INFO  lora_dropout     0.05
2026-01-05 20:10:20,134   INFO  lora_target      None
2026-01-05 20:10:20,134   INFO  freeze_llama     False
2026-01-05 20:10:20,134   INFO  tune_token_emb   False
2026-01-05 20:10:20,134   INFO  no_loc_fts       False
2026-01-05 20:10:20,134   INFO  multi_endpoints  1
2026-01-05 20:10:20,134   INFO  path_type        trusted_path
2026-01-05 20:10:20,135   INFO  test_datasets    ['SOON']
2026-01-05 20:10:20,135   INFO  validation_split val_unseen
2026-01-05 20:10:20,135   INFO  do_sample        True
2026-01-05 20:10:20,135   INFO  temperature      0.01
2026-01-05 20:10:20,135   INFO  max_datapoints   None
2026-01-05 20:10:20,135   INFO  rank             0
2026-01-05 20:10:20,135   INFO  distributed      False
2026-01-05 20:10:20,135   INFO  device           cuda:0
2026-01-05 20:10:20,135   INFO  image_feat_size  1024
2026-01-05 20:10:20,135   INFO  obj_feat_size    768
2026-01-05 20:10:20,135   INFO  angle_feat_size  4
2026-01-05 20:10:20,135   INFO  enc_full_graph   True
2026-01-05 20:10:20,135   INFO  expert_policy    spl
2026-01-05 20:10:20,135   INFO  num_pano_layers  2
2026-01-05 20:10:20,135   INFO  ----------- Feature -----------
2026-01-05 20:10:20,135   INFO  cfg.Feature.object_feature_type: 
2026-01-05 20:10:20,135   INFO  cfg.Feature.angle_feat_size: 4
2026-01-05 20:10:20,135   INFO  cfg.Feature.max_objects: 70
2026-01-05 20:10:20,135   INFO  cfg.Feature.image_feat_size: 1024
2026-01-05 20:10:20,135   INFO  ----------- feature_database -----------
2026-01-05 20:10:20,136   INFO  cfg.Feature.feature_database.mp3d: eva_features/mp3d_EVA02-CLIP-L-14-336.hdf5
2026-01-05 20:10:20,136   INFO  cfg.Feature.feature_database.scan_qa: eva_features/scanqa_EVA02-CLIP-L-14-336.hdf5
2026-01-05 20:10:20,136   INFO  cfg.Feature.feature_database.room_tour: eva_features/web_obj_prog_p1_EVA02-CLIP-L-14-336.hdf5.bak
2026-01-05 20:10:20,136   INFO  cfg.Feature.feature_database.room3d_tour: eva_features/web_3d_obj_prog_crop_p1_EVA02-CLIP-L-14-336.hdf5
2026-01-05 20:10:20,136   INFO  cfg.Feature.feature_database.coco: eva_features/coco_EVA02-CLIP-L-14-336.hdf5
2026-01-05 20:10:20,136   INFO  cfg.Feature.obj_feat_size: 768
2026-01-05 20:10:20,136   INFO  ----------- object_database -----------
2026-01-05 20:10:20,136   INFO  cfg.Feature.object_database.reverie: obj_features/reverie_obj_feat
2026-01-05 20:10:20,136   INFO  cfg.Feature.object_database.soon: obj_features/soon_obj_feat
2026-01-05 20:10:20,136   INFO  ----------- Dataset -----------
2026-01-05 20:10:20,136   INFO  ----------- R2R -----------
2026-01-05 20:10:20,136   INFO  cfg.Dataset.R2R.DIR: R2R
2026-01-05 20:10:20,136   INFO  ----------- SPLIT -----------
2026-01-05 20:10:20,136   INFO  cfg.Dataset.R2R.SPLIT.train: FGR2R_train.json
2026-01-05 20:10:20,136   INFO  cfg.Dataset.R2R.SPLIT.val_seen: R2R_val_seen_enc.json
2026-01-05 20:10:20,136   INFO  cfg.Dataset.R2R.SPLIT.val_unseen: R2R_val_unseen_enc.json
2026-01-05 20:10:20,136   INFO  cfg.Dataset.R2R.SPLIT.test: R2R_test_enc.json
2026-01-05 20:10:20,136   INFO  ----------- REVERIE -----------
2026-01-05 20:10:20,136   INFO  cfg.Dataset.REVERIE.DIR: REVERIE
2026-01-05 20:10:20,136   INFO  cfg.Dataset.REVERIE.bbox_file: BBoxes.json
2026-01-05 20:10:20,137   INFO  ----------- SPLIT -----------
2026-01-05 20:10:20,137   INFO  cfg.Dataset.REVERIE.SPLIT.train: REVERIE_train_enc.json
2026-01-05 20:10:20,137   INFO  cfg.Dataset.REVERIE.SPLIT.val_seen: REVERIE_val_seen_enc.json
2026-01-05 20:10:20,137   INFO  cfg.Dataset.REVERIE.SPLIT.val_unseen: REVERIE_val_unseen_enc.json
2026-01-05 20:10:20,137   INFO  cfg.Dataset.REVERIE.SPLIT.test: REVERIE_test_enc.json
2026-01-05 20:10:20,137   INFO  ----------- CVDN -----------
2026-01-05 20:10:20,137   INFO  cfg.Dataset.CVDN.DIR: CVDN
2026-01-05 20:10:20,137   INFO  ----------- SPLIT -----------
2026-01-05 20:10:20,137   INFO  cfg.Dataset.CVDN.SPLIT.train: train.json
2026-01-05 20:10:20,137   INFO  cfg.Dataset.CVDN.SPLIT.val_seen: val_seen.json
2026-01-05 20:10:20,137   INFO  cfg.Dataset.CVDN.SPLIT.val_unseen: val_unseen.json
2026-01-05 20:10:20,137   INFO  cfg.Dataset.CVDN.SPLIT.test: test_cleaned.json
2026-01-05 20:10:20,137   INFO  ----------- SOON -----------
2026-01-05 20:10:20,137   INFO  cfg.Dataset.SOON.DIR: SOON
2026-01-05 20:10:20,137   INFO  ----------- SPLIT -----------
2026-01-05 20:10:20,137   INFO  cfg.Dataset.SOON.SPLIT.train: train_enc_pseudo_obj_ade30k_label.jsonl
2026-01-05 20:10:20,137   INFO  cfg.Dataset.SOON.SPLIT.val_seen: val_unseen_instrs_enc_pseudo_obj_ade30k_label.jsonl
2026-01-05 20:10:20,137   INFO  cfg.Dataset.SOON.SPLIT.val_unseen: val_unseen_house_enc_pseudo_obj_ade30k_label.jsonl
2026-01-05 20:10:20,137   INFO  cfg.Dataset.SOON.SPLIT.test: test_v2_enc.jsonl
2026-01-05 20:10:20,137   INFO  ----------- ScanQA -----------
2026-01-05 20:10:20,138   INFO  cfg.Dataset.ScanQA.DIR: ScanQA
2026-01-05 20:10:20,138   INFO  ----------- SPLIT -----------
2026-01-05 20:10:20,138   INFO  cfg.Dataset.ScanQA.SPLIT.train: ScanQA_v1.0_train_reformat.json
2026-01-05 20:10:20,138   INFO  cfg.Dataset.ScanQA.SPLIT.val_unseen: ScanQA_v1.0_val_reformat.json
2026-01-05 20:10:20,138   INFO  cfg.Dataset.ScanQA.SPLIT.test_wo_obj: ScanQA_v1.0_test_wo_obj_reformat.json
2026-01-05 20:10:20,138   INFO  cfg.Dataset.ScanQA.SPLIT.test_w_obj: ScanQA_v1.0_test_w_obj_reformat.json
2026-01-05 20:10:20,138   INFO  ----------- RoomTour -----------
2026-01-05 20:10:20,138   INFO  cfg.Dataset.RoomTour.DIR: RoomTour
2026-01-05 20:10:20,138   INFO  ----------- SPLIT -----------
2026-01-05 20:10:20,138   INFO  cfg.Dataset.RoomTour.SPLIT.train: p1_train_reformat.json
2026-01-05 20:10:20,138   INFO  ----------- Tour3D -----------
2026-01-05 20:10:20,138   INFO  cfg.Dataset.Tour3D.DIR: RoomTour
2026-01-05 20:10:20,138   INFO  ----------- SPLIT -----------
2026-01-05 20:10:20,138   INFO  cfg.Dataset.Tour3D.SPLIT.train: p1_train_colmap_trajectory_tour3d.json
2026-01-05 20:10:20,138   INFO  ----------- EQA -----------
2026-01-05 20:10:20,138   INFO  cfg.Dataset.EQA.DIR: EQA_MP3D
2026-01-05 20:10:20,138   INFO  ----------- SPLIT -----------
2026-01-05 20:10:20,138   INFO  cfg.Dataset.EQA.SPLIT.val_unseen: eqa_val_enc.json
2026-01-05 20:10:20,138   INFO  cfg.Dataset.EQA.ANSWER_VOCAB: eqa_answer_vocab.json
2026-01-05 20:10:20,138   INFO  ----------- R2R_AUG -----------
2026-01-05 20:10:20,138   INFO  cfg.Dataset.R2R_AUG.DIR: R2R
2026-01-05 20:10:20,139   INFO  ----------- SPLIT -----------
2026-01-05 20:10:20,139   INFO  cfg.Dataset.R2R_AUG.SPLIT.train: R2R_prevalent_aug_train_enc.jsonl
2026-01-05 20:10:20,139   INFO  ----------- REVERIE_AUG -----------
2026-01-05 20:10:20,139   INFO  cfg.Dataset.REVERIE_AUG.DIR: REVERIE
2026-01-05 20:10:20,139   INFO  cfg.Dataset.REVERIE_AUG.bbox_file: BBoxes.json
2026-01-05 20:10:20,139   INFO  ----------- SPLIT -----------
2026-01-05 20:10:20,139   INFO  cfg.Dataset.REVERIE_AUG.SPLIT.train: REVERIE_speaker_aug_enc.jsonl
2026-01-05 20:10:20,139   INFO  ----------- LLaVA -----------
2026-01-05 20:10:20,139   INFO  cfg.Dataset.LLaVA.DIR: LLaVA
2026-01-05 20:10:20,139   INFO  ----------- SPLIT -----------
2026-01-05 20:10:20,139   INFO  cfg.Dataset.LLaVA.SPLIT.train: detail_23k.json
2026-01-05 20:10:20,139   INFO  ----------- Pretrain -----------
2026-01-05 20:10:20,139   INFO  cfg.Pretrain.SOURCE: ['Tour3D', 'RoomTour', 'ScanQA', 'LLaVA']
2026-01-05 20:10:20,139   INFO  cfg.Pretrain.Ratio: [10, 20, 5, 2]
2026-01-05 20:10:20,139   INFO  ----------- LOSS_COEF -----------
2026-01-05 20:10:20,139   INFO  cfg.Pretrain.LOSS_COEF.R2R_AUG: 1
2026-01-05 20:10:20,139   INFO  cfg.Pretrain.LOSS_COEF.REVERIE_AUG: 1
2026-01-05 20:10:20,139   INFO  ----------- Multi -----------
2026-01-05 20:10:20,139   INFO  cfg.Multi.SOURCE: ['Tour3D', 'R2R', 'REVERIE', 'CVDN', 'SOON', 'ScanQA', 'LLaVA']
2026-01-05 20:10:20,139   INFO  cfg.Multi.Ratio: [10, 20, 5, 1, 5, 5, 5]
2026-01-05 20:10:20,140   INFO  ----------- LOSS_COEF -----------
2026-01-05 20:10:20,140   INFO  ----------- Model -----------
2026-01-05 20:10:20,140   INFO  cfg.Model.num_l_layers: 9
2026-01-05 20:10:20,140   INFO  cfg.Model.num_pano_layers: 2
2026-01-05 20:10:20,140   INFO  cfg.Model.num_x_layers: 4
2026-01-05 20:10:20,140   INFO  cfg.Model.graph_sprels: True
2026-01-05 20:10:20,140   INFO  cfg.Model.fusion: dynamic
2026-01-05 20:10:20,140   INFO  cfg.Model.enc_full_graph: True
2026-01-05 20:10:20,140   INFO  cfg.Model.expert_policy: spl
2026-01-05 20:10:20,140   INFO  ----------- Optim -----------
2026-01-05 20:10:20,140   INFO  ----------- val_max_action_len -----------
2026-01-05 20:10:20,140   INFO  cfg.Optim.val_max_action_len.R2R: 15
2026-01-05 20:10:20,140   INFO  cfg.Optim.val_max_action_len.REVERIE: 15
2026-01-05 20:10:20,140   INFO  cfg.Optim.val_max_action_len.CVDN: 30
2026-01-05 20:10:20,140   INFO  cfg.Optim.val_max_action_len.SOON: 20
2026-01-05 20:10:20,140   INFO  cfg.Optim.val_max_action_len.EQA: 15
2026-01-05 20:10:20,140   INFO  ----------- train_max_action_len -----------
2026-01-05 20:10:20,140   INFO  cfg.Optim.train_max_action_len.R2R: 15
2026-01-05 20:10:20,140   INFO  cfg.Optim.train_max_action_len.Tour3D: 15
2026-01-05 20:10:20,140   INFO  cfg.Optim.train_max_action_len.REVERIE: 15
2026-01-05 20:10:20,141   INFO  cfg.Optim.train_max_action_len.CVDN: 15
2026-01-05 20:10:20,141   INFO  cfg.Optim.train_max_action_len.SOON: 15
2026-01-05 20:10:20,141   INFO  cfg.Optim.train_max_action_len.EQA: 15
2026-01-05 20:10:20,141   INFO  cfg.Optim.train_max_action_len.R2R_AUG: 15
2026-01-05 20:10:20,141   INFO  cfg.Optim.train_max_action_len.REVERIE_AUG: 15
2026-01-05 20:10:23,194   INFO  [INFO] SOONDataset loaded with 3390 instructions, using splits: val_unseen
2026-01-05 20:10:23,195   INFO  
- Dataset: load 3390 SOON samples
- Dataset: load val_unseen split: 3390 samples in total
- Dataset: load val_unseen split: 5 scans in total
2026-01-05 20:10:23,196   INFO  SOON: 3390 samples loaded
2026-01-05 20:10:23,295   INFO  Initialize the model from config.
2026-01-05 20:11:53,189   INFO  model type: torch.bfloat16
2026-01-05 20:11:53,192   INFO  Trainable params: lang_model.model.embed_tokens.weight,lang_model.model.layers.0.self_attn.q_proj.weight,lang_model.model.layers.0.self_attn.k_proj.weight,lang_model.model.layers.0.self_attn.v_proj.weight,lang_model.model.layers.0.self_attn.o_proj.weight,lang_model.model.layers.0.mlp.gate_proj.weight,lang_model.model.layers.0.mlp.down_proj.weight,lang_model.model.layers.0.mlp.up_proj.weight,lang_model.model.layers.0.input_layernorm.weight,lang_model.model.layers.0.post_attention_layernorm.weight,lang_model.model.layers.1.self_attn.q_proj.weight,lang_model.model.layers.1.self_attn.k_proj.weight,lang_model.model.layers.1.self_attn.v_proj.weight,lang_model.model.layers.1.self_attn.o_proj.weight,lang_model.model.layers.1.mlp.gate_proj.weight,lang_model.model.layers.1.mlp.down_proj.weight,lang_model.model.layers.1.mlp.up_proj.weight,lang_model.model.layers.1.input_layernorm.weight,lang_model.model.layers.1.post_attention_layernorm.weight,lang_model.model.layers.2.self_attn.q_proj.weight,lang_model.model.layers.2.self_attn.k_proj.weight,lang_model.model.layers.2.self_attn.v_proj.weight,lang_model.model.layers.2.self_attn.o_proj.weight,lang_model.model.layers.2.mlp.gate_proj.weight,lang_model.model.layers.2.mlp.down_proj.weight,lang_model.model.layers.2.mlp.up_proj.weight,lang_model.model.layers.2.input_layernorm.weight,lang_model.model.layers.2.post_attention_layernorm.weight,lang_model.model.layers.3.self_attn.q_proj.weight,lang_model.model.layers.3.self_attn.k_proj.weight,lang_model.model.layers.3.self_attn.v_proj.weight,lang_model.model.layers.3.self_attn.o_proj.weight,lang_model.model.layers.3.mlp.gate_proj.weight,lang_model.model.layers.3.mlp.down_proj.weight,lang_model.model.layers.3.mlp.up_proj.weight,lang_model.model.layers.3.input_layernorm.weight,lang_model.model.layers.3.post_attention_layernorm.weight,lang_model.model.layers.4.self_attn.q_proj.weight,lang_model.model.layers.4.self_attn.k_proj.weight,lang_model.model.layers.4.self_attn.v_proj.weight,lang_model.model.layers.4.self_attn.o_proj.weight,lang_model.model.layers.4.mlp.gate_proj.weight,lang_model.model.layers.4.mlp.down_proj.weight,lang_model.model.layers.4.mlp.up_proj.weight,lang_model.model.layers.4.input_layernorm.weight,lang_model.model.layers.4.post_attention_layernorm.weight,lang_model.model.layers.5.self_attn.q_proj.weight,lang_model.model.layers.5.self_attn.k_proj.weight,lang_model.model.layers.5.self_attn.v_proj.weight,lang_model.model.layers.5.self_attn.o_proj.weight,lang_model.model.layers.5.mlp.gate_proj.weight,lang_model.model.layers.5.mlp.down_proj.weight,lang_model.model.layers.5.mlp.up_proj.weight,lang_model.model.layers.5.input_layernorm.weight,lang_model.model.layers.5.post_attention_layernorm.weight,lang_model.model.layers.6.self_attn.q_proj.weight,lang_model.model.layers.6.self_attn.k_proj.weight,lang_model.model.layers.6.self_attn.v_proj.weight,lang_model.model.layers.6.self_attn.o_proj.weight,lang_model.model.layers.6.mlp.gate_proj.weight,lang_model.model.layers.6.mlp.down_proj.weight,lang_model.model.layers.6.mlp.up_proj.weight,lang_model.model.layers.6.input_layernorm.weight,lang_model.model.layers.6.post_attention_layernorm.weight,lang_model.model.layers.7.self_attn.q_proj.weight,lang_model.model.layers.7.self_attn.k_proj.weight,lang_model.model.layers.7.self_attn.v_proj.weight,lang_model.model.layers.7.self_attn.o_proj.weight,lang_model.model.layers.7.mlp.gate_proj.weight,lang_model.model.layers.7.mlp.down_proj.weight,lang_model.model.layers.7.mlp.up_proj.weight,lang_model.model.layers.7.input_layernorm.weight,lang_model.model.layers.7.post_attention_layernorm.weight,lang_model.model.layers.8.self_attn.q_proj.weight,lang_model.model.layers.8.self_attn.k_proj.weight,lang_model.model.layers.8.self_attn.v_proj.weight,lang_model.model.layers.8.self_attn.o_proj.weight,lang_model.model.layers.8.mlp.gate_proj.weight,lang_model.model.layers.8.mlp.down_proj.weight,lang_model.model.layers.8.mlp.up_proj.weight,lang_model.model.layers.8.input_layernorm.weight,lang_model.model.layers.8.post_attention_layernorm.weight,lang_model.model.layers.9.self_attn.q_proj.weight,lang_model.model.layers.9.self_attn.k_proj.weight,lang_model.model.layers.9.self_attn.v_proj.weight,lang_model.model.layers.9.self_attn.o_proj.weight,lang_model.model.layers.9.mlp.gate_proj.weight,lang_model.model.layers.9.mlp.down_proj.weight,lang_model.model.layers.9.mlp.up_proj.weight,lang_model.model.layers.9.input_layernorm.weight,lang_model.model.layers.9.post_attention_layernorm.weight,lang_model.model.layers.10.self_attn.q_proj.weight,lang_model.model.layers.10.self_attn.k_proj.weight,lang_model.model.layers.10.self_attn.v_proj.weight,lang_model.model.layers.10.self_attn.o_proj.weight,lang_model.model.layers.10.mlp.gate_proj.weight,lang_model.model.layers.10.mlp.down_proj.weight,lang_model.model.layers.10.mlp.up_proj.weight,lang_model.model.layers.10.input_layernorm.weight,lang_model.model.layers.10.post_attention_layernorm.weight,lang_model.model.layers.11.self_attn.q_proj.weight,lang_model.model.layers.11.self_attn.k_proj.weight,lang_model.model.layers.11.self_attn.v_proj.weight,lang_model.model.layers.11.self_attn.o_proj.weight,lang_model.model.layers.11.mlp.gate_proj.weight,lang_model.model.layers.11.mlp.down_proj.weight,lang_model.model.layers.11.mlp.up_proj.weight,lang_model.model.layers.11.input_layernorm.weight,lang_model.model.layers.11.post_attention_layernorm.weight,lang_model.model.layers.12.self_attn.q_proj.weight,lang_model.model.layers.12.self_attn.k_proj.weight,lang_model.model.layers.12.self_attn.v_proj.weight,lang_model.model.layers.12.self_attn.o_proj.weight,lang_model.model.layers.12.mlp.gate_proj.weight,lang_model.model.layers.12.mlp.down_proj.weight,lang_model.model.layers.12.mlp.up_proj.weight,lang_model.model.layers.12.input_layernorm.weight,lang_model.model.layers.12.post_attention_layernorm.weight,lang_model.model.layers.13.self_attn.q_proj.weight,lang_model.model.layers.13.self_attn.k_proj.weight,lang_model.model.layers.13.self_attn.v_proj.weight,lang_model.model.layers.13.self_attn.o_proj.weight,lang_model.model.layers.13.mlp.gate_proj.weight,lang_model.model.layers.13.mlp.down_proj.weight,lang_model.model.layers.13.mlp.up_proj.weight,lang_model.model.layers.13.input_layernorm.weight,lang_model.model.layers.13.post_attention_layernorm.weight,lang_model.model.layers.14.self_attn.q_proj.weight,lang_model.model.layers.14.self_attn.k_proj.weight,lang_model.model.layers.14.self_attn.v_proj.weight,lang_model.model.layers.14.self_attn.o_proj.weight,lang_model.model.layers.14.mlp.gate_proj.weight,lang_model.model.layers.14.mlp.down_proj.weight,lang_model.model.layers.14.mlp.up_proj.weight,lang_model.model.layers.14.input_layernorm.weight,lang_model.model.layers.14.post_attention_layernorm.weight,lang_model.model.layers.15.self_attn.q_proj.weight,lang_model.model.layers.15.self_attn.k_proj.weight,lang_model.model.layers.15.self_attn.v_proj.weight,lang_model.model.layers.15.self_attn.o_proj.weight,lang_model.model.layers.15.mlp.gate_proj.weight,lang_model.model.layers.15.mlp.down_proj.weight,lang_model.model.layers.15.mlp.up_proj.weight,lang_model.model.layers.15.input_layernorm.weight,lang_model.model.layers.15.post_attention_layernorm.weight,lang_model.model.layers.16.self_attn.q_proj.weight,lang_model.model.layers.16.self_attn.k_proj.weight,lang_model.model.layers.16.self_attn.v_proj.weight,lang_model.model.layers.16.self_attn.o_proj.weight,lang_model.model.layers.16.mlp.gate_proj.weight,lang_model.model.layers.16.mlp.down_proj.weight,lang_model.model.layers.16.mlp.up_proj.weight,lang_model.model.layers.16.input_layernorm.weight,lang_model.model.layers.16.post_attention_layernorm.weight,lang_model.model.layers.17.self_attn.q_proj.weight,lang_model.model.layers.17.self_attn.k_proj.weight,lang_model.model.layers.17.self_attn.v_proj.weight,lang_model.model.layers.17.self_attn.o_proj.weight,lang_model.model.layers.17.mlp.gate_proj.weight,lang_model.model.layers.17.mlp.down_proj.weight,lang_model.model.layers.17.mlp.up_proj.weight,lang_model.model.layers.17.input_layernorm.weight,lang_model.model.layers.17.post_attention_layernorm.weight,lang_model.model.layers.18.self_attn.q_proj.weight,lang_model.model.layers.18.self_attn.k_proj.weight,lang_model.model.layers.18.self_attn.v_proj.weight,lang_model.model.layers.18.self_attn.o_proj.weight,lang_model.model.layers.18.mlp.gate_proj.weight,lang_model.model.layers.18.mlp.down_proj.weight,lang_model.model.layers.18.mlp.up_proj.weight,lang_model.model.layers.18.input_layernorm.weight,lang_model.model.layers.18.post_attention_layernorm.weight,lang_model.model.layers.19.self_attn.q_proj.weight,lang_model.model.layers.19.self_attn.k_proj.weight,lang_model.model.layers.19.self_attn.v_proj.weight,lang_model.model.layers.19.self_attn.o_proj.weight,lang_model.model.layers.19.mlp.gate_proj.weight,lang_model.model.layers.19.mlp.down_proj.weight,lang_model.model.layers.19.mlp.up_proj.weight,lang_model.model.layers.19.input_layernorm.weight,lang_model.model.layers.19.post_attention_layernorm.weight,lang_model.model.layers.20.self_attn.q_proj.weight,lang_model.model.layers.20.self_attn.k_proj.weight,lang_model.model.layers.20.self_attn.v_proj.weight,lang_model.model.layers.20.self_attn.o_proj.weight,lang_model.model.layers.20.mlp.gate_proj.weight,lang_model.model.layers.20.mlp.down_proj.weight,lang_model.model.layers.20.mlp.up_proj.weight,lang_model.model.layers.20.input_layernorm.weight,lang_model.model.layers.20.post_attention_layernorm.weight,lang_model.model.layers.21.self_attn.q_proj.weight,lang_model.model.layers.21.self_attn.k_proj.weight,lang_model.model.layers.21.self_attn.v_proj.weight,lang_model.model.layers.21.self_attn.o_proj.weight,lang_model.model.layers.21.mlp.gate_proj.weight,lang_model.model.layers.21.mlp.down_proj.weight,lang_model.model.layers.21.mlp.up_proj.weight,lang_model.model.layers.21.input_layernorm.weight,lang_model.model.layers.21.post_attention_layernorm.weight,lang_model.model.layers.22.self_attn.q_proj.weight,lang_model.model.layers.22.self_attn.k_proj.weight,lang_model.model.layers.22.self_attn.v_proj.weight,lang_model.model.layers.22.self_attn.o_proj.weight,lang_model.model.layers.22.mlp.gate_proj.weight,lang_model.model.layers.22.mlp.down_proj.weight,lang_model.model.layers.22.mlp.up_proj.weight,lang_model.model.layers.22.input_layernorm.weight,lang_model.model.layers.22.post_attention_layernorm.weight,lang_model.model.layers.23.self_attn.q_proj.weight,lang_model.model.layers.23.self_attn.k_proj.weight,lang_model.model.layers.23.self_attn.v_proj.weight,lang_model.model.layers.23.self_attn.o_proj.weight,lang_model.model.layers.23.mlp.gate_proj.weight,lang_model.model.layers.23.mlp.down_proj.weight,lang_model.model.layers.23.mlp.up_proj.weight,lang_model.model.layers.23.input_layernorm.weight,lang_model.model.layers.23.post_attention_layernorm.weight,lang_model.model.layers.24.self_attn.q_proj.weight,lang_model.model.layers.24.self_attn.k_proj.weight,lang_model.model.layers.24.self_attn.v_proj.weight,lang_model.model.layers.24.self_attn.o_proj.weight,lang_model.model.layers.24.mlp.gate_proj.weight,lang_model.model.layers.24.mlp.down_proj.weight,lang_model.model.layers.24.mlp.up_proj.weight,lang_model.model.layers.24.input_layernorm.weight,lang_model.model.layers.24.post_attention_layernorm.weight,lang_model.model.layers.25.self_attn.q_proj.weight,lang_model.model.layers.25.self_attn.k_proj.weight,lang_model.model.layers.25.self_attn.v_proj.weight,lang_model.model.layers.25.self_attn.o_proj.weight,lang_model.model.layers.25.mlp.gate_proj.weight,lang_model.model.layers.25.mlp.down_proj.weight,lang_model.model.layers.25.mlp.up_proj.weight,lang_model.model.layers.25.input_layernorm.weight,lang_model.model.layers.25.post_attention_layernorm.weight,lang_model.model.layers.26.self_attn.q_proj.weight,lang_model.model.layers.26.self_attn.k_proj.weight,lang_model.model.layers.26.self_attn.v_proj.weight,lang_model.model.layers.26.self_attn.o_proj.weight,lang_model.model.layers.26.mlp.gate_proj.weight,lang_model.model.layers.26.mlp.down_proj.weight,lang_model.model.layers.26.mlp.up_proj.weight,lang_model.model.layers.26.input_layernorm.weight,lang_model.model.layers.26.post_attention_layernorm.weight,lang_model.model.layers.27.self_attn.q_proj.weight,lang_model.model.layers.27.self_attn.k_proj.weight,lang_model.model.layers.27.self_attn.v_proj.weight,lang_model.model.layers.27.self_attn.o_proj.weight,lang_model.model.layers.27.mlp.gate_proj.weight,lang_model.model.layers.27.mlp.down_proj.weight,lang_model.model.layers.27.mlp.up_proj.weight,lang_model.model.layers.27.input_layernorm.weight,lang_model.model.layers.27.post_attention_layernorm.weight,lang_model.model.layers.28.self_attn.q_proj.weight,lang_model.model.layers.28.self_attn.k_proj.weight,lang_model.model.layers.28.self_attn.v_proj.weight,lang_model.model.layers.28.self_attn.o_proj.weight,lang_model.model.layers.28.mlp.gate_proj.weight,lang_model.model.layers.28.mlp.down_proj.weight,lang_model.model.layers.28.mlp.up_proj.weight,lang_model.model.layers.28.input_layernorm.weight,lang_model.model.layers.28.post_attention_layernorm.weight,lang_model.model.layers.29.self_attn.q_proj.weight,lang_model.model.layers.29.self_attn.k_proj.weight,lang_model.model.layers.29.self_attn.v_proj.weight,lang_model.model.layers.29.self_attn.o_proj.weight,lang_model.model.layers.29.mlp.gate_proj.weight,lang_model.model.layers.29.mlp.down_proj.weight,lang_model.model.layers.29.mlp.up_proj.weight,lang_model.model.layers.29.input_layernorm.weight,lang_model.model.layers.29.post_attention_layernorm.weight,lang_model.model.layers.30.self_attn.q_proj.weight,lang_model.model.layers.30.self_attn.k_proj.weight,lang_model.model.layers.30.self_attn.v_proj.weight,lang_model.model.layers.30.self_attn.o_proj.weight,lang_model.model.layers.30.mlp.gate_proj.weight,lang_model.model.layers.30.mlp.down_proj.weight,lang_model.model.layers.30.mlp.up_proj.weight,lang_model.model.layers.30.input_layernorm.weight,lang_model.model.layers.30.post_attention_layernorm.weight,lang_model.model.layers.31.self_attn.q_proj.weight,lang_model.model.layers.31.self_attn.k_proj.weight,lang_model.model.layers.31.self_attn.v_proj.weight,lang_model.model.layers.31.self_attn.o_proj.weight,lang_model.model.layers.31.mlp.gate_proj.weight,lang_model.model.layers.31.mlp.down_proj.weight,lang_model.model.layers.31.mlp.up_proj.weight,lang_model.model.layers.31.input_layernorm.weight,lang_model.model.layers.31.post_attention_layernorm.weight,lang_model.model.norm.weight,lang_model.lm_head.weight,img_embeddings.img_linear.weight,img_embeddings.img_linear.bias,img_embeddings.img_layer_norm.weight,img_embeddings.img_layer_norm.bias,img_embeddings.loc_linear.weight,img_embeddings.loc_linear.bias,img_embeddings.loc_layer_norm.weight,img_embeddings.loc_layer_norm.bias,img_embeddings.obj_projector.0.weight,img_embeddings.obj_projector.0.bias,img_embeddings.obj_projector.1.weight,img_embeddings.obj_projector.1.bias,img_embeddings.nav_type_embedding.weight,img_embeddings.layer_norm.weight,img_embeddings.layer_norm.bias,img_embeddings.pano_encoder.layers.0.self_attn.in_proj_weight,img_embeddings.pano_encoder.layers.0.self_attn.in_proj_bias,img_embeddings.pano_encoder.layers.0.self_attn.out_proj.weight,img_embeddings.pano_encoder.layers.0.self_attn.out_proj.bias,img_embeddings.pano_encoder.layers.0.linear1.weight,img_embeddings.pano_encoder.layers.0.linear1.bias,img_embeddings.pano_encoder.layers.0.linear2.weight,img_embeddings.pano_encoder.layers.0.linear2.bias,img_embeddings.pano_encoder.layers.0.norm1.weight,img_embeddings.pano_encoder.layers.0.norm1.bias,img_embeddings.pano_encoder.layers.0.norm2.weight,img_embeddings.pano_encoder.layers.0.norm2.bias,img_embeddings.pano_encoder.layers.1.self_attn.in_proj_weight,img_embeddings.pano_encoder.layers.1.self_attn.in_proj_bias,img_embeddings.pano_encoder.layers.1.self_attn.out_proj.weight,img_embeddings.pano_encoder.layers.1.self_attn.out_proj.bias,img_embeddings.pano_encoder.layers.1.linear1.weight,img_embeddings.pano_encoder.layers.1.linear1.bias,img_embeddings.pano_encoder.layers.1.linear2.weight,img_embeddings.pano_encoder.layers.1.linear2.bias,img_embeddings.pano_encoder.layers.1.norm1.weight,img_embeddings.pano_encoder.layers.1.norm1.bias,img_embeddings.pano_encoder.layers.1.norm2.weight,img_embeddings.pano_encoder.layers.1.norm2.bias,img_embeddings.pano_encoder.norm.weight,img_embeddings.pano_encoder.norm.bias,img_embeddings.mapper.weight,img_embeddings.mapper.bias,token_type_embeddings.weight,gmap_pos_embeddings.0.weight,gmap_pos_embeddings.0.bias,gmap_pos_embeddings.1.weight,gmap_pos_embeddings.1.bias,gmap_step_embeddings.weight,vp_pos_embeddings.0.weight,vp_pos_embeddings.0.bias,vp_pos_embeddings.1.weight,vp_pos_embeddings.1.bias,obj_pos_embeddings.0.weight,obj_pos_embeddings.0.bias,obj_pos_embeddings.1.weight,obj_pos_embeddings.1.bias,og_head.0.weight,og_head.0.bias,out_head.0.weight,out_head.0.bias
2026-01-05 20:11:53,192   INFO  *************** init model *************** 
2026-01-05 20:12:02,779   INFO  Loading checkpoint from /data/wanghaoxuan/model_with_pretrain.pt
2026-01-05 20:12:09,614   INFO  <All keys matched successfully>
2026-01-05 20:12:09,958   INFO  model initialized with 6773.48 M trainable parameters
2026-01-05 20:12:09,959   INFO  Training with a single process
2026-01-05 20:12:09,959   INFO  **************************** Test ****************************
2026-01-05 20:12:09,960   INFO  ***** validate val_unseen split on SOON task *****
2026-01-05 21:12:27,051   INFO  eval 3390 predictions
2026-01-05 21:12:27,176   INFO  
[Eval] val_unseen epoch 0

 [Eval] dataset=[SOON] 
, action_steps: 11.74, steps: 14.39, lengths: 27.72, nav_error: 7.27, oracle_error: 4.31
[Eval] ||| sr: 37.52, oracle_sr: 53.19, spl: 28.88, det_sr: 3.98, det_spl: 3.12
2026-01-05 21:14:43,512   INFO  **********************Start logging**********************
2026-01-05 21:14:43,513   INFO  CUDA_VISIBLE_DEVICES=0
2026-01-05 21:14:43,513   INFO  data_dir         /data/wanghaoxuan/data
2026-01-05 21:14:43,513   INFO  cfg_file         configs/multi.yaml
2026-01-05 21:14:43,513   INFO  pretrained_model_name_or_path /data/wanghaoxuan/data/models/Vicuna-7B
2026-01-05 21:14:43,513   INFO  off_batch_task   False
2026-01-05 21:14:43,513   INFO  debug            False
2026-01-05 21:14:43,513   INFO  few_shot         None
2026-01-05 21:14:43,513   INFO  tour3d_nav_head  False
2026-01-05 21:14:43,513   INFO  seed             0
2026-01-05 21:14:43,513   INFO  num_epochs       30
2026-01-05 21:14:43,513   INFO  resume_from_checkpoint /data/wanghaoxuan/model_with_pretrain.pt
2026-01-05 21:14:43,513   INFO  from_scratch     False
2026-01-05 21:14:43,513   INFO  batch_size       4
2026-01-05 21:14:43,513   INFO  val_batch_size   2
2026-01-05 21:14:43,513   INFO  lr               1e-05
2026-01-05 21:14:43,514   INFO  feat_dropout     0.4
2026-01-05 21:14:43,514   INFO  num_warmup_steps 0
2026-01-05 21:14:43,514   INFO  num_steps_per_epoch -1
2026-01-05 21:14:43,514   INFO  gradient_accumulation_step 2
2026-01-05 21:14:43,514   INFO  precision        amp_bf16
2026-01-05 21:14:43,514   INFO  workers          0
2026-01-05 21:14:43,514   INFO  gpu              0
2026-01-05 21:14:43,514   INFO  world_size       1
2026-01-05 21:14:43,514   INFO  local_rank       0
2026-01-05 21:14:43,514   INFO  dist_url         env://
2026-01-05 21:14:43,514   INFO  dist_backend     nccl
2026-01-05 21:14:43,514   INFO  horovod          False
2026-01-05 21:14:43,514   INFO  no_set_device_rank False
2026-01-05 21:14:43,514   INFO  output_dir       build/eval
2026-01-05 21:14:43,514   INFO  max_saved_checkpoints 0
2026-01-05 21:14:43,514   INFO  save_ckpt_per_epochs 10
2026-01-05 21:14:43,514   INFO  save_latest_states False
2026-01-05 21:14:43,514   INFO  save_pred_results False
2026-01-05 21:14:43,514   INFO  save_detail_results False
2026-01-05 21:14:43,515   INFO  mode             test
2026-01-05 21:14:43,515   INFO  stage            multi
2026-01-05 21:14:43,515   INFO  ignoreid         -100
2026-01-05 21:14:43,515   INFO  enable_og        True
2026-01-05 21:14:43,515   INFO  enable_summarize False
2026-01-05 21:14:43,515   INFO  enable_fgr2r     False
2026-01-05 21:14:43,515   INFO  disable_nav      False
2026-01-05 21:14:43,515   INFO  gen_loss_coef    1.0
2026-01-05 21:14:43,515   INFO  obj_loss_coef    1.0
2026-01-05 21:14:43,515   INFO  teacher_forcing_coef 1.0
2026-01-05 21:14:43,515   INFO  fuse_obj         False
2026-01-05 21:14:43,515   INFO  use_lora         False
2026-01-05 21:14:43,515   INFO  lora_rank        8
2026-01-05 21:14:43,515   INFO  lora_alpha       16
2026-01-05 21:14:43,515   INFO  lora_dropout     0.05
2026-01-05 21:14:43,515   INFO  lora_target      None
2026-01-05 21:14:43,515   INFO  freeze_llama     False
2026-01-05 21:14:43,515   INFO  tune_token_emb   False
2026-01-05 21:14:43,515   INFO  no_loc_fts       False
2026-01-05 21:14:43,516   INFO  multi_endpoints  1
2026-01-05 21:14:43,516   INFO  path_type        trusted_path
2026-01-05 21:14:43,516   INFO  test_datasets    ['REVERIE']
2026-01-05 21:14:43,516   INFO  validation_split val_unseen
2026-01-05 21:14:43,516   INFO  do_sample        True
2026-01-05 21:14:43,516   INFO  temperature      0.01
2026-01-05 21:14:43,516   INFO  max_datapoints   None
2026-01-05 21:14:43,516   INFO  rank             0
2026-01-05 21:14:43,516   INFO  distributed      False
2026-01-05 21:14:43,516   INFO  device           cuda:0
2026-01-05 21:14:43,516   INFO  image_feat_size  1024
2026-01-05 21:14:43,516   INFO  obj_feat_size    768
2026-01-05 21:14:43,516   INFO  angle_feat_size  4
2026-01-05 21:14:43,516   INFO  enc_full_graph   True
2026-01-05 21:14:43,516   INFO  expert_policy    spl
2026-01-05 21:14:43,516   INFO  num_pano_layers  2
2026-01-05 21:14:43,516   INFO  ----------- Feature -----------
2026-01-05 21:14:43,516   INFO  cfg.Feature.object_feature_type: 
2026-01-05 21:14:43,516   INFO  cfg.Feature.angle_feat_size: 4
2026-01-05 21:14:43,517   INFO  cfg.Feature.max_objects: 70
2026-01-05 21:14:43,517   INFO  cfg.Feature.image_feat_size: 1024
2026-01-05 21:14:43,517   INFO  ----------- feature_database -----------
2026-01-05 21:14:43,517   INFO  cfg.Feature.feature_database.mp3d: eva_features/mp3d_EVA02-CLIP-L-14-336.hdf5
2026-01-05 21:14:43,517   INFO  cfg.Feature.feature_database.scan_qa: eva_features/scanqa_EVA02-CLIP-L-14-336.hdf5
2026-01-05 21:14:43,517   INFO  cfg.Feature.feature_database.room_tour: eva_features/web_obj_prog_p1_EVA02-CLIP-L-14-336.hdf5.bak
2026-01-05 21:14:43,517   INFO  cfg.Feature.feature_database.room3d_tour: eva_features/web_3d_obj_prog_crop_p1_EVA02-CLIP-L-14-336.hdf5
2026-01-05 21:14:43,517   INFO  cfg.Feature.feature_database.coco: eva_features/coco_EVA02-CLIP-L-14-336.hdf5
2026-01-05 21:14:43,517   INFO  cfg.Feature.obj_feat_size: 768
2026-01-05 21:14:43,517   INFO  ----------- object_database -----------
2026-01-05 21:14:43,517   INFO  cfg.Feature.object_database.reverie: obj_features/reverie_obj_feat
2026-01-05 21:14:43,517   INFO  cfg.Feature.object_database.soon: obj_features/soon_obj_feat
2026-01-05 21:14:43,517   INFO  ----------- Dataset -----------
2026-01-05 21:14:43,517   INFO  ----------- R2R -----------
2026-01-05 21:14:43,517   INFO  cfg.Dataset.R2R.DIR: R2R
2026-01-05 21:14:43,517   INFO  ----------- SPLIT -----------
2026-01-05 21:14:43,517   INFO  cfg.Dataset.R2R.SPLIT.train: FGR2R_train.json
2026-01-05 21:14:43,517   INFO  cfg.Dataset.R2R.SPLIT.val_seen: R2R_val_seen_enc.json
2026-01-05 21:14:43,517   INFO  cfg.Dataset.R2R.SPLIT.val_unseen: R2R_val_unseen_enc.json
2026-01-05 21:14:43,517   INFO  cfg.Dataset.R2R.SPLIT.test: R2R_test_enc.json
2026-01-05 21:14:43,518   INFO  ----------- REVERIE -----------
2026-01-05 21:14:43,518   INFO  cfg.Dataset.REVERIE.DIR: REVERIE
2026-01-05 21:14:43,518   INFO  cfg.Dataset.REVERIE.bbox_file: BBoxes.json
2026-01-05 21:14:43,518   INFO  ----------- SPLIT -----------
2026-01-05 21:14:43,518   INFO  cfg.Dataset.REVERIE.SPLIT.train: REVERIE_train_enc.json
2026-01-05 21:14:43,518   INFO  cfg.Dataset.REVERIE.SPLIT.val_seen: REVERIE_val_seen_enc.json
2026-01-05 21:14:43,518   INFO  cfg.Dataset.REVERIE.SPLIT.val_unseen: REVERIE_val_unseen_enc.json
2026-01-05 21:14:43,518   INFO  cfg.Dataset.REVERIE.SPLIT.test: REVERIE_test_enc.json
2026-01-05 21:14:43,518   INFO  ----------- CVDN -----------
2026-01-05 21:14:43,518   INFO  cfg.Dataset.CVDN.DIR: CVDN
2026-01-05 21:14:43,518   INFO  ----------- SPLIT -----------
2026-01-05 21:14:43,518   INFO  cfg.Dataset.CVDN.SPLIT.train: train.json
2026-01-05 21:14:43,518   INFO  cfg.Dataset.CVDN.SPLIT.val_seen: val_seen.json
2026-01-05 21:14:43,518   INFO  cfg.Dataset.CVDN.SPLIT.val_unseen: val_unseen.json
2026-01-05 21:14:43,518   INFO  cfg.Dataset.CVDN.SPLIT.test: test_cleaned.json
2026-01-05 21:14:43,518   INFO  ----------- SOON -----------
2026-01-05 21:14:43,518   INFO  cfg.Dataset.SOON.DIR: SOON
2026-01-05 21:14:43,518   INFO  ----------- SPLIT -----------
2026-01-05 21:14:43,518   INFO  cfg.Dataset.SOON.SPLIT.train: train_enc_pseudo_obj_ade30k_label.jsonl
2026-01-05 21:14:43,519   INFO  cfg.Dataset.SOON.SPLIT.val_seen: val_unseen_instrs_enc_pseudo_obj_ade30k_label.jsonl
2026-01-05 21:14:43,519   INFO  cfg.Dataset.SOON.SPLIT.val_unseen: val_unseen_house_enc_pseudo_obj_ade30k_label.jsonl
2026-01-05 21:14:43,519   INFO  cfg.Dataset.SOON.SPLIT.test: test_v2_enc.jsonl
2026-01-05 21:14:43,519   INFO  ----------- ScanQA -----------
2026-01-05 21:14:43,519   INFO  cfg.Dataset.ScanQA.DIR: ScanQA
2026-01-05 21:14:43,519   INFO  ----------- SPLIT -----------
2026-01-05 21:14:43,519   INFO  cfg.Dataset.ScanQA.SPLIT.train: ScanQA_v1.0_train_reformat.json
2026-01-05 21:14:43,519   INFO  cfg.Dataset.ScanQA.SPLIT.val_unseen: ScanQA_v1.0_val_reformat.json
2026-01-05 21:14:43,519   INFO  cfg.Dataset.ScanQA.SPLIT.test_wo_obj: ScanQA_v1.0_test_wo_obj_reformat.json
2026-01-05 21:14:43,519   INFO  cfg.Dataset.ScanQA.SPLIT.test_w_obj: ScanQA_v1.0_test_w_obj_reformat.json
2026-01-05 21:14:43,519   INFO  ----------- RoomTour -----------
2026-01-05 21:14:43,519   INFO  cfg.Dataset.RoomTour.DIR: RoomTour
2026-01-05 21:14:43,519   INFO  ----------- SPLIT -----------
2026-01-05 21:14:43,519   INFO  cfg.Dataset.RoomTour.SPLIT.train: p1_train_reformat.json
2026-01-05 21:14:43,519   INFO  ----------- Tour3D -----------
2026-01-05 21:14:43,519   INFO  cfg.Dataset.Tour3D.DIR: RoomTour
2026-01-05 21:14:43,519   INFO  ----------- SPLIT -----------
2026-01-05 21:14:43,519   INFO  cfg.Dataset.Tour3D.SPLIT.train: p1_train_colmap_trajectory_tour3d.json
2026-01-05 21:14:43,519   INFO  ----------- EQA -----------
2026-01-05 21:14:43,519   INFO  cfg.Dataset.EQA.DIR: EQA_MP3D
2026-01-05 21:14:43,520   INFO  ----------- SPLIT -----------
2026-01-05 21:14:43,520   INFO  cfg.Dataset.EQA.SPLIT.val_unseen: eqa_val_enc.json
2026-01-05 21:14:43,520   INFO  cfg.Dataset.EQA.ANSWER_VOCAB: eqa_answer_vocab.json
2026-01-05 21:14:43,520   INFO  ----------- R2R_AUG -----------
2026-01-05 21:14:43,520   INFO  cfg.Dataset.R2R_AUG.DIR: R2R
2026-01-05 21:14:43,520   INFO  ----------- SPLIT -----------
2026-01-05 21:14:43,520   INFO  cfg.Dataset.R2R_AUG.SPLIT.train: R2R_prevalent_aug_train_enc.jsonl
2026-01-05 21:14:43,520   INFO  ----------- REVERIE_AUG -----------
2026-01-05 21:14:43,520   INFO  cfg.Dataset.REVERIE_AUG.DIR: REVERIE
2026-01-05 21:14:43,520   INFO  cfg.Dataset.REVERIE_AUG.bbox_file: BBoxes.json
2026-01-05 21:14:43,520   INFO  ----------- SPLIT -----------
2026-01-05 21:14:43,520   INFO  cfg.Dataset.REVERIE_AUG.SPLIT.train: REVERIE_speaker_aug_enc.jsonl
2026-01-05 21:14:43,520   INFO  ----------- LLaVA -----------
2026-01-05 21:14:43,520   INFO  cfg.Dataset.LLaVA.DIR: LLaVA
2026-01-05 21:14:43,520   INFO  ----------- SPLIT -----------
2026-01-05 21:14:43,520   INFO  cfg.Dataset.LLaVA.SPLIT.train: detail_23k.json
2026-01-05 21:14:43,520   INFO  ----------- Pretrain -----------
2026-01-05 21:14:43,520   INFO  cfg.Pretrain.SOURCE: ['Tour3D', 'RoomTour', 'ScanQA', 'LLaVA']
2026-01-05 21:14:43,520   INFO  cfg.Pretrain.Ratio: [10, 20, 5, 2]
2026-01-05 21:14:43,521   INFO  ----------- LOSS_COEF -----------
2026-01-05 21:14:43,521   INFO  cfg.Pretrain.LOSS_COEF.R2R_AUG: 1
2026-01-05 21:14:43,521   INFO  cfg.Pretrain.LOSS_COEF.REVERIE_AUG: 1
2026-01-05 21:14:43,521   INFO  ----------- Multi -----------
2026-01-05 21:14:43,521   INFO  cfg.Multi.SOURCE: ['Tour3D', 'R2R', 'REVERIE', 'CVDN', 'SOON', 'ScanQA', 'LLaVA']
2026-01-05 21:14:43,521   INFO  cfg.Multi.Ratio: [10, 20, 5, 1, 5, 5, 5]
2026-01-05 21:14:43,521   INFO  ----------- LOSS_COEF -----------
2026-01-05 21:14:43,521   INFO  ----------- Model -----------
2026-01-05 21:14:43,521   INFO  cfg.Model.num_l_layers: 9
2026-01-05 21:14:43,521   INFO  cfg.Model.num_pano_layers: 2
2026-01-05 21:14:43,521   INFO  cfg.Model.num_x_layers: 4
2026-01-05 21:14:43,521   INFO  cfg.Model.graph_sprels: True
2026-01-05 21:14:43,521   INFO  cfg.Model.fusion: dynamic
2026-01-05 21:14:43,521   INFO  cfg.Model.enc_full_graph: True
2026-01-05 21:14:43,521   INFO  cfg.Model.expert_policy: spl
2026-01-05 21:14:43,521   INFO  ----------- Optim -----------
2026-01-05 21:14:43,521   INFO  ----------- val_max_action_len -----------
2026-01-05 21:14:43,521   INFO  cfg.Optim.val_max_action_len.R2R: 15
2026-01-05 21:14:43,521   INFO  cfg.Optim.val_max_action_len.REVERIE: 15
2026-01-05 21:14:43,522   INFO  cfg.Optim.val_max_action_len.CVDN: 30
2026-01-05 21:14:43,522   INFO  cfg.Optim.val_max_action_len.SOON: 20
2026-01-05 21:14:43,522   INFO  cfg.Optim.val_max_action_len.EQA: 15
2026-01-05 21:14:43,522   INFO  ----------- train_max_action_len -----------
2026-01-05 21:14:43,522   INFO  cfg.Optim.train_max_action_len.R2R: 15
2026-01-05 21:14:43,522   INFO  cfg.Optim.train_max_action_len.Tour3D: 15
2026-01-05 21:14:43,522   INFO  cfg.Optim.train_max_action_len.REVERIE: 15
2026-01-05 21:14:43,522   INFO  cfg.Optim.train_max_action_len.CVDN: 15
2026-01-05 21:14:43,522   INFO  cfg.Optim.train_max_action_len.SOON: 15
2026-01-05 21:14:43,522   INFO  cfg.Optim.train_max_action_len.EQA: 15
2026-01-05 21:14:43,522   INFO  cfg.Optim.train_max_action_len.R2R_AUG: 15
2026-01-05 21:14:43,522   INFO  cfg.Optim.train_max_action_len.REVERIE_AUG: 15
2026-01-05 21:14:46,283   INFO  [INFO] REVERIEDataset loaded with 3521 instructions, using splits: val_unseen
2026-01-05 21:14:46,284   INFO  
- Dataset: load 3521 REVERIE samples
- Dataset: load val_unseen split: 3521 samples in total
- Dataset: load val_unseen split: 10 scans in total
2026-01-05 21:14:46,284   INFO  REVERIE: 3521 samples loaded
2026-01-05 21:14:46,412   INFO  Initialize the model from config.
2026-01-05 21:16:14,841   INFO  model type: torch.bfloat16
2026-01-05 21:16:14,844   INFO  Trainable params: lang_model.model.embed_tokens.weight,lang_model.model.layers.0.self_attn.q_proj.weight,lang_model.model.layers.0.self_attn.k_proj.weight,lang_model.model.layers.0.self_attn.v_proj.weight,lang_model.model.layers.0.self_attn.o_proj.weight,lang_model.model.layers.0.mlp.gate_proj.weight,lang_model.model.layers.0.mlp.down_proj.weight,lang_model.model.layers.0.mlp.up_proj.weight,lang_model.model.layers.0.input_layernorm.weight,lang_model.model.layers.0.post_attention_layernorm.weight,lang_model.model.layers.1.self_attn.q_proj.weight,lang_model.model.layers.1.self_attn.k_proj.weight,lang_model.model.layers.1.self_attn.v_proj.weight,lang_model.model.layers.1.self_attn.o_proj.weight,lang_model.model.layers.1.mlp.gate_proj.weight,lang_model.model.layers.1.mlp.down_proj.weight,lang_model.model.layers.1.mlp.up_proj.weight,lang_model.model.layers.1.input_layernorm.weight,lang_model.model.layers.1.post_attention_layernorm.weight,lang_model.model.layers.2.self_attn.q_proj.weight,lang_model.model.layers.2.self_attn.k_proj.weight,lang_model.model.layers.2.self_attn.v_proj.weight,lang_model.model.layers.2.self_attn.o_proj.weight,lang_model.model.layers.2.mlp.gate_proj.weight,lang_model.model.layers.2.mlp.down_proj.weight,lang_model.model.layers.2.mlp.up_proj.weight,lang_model.model.layers.2.input_layernorm.weight,lang_model.model.layers.2.post_attention_layernorm.weight,lang_model.model.layers.3.self_attn.q_proj.weight,lang_model.model.layers.3.self_attn.k_proj.weight,lang_model.model.layers.3.self_attn.v_proj.weight,lang_model.model.layers.3.self_attn.o_proj.weight,lang_model.model.layers.3.mlp.gate_proj.weight,lang_model.model.layers.3.mlp.down_proj.weight,lang_model.model.layers.3.mlp.up_proj.weight,lang_model.model.layers.3.input_layernorm.weight,lang_model.model.layers.3.post_attention_layernorm.weight,lang_model.model.layers.4.self_attn.q_proj.weight,lang_model.model.layers.4.self_attn.k_proj.weight,lang_model.model.layers.4.self_attn.v_proj.weight,lang_model.model.layers.4.self_attn.o_proj.weight,lang_model.model.layers.4.mlp.gate_proj.weight,lang_model.model.layers.4.mlp.down_proj.weight,lang_model.model.layers.4.mlp.up_proj.weight,lang_model.model.layers.4.input_layernorm.weight,lang_model.model.layers.4.post_attention_layernorm.weight,lang_model.model.layers.5.self_attn.q_proj.weight,lang_model.model.layers.5.self_attn.k_proj.weight,lang_model.model.layers.5.self_attn.v_proj.weight,lang_model.model.layers.5.self_attn.o_proj.weight,lang_model.model.layers.5.mlp.gate_proj.weight,lang_model.model.layers.5.mlp.down_proj.weight,lang_model.model.layers.5.mlp.up_proj.weight,lang_model.model.layers.5.input_layernorm.weight,lang_model.model.layers.5.post_attention_layernorm.weight,lang_model.model.layers.6.self_attn.q_proj.weight,lang_model.model.layers.6.self_attn.k_proj.weight,lang_model.model.layers.6.self_attn.v_proj.weight,lang_model.model.layers.6.self_attn.o_proj.weight,lang_model.model.layers.6.mlp.gate_proj.weight,lang_model.model.layers.6.mlp.down_proj.weight,lang_model.model.layers.6.mlp.up_proj.weight,lang_model.model.layers.6.input_layernorm.weight,lang_model.model.layers.6.post_attention_layernorm.weight,lang_model.model.layers.7.self_attn.q_proj.weight,lang_model.model.layers.7.self_attn.k_proj.weight,lang_model.model.layers.7.self_attn.v_proj.weight,lang_model.model.layers.7.self_attn.o_proj.weight,lang_model.model.layers.7.mlp.gate_proj.weight,lang_model.model.layers.7.mlp.down_proj.weight,lang_model.model.layers.7.mlp.up_proj.weight,lang_model.model.layers.7.input_layernorm.weight,lang_model.model.layers.7.post_attention_layernorm.weight,lang_model.model.layers.8.self_attn.q_proj.weight,lang_model.model.layers.8.self_attn.k_proj.weight,lang_model.model.layers.8.self_attn.v_proj.weight,lang_model.model.layers.8.self_attn.o_proj.weight,lang_model.model.layers.8.mlp.gate_proj.weight,lang_model.model.layers.8.mlp.down_proj.weight,lang_model.model.layers.8.mlp.up_proj.weight,lang_model.model.layers.8.input_layernorm.weight,lang_model.model.layers.8.post_attention_layernorm.weight,lang_model.model.layers.9.self_attn.q_proj.weight,lang_model.model.layers.9.self_attn.k_proj.weight,lang_model.model.layers.9.self_attn.v_proj.weight,lang_model.model.layers.9.self_attn.o_proj.weight,lang_model.model.layers.9.mlp.gate_proj.weight,lang_model.model.layers.9.mlp.down_proj.weight,lang_model.model.layers.9.mlp.up_proj.weight,lang_model.model.layers.9.input_layernorm.weight,lang_model.model.layers.9.post_attention_layernorm.weight,lang_model.model.layers.10.self_attn.q_proj.weight,lang_model.model.layers.10.self_attn.k_proj.weight,lang_model.model.layers.10.self_attn.v_proj.weight,lang_model.model.layers.10.self_attn.o_proj.weight,lang_model.model.layers.10.mlp.gate_proj.weight,lang_model.model.layers.10.mlp.down_proj.weight,lang_model.model.layers.10.mlp.up_proj.weight,lang_model.model.layers.10.input_layernorm.weight,lang_model.model.layers.10.post_attention_layernorm.weight,lang_model.model.layers.11.self_attn.q_proj.weight,lang_model.model.layers.11.self_attn.k_proj.weight,lang_model.model.layers.11.self_attn.v_proj.weight,lang_model.model.layers.11.self_attn.o_proj.weight,lang_model.model.layers.11.mlp.gate_proj.weight,lang_model.model.layers.11.mlp.down_proj.weight,lang_model.model.layers.11.mlp.up_proj.weight,lang_model.model.layers.11.input_layernorm.weight,lang_model.model.layers.11.post_attention_layernorm.weight,lang_model.model.layers.12.self_attn.q_proj.weight,lang_model.model.layers.12.self_attn.k_proj.weight,lang_model.model.layers.12.self_attn.v_proj.weight,lang_model.model.layers.12.self_attn.o_proj.weight,lang_model.model.layers.12.mlp.gate_proj.weight,lang_model.model.layers.12.mlp.down_proj.weight,lang_model.model.layers.12.mlp.up_proj.weight,lang_model.model.layers.12.input_layernorm.weight,lang_model.model.layers.12.post_attention_layernorm.weight,lang_model.model.layers.13.self_attn.q_proj.weight,lang_model.model.layers.13.self_attn.k_proj.weight,lang_model.model.layers.13.self_attn.v_proj.weight,lang_model.model.layers.13.self_attn.o_proj.weight,lang_model.model.layers.13.mlp.gate_proj.weight,lang_model.model.layers.13.mlp.down_proj.weight,lang_model.model.layers.13.mlp.up_proj.weight,lang_model.model.layers.13.input_layernorm.weight,lang_model.model.layers.13.post_attention_layernorm.weight,lang_model.model.layers.14.self_attn.q_proj.weight,lang_model.model.layers.14.self_attn.k_proj.weight,lang_model.model.layers.14.self_attn.v_proj.weight,lang_model.model.layers.14.self_attn.o_proj.weight,lang_model.model.layers.14.mlp.gate_proj.weight,lang_model.model.layers.14.mlp.down_proj.weight,lang_model.model.layers.14.mlp.up_proj.weight,lang_model.model.layers.14.input_layernorm.weight,lang_model.model.layers.14.post_attention_layernorm.weight,lang_model.model.layers.15.self_attn.q_proj.weight,lang_model.model.layers.15.self_attn.k_proj.weight,lang_model.model.layers.15.self_attn.v_proj.weight,lang_model.model.layers.15.self_attn.o_proj.weight,lang_model.model.layers.15.mlp.gate_proj.weight,lang_model.model.layers.15.mlp.down_proj.weight,lang_model.model.layers.15.mlp.up_proj.weight,lang_model.model.layers.15.input_layernorm.weight,lang_model.model.layers.15.post_attention_layernorm.weight,lang_model.model.layers.16.self_attn.q_proj.weight,lang_model.model.layers.16.self_attn.k_proj.weight,lang_model.model.layers.16.self_attn.v_proj.weight,lang_model.model.layers.16.self_attn.o_proj.weight,lang_model.model.layers.16.mlp.gate_proj.weight,lang_model.model.layers.16.mlp.down_proj.weight,lang_model.model.layers.16.mlp.up_proj.weight,lang_model.model.layers.16.input_layernorm.weight,lang_model.model.layers.16.post_attention_layernorm.weight,lang_model.model.layers.17.self_attn.q_proj.weight,lang_model.model.layers.17.self_attn.k_proj.weight,lang_model.model.layers.17.self_attn.v_proj.weight,lang_model.model.layers.17.self_attn.o_proj.weight,lang_model.model.layers.17.mlp.gate_proj.weight,lang_model.model.layers.17.mlp.down_proj.weight,lang_model.model.layers.17.mlp.up_proj.weight,lang_model.model.layers.17.input_layernorm.weight,lang_model.model.layers.17.post_attention_layernorm.weight,lang_model.model.layers.18.self_attn.q_proj.weight,lang_model.model.layers.18.self_attn.k_proj.weight,lang_model.model.layers.18.self_attn.v_proj.weight,lang_model.model.layers.18.self_attn.o_proj.weight,lang_model.model.layers.18.mlp.gate_proj.weight,lang_model.model.layers.18.mlp.down_proj.weight,lang_model.model.layers.18.mlp.up_proj.weight,lang_model.model.layers.18.input_layernorm.weight,lang_model.model.layers.18.post_attention_layernorm.weight,lang_model.model.layers.19.self_attn.q_proj.weight,lang_model.model.layers.19.self_attn.k_proj.weight,lang_model.model.layers.19.self_attn.v_proj.weight,lang_model.model.layers.19.self_attn.o_proj.weight,lang_model.model.layers.19.mlp.gate_proj.weight,lang_model.model.layers.19.mlp.down_proj.weight,lang_model.model.layers.19.mlp.up_proj.weight,lang_model.model.layers.19.input_layernorm.weight,lang_model.model.layers.19.post_attention_layernorm.weight,lang_model.model.layers.20.self_attn.q_proj.weight,lang_model.model.layers.20.self_attn.k_proj.weight,lang_model.model.layers.20.self_attn.v_proj.weight,lang_model.model.layers.20.self_attn.o_proj.weight,lang_model.model.layers.20.mlp.gate_proj.weight,lang_model.model.layers.20.mlp.down_proj.weight,lang_model.model.layers.20.mlp.up_proj.weight,lang_model.model.layers.20.input_layernorm.weight,lang_model.model.layers.20.post_attention_layernorm.weight,lang_model.model.layers.21.self_attn.q_proj.weight,lang_model.model.layers.21.self_attn.k_proj.weight,lang_model.model.layers.21.self_attn.v_proj.weight,lang_model.model.layers.21.self_attn.o_proj.weight,lang_model.model.layers.21.mlp.gate_proj.weight,lang_model.model.layers.21.mlp.down_proj.weight,lang_model.model.layers.21.mlp.up_proj.weight,lang_model.model.layers.21.input_layernorm.weight,lang_model.model.layers.21.post_attention_layernorm.weight,lang_model.model.layers.22.self_attn.q_proj.weight,lang_model.model.layers.22.self_attn.k_proj.weight,lang_model.model.layers.22.self_attn.v_proj.weight,lang_model.model.layers.22.self_attn.o_proj.weight,lang_model.model.layers.22.mlp.gate_proj.weight,lang_model.model.layers.22.mlp.down_proj.weight,lang_model.model.layers.22.mlp.up_proj.weight,lang_model.model.layers.22.input_layernorm.weight,lang_model.model.layers.22.post_attention_layernorm.weight,lang_model.model.layers.23.self_attn.q_proj.weight,lang_model.model.layers.23.self_attn.k_proj.weight,lang_model.model.layers.23.self_attn.v_proj.weight,lang_model.model.layers.23.self_attn.o_proj.weight,lang_model.model.layers.23.mlp.gate_proj.weight,lang_model.model.layers.23.mlp.down_proj.weight,lang_model.model.layers.23.mlp.up_proj.weight,lang_model.model.layers.23.input_layernorm.weight,lang_model.model.layers.23.post_attention_layernorm.weight,lang_model.model.layers.24.self_attn.q_proj.weight,lang_model.model.layers.24.self_attn.k_proj.weight,lang_model.model.layers.24.self_attn.v_proj.weight,lang_model.model.layers.24.self_attn.o_proj.weight,lang_model.model.layers.24.mlp.gate_proj.weight,lang_model.model.layers.24.mlp.down_proj.weight,lang_model.model.layers.24.mlp.up_proj.weight,lang_model.model.layers.24.input_layernorm.weight,lang_model.model.layers.24.post_attention_layernorm.weight,lang_model.model.layers.25.self_attn.q_proj.weight,lang_model.model.layers.25.self_attn.k_proj.weight,lang_model.model.layers.25.self_attn.v_proj.weight,lang_model.model.layers.25.self_attn.o_proj.weight,lang_model.model.layers.25.mlp.gate_proj.weight,lang_model.model.layers.25.mlp.down_proj.weight,lang_model.model.layers.25.mlp.up_proj.weight,lang_model.model.layers.25.input_layernorm.weight,lang_model.model.layers.25.post_attention_layernorm.weight,lang_model.model.layers.26.self_attn.q_proj.weight,lang_model.model.layers.26.self_attn.k_proj.weight,lang_model.model.layers.26.self_attn.v_proj.weight,lang_model.model.layers.26.self_attn.o_proj.weight,lang_model.model.layers.26.mlp.gate_proj.weight,lang_model.model.layers.26.mlp.down_proj.weight,lang_model.model.layers.26.mlp.up_proj.weight,lang_model.model.layers.26.input_layernorm.weight,lang_model.model.layers.26.post_attention_layernorm.weight,lang_model.model.layers.27.self_attn.q_proj.weight,lang_model.model.layers.27.self_attn.k_proj.weight,lang_model.model.layers.27.self_attn.v_proj.weight,lang_model.model.layers.27.self_attn.o_proj.weight,lang_model.model.layers.27.mlp.gate_proj.weight,lang_model.model.layers.27.mlp.down_proj.weight,lang_model.model.layers.27.mlp.up_proj.weight,lang_model.model.layers.27.input_layernorm.weight,lang_model.model.layers.27.post_attention_layernorm.weight,lang_model.model.layers.28.self_attn.q_proj.weight,lang_model.model.layers.28.self_attn.k_proj.weight,lang_model.model.layers.28.self_attn.v_proj.weight,lang_model.model.layers.28.self_attn.o_proj.weight,lang_model.model.layers.28.mlp.gate_proj.weight,lang_model.model.layers.28.mlp.down_proj.weight,lang_model.model.layers.28.mlp.up_proj.weight,lang_model.model.layers.28.input_layernorm.weight,lang_model.model.layers.28.post_attention_layernorm.weight,lang_model.model.layers.29.self_attn.q_proj.weight,lang_model.model.layers.29.self_attn.k_proj.weight,lang_model.model.layers.29.self_attn.v_proj.weight,lang_model.model.layers.29.self_attn.o_proj.weight,lang_model.model.layers.29.mlp.gate_proj.weight,lang_model.model.layers.29.mlp.down_proj.weight,lang_model.model.layers.29.mlp.up_proj.weight,lang_model.model.layers.29.input_layernorm.weight,lang_model.model.layers.29.post_attention_layernorm.weight,lang_model.model.layers.30.self_attn.q_proj.weight,lang_model.model.layers.30.self_attn.k_proj.weight,lang_model.model.layers.30.self_attn.v_proj.weight,lang_model.model.layers.30.self_attn.o_proj.weight,lang_model.model.layers.30.mlp.gate_proj.weight,lang_model.model.layers.30.mlp.down_proj.weight,lang_model.model.layers.30.mlp.up_proj.weight,lang_model.model.layers.30.input_layernorm.weight,lang_model.model.layers.30.post_attention_layernorm.weight,lang_model.model.layers.31.self_attn.q_proj.weight,lang_model.model.layers.31.self_attn.k_proj.weight,lang_model.model.layers.31.self_attn.v_proj.weight,lang_model.model.layers.31.self_attn.o_proj.weight,lang_model.model.layers.31.mlp.gate_proj.weight,lang_model.model.layers.31.mlp.down_proj.weight,lang_model.model.layers.31.mlp.up_proj.weight,lang_model.model.layers.31.input_layernorm.weight,lang_model.model.layers.31.post_attention_layernorm.weight,lang_model.model.norm.weight,lang_model.lm_head.weight,img_embeddings.img_linear.weight,img_embeddings.img_linear.bias,img_embeddings.img_layer_norm.weight,img_embeddings.img_layer_norm.bias,img_embeddings.loc_linear.weight,img_embeddings.loc_linear.bias,img_embeddings.loc_layer_norm.weight,img_embeddings.loc_layer_norm.bias,img_embeddings.obj_projector.0.weight,img_embeddings.obj_projector.0.bias,img_embeddings.obj_projector.1.weight,img_embeddings.obj_projector.1.bias,img_embeddings.nav_type_embedding.weight,img_embeddings.layer_norm.weight,img_embeddings.layer_norm.bias,img_embeddings.pano_encoder.layers.0.self_attn.in_proj_weight,img_embeddings.pano_encoder.layers.0.self_attn.in_proj_bias,img_embeddings.pano_encoder.layers.0.self_attn.out_proj.weight,img_embeddings.pano_encoder.layers.0.self_attn.out_proj.bias,img_embeddings.pano_encoder.layers.0.linear1.weight,img_embeddings.pano_encoder.layers.0.linear1.bias,img_embeddings.pano_encoder.layers.0.linear2.weight,img_embeddings.pano_encoder.layers.0.linear2.bias,img_embeddings.pano_encoder.layers.0.norm1.weight,img_embeddings.pano_encoder.layers.0.norm1.bias,img_embeddings.pano_encoder.layers.0.norm2.weight,img_embeddings.pano_encoder.layers.0.norm2.bias,img_embeddings.pano_encoder.layers.1.self_attn.in_proj_weight,img_embeddings.pano_encoder.layers.1.self_attn.in_proj_bias,img_embeddings.pano_encoder.layers.1.self_attn.out_proj.weight,img_embeddings.pano_encoder.layers.1.self_attn.out_proj.bias,img_embeddings.pano_encoder.layers.1.linear1.weight,img_embeddings.pano_encoder.layers.1.linear1.bias,img_embeddings.pano_encoder.layers.1.linear2.weight,img_embeddings.pano_encoder.layers.1.linear2.bias,img_embeddings.pano_encoder.layers.1.norm1.weight,img_embeddings.pano_encoder.layers.1.norm1.bias,img_embeddings.pano_encoder.layers.1.norm2.weight,img_embeddings.pano_encoder.layers.1.norm2.bias,img_embeddings.pano_encoder.norm.weight,img_embeddings.pano_encoder.norm.bias,img_embeddings.mapper.weight,img_embeddings.mapper.bias,token_type_embeddings.weight,gmap_pos_embeddings.0.weight,gmap_pos_embeddings.0.bias,gmap_pos_embeddings.1.weight,gmap_pos_embeddings.1.bias,gmap_step_embeddings.weight,vp_pos_embeddings.0.weight,vp_pos_embeddings.0.bias,vp_pos_embeddings.1.weight,vp_pos_embeddings.1.bias,obj_pos_embeddings.0.weight,obj_pos_embeddings.0.bias,obj_pos_embeddings.1.weight,obj_pos_embeddings.1.bias,og_head.0.weight,og_head.0.bias,out_head.0.weight,out_head.0.bias
2026-01-05 21:16:14,846   INFO  *************** init model *************** 
2026-01-05 21:16:17,671   INFO  Loading checkpoint from /data/wanghaoxuan/model_with_pretrain.pt
2026-01-05 21:16:23,116   INFO  <All keys matched successfully>
2026-01-05 21:16:23,448   INFO  model initialized with 6773.48 M trainable parameters
2026-01-05 21:16:23,448   INFO  Training with a single process
2026-01-05 21:16:23,449   INFO  **************************** Test ****************************
2026-01-05 21:16:23,451   INFO  ***** validate val_unseen split on REVERIE task *****
2026-01-05 21:49:41,117   INFO  eval 3521 predictions
2026-01-05 21:49:41,224   INFO  
[Eval] val_unseen epoch 0

 [Eval] dataset=[REVERIE] 
, action_steps: 6.45, steps: 7.79, lengths: 15.32, nav_error: 5.86, oracle_error: 2.85
[Eval] ||| sr: 41.52, oracle_sr: 52.37, spl: 35.45, rgs: 21.90, rgspl: 18.31
2026-01-05 21:54:39,575   INFO  **********************Start logging**********************
2026-01-05 21:54:39,575   INFO  CUDA_VISIBLE_DEVICES=0
2026-01-05 21:54:39,576   INFO  data_dir         /data/wanghaoxuan/data
2026-01-05 21:54:39,576   INFO  cfg_file         configs/multi.yaml
2026-01-05 21:54:39,576   INFO  pretrained_model_name_or_path /data/wanghaoxuan/data/models/Vicuna-7B
2026-01-05 21:54:39,576   INFO  off_batch_task   False
2026-01-05 21:54:39,576   INFO  debug            False
2026-01-05 21:54:39,576   INFO  few_shot         None
2026-01-05 21:54:39,576   INFO  tour3d_nav_head  False
2026-01-05 21:54:39,576   INFO  seed             0
2026-01-05 21:54:39,576   INFO  num_epochs       30
2026-01-05 21:54:39,576   INFO  resume_from_checkpoint /data/wanghaoxuan/model_with_pretrain.pt
2026-01-05 21:54:39,576   INFO  from_scratch     False
2026-01-05 21:54:39,576   INFO  batch_size       4
2026-01-05 21:54:39,576   INFO  val_batch_size   2
2026-01-05 21:54:39,576   INFO  lr               1e-05
2026-01-05 21:54:39,576   INFO  feat_dropout     0.4
2026-01-05 21:54:39,576   INFO  num_warmup_steps 0
2026-01-05 21:54:39,576   INFO  num_steps_per_epoch -1
2026-01-05 21:54:39,577   INFO  gradient_accumulation_step 2
2026-01-05 21:54:39,577   INFO  precision        amp_bf16
2026-01-05 21:54:39,577   INFO  workers          0
2026-01-05 21:54:39,577   INFO  gpu              0
2026-01-05 21:54:39,577   INFO  world_size       1
2026-01-05 21:54:39,577   INFO  local_rank       0
2026-01-05 21:54:39,577   INFO  dist_url         env://
2026-01-05 21:54:39,577   INFO  dist_backend     nccl
2026-01-05 21:54:39,577   INFO  horovod          False
2026-01-05 21:54:39,577   INFO  no_set_device_rank False
2026-01-05 21:54:39,577   INFO  output_dir       build/eval
2026-01-05 21:54:39,577   INFO  max_saved_checkpoints 0
2026-01-05 21:54:39,577   INFO  save_ckpt_per_epochs 10
2026-01-05 21:54:39,577   INFO  save_latest_states False
2026-01-05 21:54:39,577   INFO  save_pred_results True
2026-01-05 21:54:39,577   INFO  save_detail_results False
2026-01-05 21:54:39,577   INFO  mode             test
2026-01-05 21:54:39,577   INFO  stage            multi
2026-01-05 21:54:39,578   INFO  ignoreid         -100
2026-01-05 21:54:39,578   INFO  enable_og        True
2026-01-05 21:54:39,578   INFO  enable_summarize False
2026-01-05 21:54:39,578   INFO  enable_fgr2r     False
2026-01-05 21:54:39,578   INFO  disable_nav      False
2026-01-05 21:54:39,578   INFO  gen_loss_coef    1.0
2026-01-05 21:54:39,578   INFO  obj_loss_coef    1.0
2026-01-05 21:54:39,578   INFO  teacher_forcing_coef 1.0
2026-01-05 21:54:39,578   INFO  fuse_obj         False
2026-01-05 21:54:39,578   INFO  use_lora         False
2026-01-05 21:54:39,578   INFO  lora_rank        8
2026-01-05 21:54:39,578   INFO  lora_alpha       16
2026-01-05 21:54:39,578   INFO  lora_dropout     0.05
2026-01-05 21:54:39,578   INFO  lora_target      None
2026-01-05 21:54:39,578   INFO  freeze_llama     False
2026-01-05 21:54:39,578   INFO  tune_token_emb   False
2026-01-05 21:54:39,578   INFO  no_loc_fts       False
2026-01-05 21:54:39,578   INFO  multi_endpoints  1
2026-01-05 21:54:39,578   INFO  path_type        trusted_path
2026-01-05 21:54:39,578   INFO  test_datasets    ['SOON']
2026-01-05 21:54:39,579   INFO  validation_split test
2026-01-05 21:54:39,579   INFO  do_sample        True
2026-01-05 21:54:39,579   INFO  temperature      0.01
2026-01-05 21:54:39,579   INFO  max_datapoints   None
2026-01-05 21:54:39,579   INFO  rank             0
2026-01-05 21:54:39,579   INFO  distributed      False
2026-01-05 21:54:39,579   INFO  device           cuda:0
2026-01-05 21:54:39,579   INFO  image_feat_size  1024
2026-01-05 21:54:39,579   INFO  obj_feat_size    768
2026-01-05 21:54:39,579   INFO  angle_feat_size  4
2026-01-05 21:54:39,579   INFO  enc_full_graph   True
2026-01-05 21:54:39,579   INFO  expert_policy    spl
2026-01-05 21:54:39,579   INFO  num_pano_layers  2
2026-01-05 21:54:39,579   INFO  ----------- Feature -----------
2026-01-05 21:54:39,579   INFO  cfg.Feature.object_feature_type: 
2026-01-05 21:54:39,579   INFO  cfg.Feature.angle_feat_size: 4
2026-01-05 21:54:39,579   INFO  cfg.Feature.max_objects: 70
2026-01-05 21:54:39,579   INFO  cfg.Feature.image_feat_size: 1024
2026-01-05 21:54:39,579   INFO  ----------- feature_database -----------
2026-01-05 21:54:39,580   INFO  cfg.Feature.feature_database.mp3d: eva_features/mp3d_EVA02-CLIP-L-14-336.hdf5
2026-01-05 21:54:39,580   INFO  cfg.Feature.feature_database.scan_qa: eva_features/scanqa_EVA02-CLIP-L-14-336.hdf5
2026-01-05 21:54:39,580   INFO  cfg.Feature.feature_database.room_tour: eva_features/web_obj_prog_p1_EVA02-CLIP-L-14-336.hdf5.bak
2026-01-05 21:54:39,580   INFO  cfg.Feature.feature_database.room3d_tour: eva_features/web_3d_obj_prog_crop_p1_EVA02-CLIP-L-14-336.hdf5
2026-01-05 21:54:39,580   INFO  cfg.Feature.feature_database.coco: eva_features/coco_EVA02-CLIP-L-14-336.hdf5
2026-01-05 21:54:39,580   INFO  cfg.Feature.obj_feat_size: 768
2026-01-05 21:54:39,580   INFO  ----------- object_database -----------
2026-01-05 21:54:39,580   INFO  cfg.Feature.object_database.reverie: obj_features/reverie_obj_feat
2026-01-05 21:54:39,580   INFO  cfg.Feature.object_database.soon: obj_features/soon_obj_feat
2026-01-05 21:54:39,580   INFO  ----------- Dataset -----------
2026-01-05 21:54:39,580   INFO  ----------- R2R -----------
2026-01-05 21:54:39,580   INFO  cfg.Dataset.R2R.DIR: R2R
2026-01-05 21:54:39,580   INFO  ----------- SPLIT -----------
2026-01-05 21:54:39,580   INFO  cfg.Dataset.R2R.SPLIT.train: FGR2R_train.json
2026-01-05 21:54:39,580   INFO  cfg.Dataset.R2R.SPLIT.val_seen: R2R_val_seen_enc.json
2026-01-05 21:54:39,580   INFO  cfg.Dataset.R2R.SPLIT.val_unseen: R2R_val_unseen_enc.json
2026-01-05 21:54:39,580   INFO  cfg.Dataset.R2R.SPLIT.test: R2R_test_enc.json
2026-01-05 21:54:39,580   INFO  ----------- REVERIE -----------
2026-01-05 21:54:39,580   INFO  cfg.Dataset.REVERIE.DIR: REVERIE
2026-01-05 21:54:39,580   INFO  cfg.Dataset.REVERIE.bbox_file: BBoxes.json
2026-01-05 21:54:39,581   INFO  ----------- SPLIT -----------
2026-01-05 21:54:39,581   INFO  cfg.Dataset.REVERIE.SPLIT.train: REVERIE_train_enc.json
2026-01-05 21:54:39,581   INFO  cfg.Dataset.REVERIE.SPLIT.val_seen: REVERIE_val_seen_enc.json
2026-01-05 21:54:39,581   INFO  cfg.Dataset.REVERIE.SPLIT.val_unseen: REVERIE_val_unseen_enc.json
2026-01-05 21:54:39,581   INFO  cfg.Dataset.REVERIE.SPLIT.test: REVERIE_test_enc.json
2026-01-05 21:54:39,581   INFO  ----------- CVDN -----------
2026-01-05 21:54:39,581   INFO  cfg.Dataset.CVDN.DIR: CVDN
2026-01-05 21:54:39,581   INFO  ----------- SPLIT -----------
2026-01-05 21:54:39,581   INFO  cfg.Dataset.CVDN.SPLIT.train: train.json
2026-01-05 21:54:39,581   INFO  cfg.Dataset.CVDN.SPLIT.val_seen: val_seen.json
2026-01-05 21:54:39,581   INFO  cfg.Dataset.CVDN.SPLIT.val_unseen: val_unseen.json
2026-01-05 21:54:39,581   INFO  cfg.Dataset.CVDN.SPLIT.test: test_cleaned.json
2026-01-05 21:54:39,581   INFO  ----------- SOON -----------
2026-01-05 21:54:39,581   INFO  cfg.Dataset.SOON.DIR: SOON
2026-01-05 21:54:39,581   INFO  ----------- SPLIT -----------
2026-01-05 21:54:39,581   INFO  cfg.Dataset.SOON.SPLIT.train: train_enc_pseudo_obj_ade30k_label.jsonl
2026-01-05 21:54:39,581   INFO  cfg.Dataset.SOON.SPLIT.val_seen: val_unseen_instrs_enc_pseudo_obj_ade30k_label.jsonl
2026-01-05 21:54:39,581   INFO  cfg.Dataset.SOON.SPLIT.val_unseen: val_unseen_house_enc_pseudo_obj_ade30k_label.jsonl
2026-01-05 21:54:39,581   INFO  cfg.Dataset.SOON.SPLIT.test: test_v2_enc.jsonl
2026-01-05 21:54:39,582   INFO  ----------- ScanQA -----------
2026-01-05 21:54:39,582   INFO  cfg.Dataset.ScanQA.DIR: ScanQA
2026-01-05 21:54:39,582   INFO  ----------- SPLIT -----------
2026-01-05 21:54:39,582   INFO  cfg.Dataset.ScanQA.SPLIT.train: ScanQA_v1.0_train_reformat.json
2026-01-05 21:54:39,582   INFO  cfg.Dataset.ScanQA.SPLIT.val_unseen: ScanQA_v1.0_val_reformat.json
2026-01-05 21:54:39,582   INFO  cfg.Dataset.ScanQA.SPLIT.test_wo_obj: ScanQA_v1.0_test_wo_obj_reformat.json
2026-01-05 21:54:39,582   INFO  cfg.Dataset.ScanQA.SPLIT.test_w_obj: ScanQA_v1.0_test_w_obj_reformat.json
2026-01-05 21:54:39,582   INFO  ----------- RoomTour -----------
2026-01-05 21:54:39,582   INFO  cfg.Dataset.RoomTour.DIR: RoomTour
2026-01-05 21:54:39,582   INFO  ----------- SPLIT -----------
2026-01-05 21:54:39,582   INFO  cfg.Dataset.RoomTour.SPLIT.train: p1_train_reformat.json
2026-01-05 21:54:39,582   INFO  ----------- Tour3D -----------
2026-01-05 21:54:39,582   INFO  cfg.Dataset.Tour3D.DIR: RoomTour
2026-01-05 21:54:39,582   INFO  ----------- SPLIT -----------
2026-01-05 21:54:39,582   INFO  cfg.Dataset.Tour3D.SPLIT.train: p1_train_colmap_trajectory_tour3d.json
2026-01-05 21:54:39,582   INFO  ----------- EQA -----------
2026-01-05 21:54:39,582   INFO  cfg.Dataset.EQA.DIR: EQA_MP3D
2026-01-05 21:54:39,582   INFO  ----------- SPLIT -----------
2026-01-05 21:54:39,582   INFO  cfg.Dataset.EQA.SPLIT.val_unseen: eqa_val_enc.json
2026-01-05 21:54:39,583   INFO  cfg.Dataset.EQA.ANSWER_VOCAB: eqa_answer_vocab.json
2026-01-05 21:54:39,583   INFO  ----------- R2R_AUG -----------
2026-01-05 21:54:39,583   INFO  cfg.Dataset.R2R_AUG.DIR: R2R
2026-01-05 21:54:39,583   INFO  ----------- SPLIT -----------
2026-01-05 21:54:39,583   INFO  cfg.Dataset.R2R_AUG.SPLIT.train: R2R_prevalent_aug_train_enc.jsonl
2026-01-05 21:54:39,583   INFO  ----------- REVERIE_AUG -----------
2026-01-05 21:54:39,583   INFO  cfg.Dataset.REVERIE_AUG.DIR: REVERIE
2026-01-05 21:54:39,583   INFO  cfg.Dataset.REVERIE_AUG.bbox_file: BBoxes.json
2026-01-05 21:54:39,583   INFO  ----------- SPLIT -----------
2026-01-05 21:54:39,583   INFO  cfg.Dataset.REVERIE_AUG.SPLIT.train: REVERIE_speaker_aug_enc.jsonl
2026-01-05 21:54:39,583   INFO  ----------- LLaVA -----------
2026-01-05 21:54:39,583   INFO  cfg.Dataset.LLaVA.DIR: LLaVA
2026-01-05 21:54:39,583   INFO  ----------- SPLIT -----------
2026-01-05 21:54:39,583   INFO  cfg.Dataset.LLaVA.SPLIT.train: detail_23k.json
2026-01-05 21:54:39,583   INFO  ----------- Pretrain -----------
2026-01-05 21:54:39,583   INFO  cfg.Pretrain.SOURCE: ['Tour3D', 'RoomTour', 'ScanQA', 'LLaVA']
2026-01-05 21:54:39,583   INFO  cfg.Pretrain.Ratio: [10, 20, 5, 2]
2026-01-05 21:54:39,583   INFO  ----------- LOSS_COEF -----------
2026-01-05 21:54:39,583   INFO  cfg.Pretrain.LOSS_COEF.R2R_AUG: 1
2026-01-05 21:54:39,584   INFO  cfg.Pretrain.LOSS_COEF.REVERIE_AUG: 1
2026-01-05 21:54:39,584   INFO  ----------- Multi -----------
2026-01-05 21:54:39,584   INFO  cfg.Multi.SOURCE: ['Tour3D', 'R2R', 'REVERIE', 'CVDN', 'SOON', 'ScanQA', 'LLaVA']
2026-01-05 21:54:39,584   INFO  cfg.Multi.Ratio: [10, 20, 5, 1, 5, 5, 5]
2026-01-05 21:54:39,584   INFO  ----------- LOSS_COEF -----------
2026-01-05 21:54:39,584   INFO  ----------- Model -----------
2026-01-05 21:54:39,584   INFO  cfg.Model.num_l_layers: 9
2026-01-05 21:54:39,584   INFO  cfg.Model.num_pano_layers: 2
2026-01-05 21:54:39,584   INFO  cfg.Model.num_x_layers: 4
2026-01-05 21:54:39,584   INFO  cfg.Model.graph_sprels: True
2026-01-05 21:54:39,584   INFO  cfg.Model.fusion: dynamic
2026-01-05 21:54:39,584   INFO  cfg.Model.enc_full_graph: True
2026-01-05 21:54:39,584   INFO  cfg.Model.expert_policy: spl
2026-01-05 21:54:39,584   INFO  ----------- Optim -----------
2026-01-05 21:54:39,584   INFO  ----------- val_max_action_len -----------
2026-01-05 21:54:39,584   INFO  cfg.Optim.val_max_action_len.R2R: 15
2026-01-05 21:54:39,584   INFO  cfg.Optim.val_max_action_len.REVERIE: 15
2026-01-05 21:54:39,584   INFO  cfg.Optim.val_max_action_len.CVDN: 30
2026-01-05 21:54:39,584   INFO  cfg.Optim.val_max_action_len.SOON: 20
2026-01-05 21:54:39,585   INFO  cfg.Optim.val_max_action_len.EQA: 15
2026-01-05 21:54:39,585   INFO  ----------- train_max_action_len -----------
2026-01-05 21:54:39,585   INFO  cfg.Optim.train_max_action_len.R2R: 15
2026-01-05 21:54:39,585   INFO  cfg.Optim.train_max_action_len.Tour3D: 15
2026-01-05 21:54:39,585   INFO  cfg.Optim.train_max_action_len.REVERIE: 15
2026-01-05 21:54:39,585   INFO  cfg.Optim.train_max_action_len.CVDN: 15
2026-01-05 21:54:39,585   INFO  cfg.Optim.train_max_action_len.SOON: 15
2026-01-05 21:54:39,585   INFO  cfg.Optim.train_max_action_len.EQA: 15
2026-01-05 21:54:39,585   INFO  cfg.Optim.train_max_action_len.R2R_AUG: 15
2026-01-05 21:54:39,585   INFO  cfg.Optim.train_max_action_len.REVERIE_AUG: 15
2026-01-05 21:54:44,524   INFO  [INFO] SOONDataset loaded with 14110 instructions, using splits: test
2026-01-05 21:54:44,524   INFO  
- Dataset: load 14110 SOON samples
- Dataset: load test split: 14110 samples in total
- Dataset: load test split: 14 scans in total
2026-01-05 21:54:44,525   INFO  SOON: 14110 samples loaded
2026-01-05 21:54:44,604   INFO  Initialize the model from config.
2026-01-05 21:56:09,969   INFO  model type: torch.bfloat16
2026-01-05 21:56:09,971   INFO  Trainable params: lang_model.model.embed_tokens.weight,lang_model.model.layers.0.self_attn.q_proj.weight,lang_model.model.layers.0.self_attn.k_proj.weight,lang_model.model.layers.0.self_attn.v_proj.weight,lang_model.model.layers.0.self_attn.o_proj.weight,lang_model.model.layers.0.mlp.gate_proj.weight,lang_model.model.layers.0.mlp.down_proj.weight,lang_model.model.layers.0.mlp.up_proj.weight,lang_model.model.layers.0.input_layernorm.weight,lang_model.model.layers.0.post_attention_layernorm.weight,lang_model.model.layers.1.self_attn.q_proj.weight,lang_model.model.layers.1.self_attn.k_proj.weight,lang_model.model.layers.1.self_attn.v_proj.weight,lang_model.model.layers.1.self_attn.o_proj.weight,lang_model.model.layers.1.mlp.gate_proj.weight,lang_model.model.layers.1.mlp.down_proj.weight,lang_model.model.layers.1.mlp.up_proj.weight,lang_model.model.layers.1.input_layernorm.weight,lang_model.model.layers.1.post_attention_layernorm.weight,lang_model.model.layers.2.self_attn.q_proj.weight,lang_model.model.layers.2.self_attn.k_proj.weight,lang_model.model.layers.2.self_attn.v_proj.weight,lang_model.model.layers.2.self_attn.o_proj.weight,lang_model.model.layers.2.mlp.gate_proj.weight,lang_model.model.layers.2.mlp.down_proj.weight,lang_model.model.layers.2.mlp.up_proj.weight,lang_model.model.layers.2.input_layernorm.weight,lang_model.model.layers.2.post_attention_layernorm.weight,lang_model.model.layers.3.self_attn.q_proj.weight,lang_model.model.layers.3.self_attn.k_proj.weight,lang_model.model.layers.3.self_attn.v_proj.weight,lang_model.model.layers.3.self_attn.o_proj.weight,lang_model.model.layers.3.mlp.gate_proj.weight,lang_model.model.layers.3.mlp.down_proj.weight,lang_model.model.layers.3.mlp.up_proj.weight,lang_model.model.layers.3.input_layernorm.weight,lang_model.model.layers.3.post_attention_layernorm.weight,lang_model.model.layers.4.self_attn.q_proj.weight,lang_model.model.layers.4.self_attn.k_proj.weight,lang_model.model.layers.4.self_attn.v_proj.weight,lang_model.model.layers.4.self_attn.o_proj.weight,lang_model.model.layers.4.mlp.gate_proj.weight,lang_model.model.layers.4.mlp.down_proj.weight,lang_model.model.layers.4.mlp.up_proj.weight,lang_model.model.layers.4.input_layernorm.weight,lang_model.model.layers.4.post_attention_layernorm.weight,lang_model.model.layers.5.self_attn.q_proj.weight,lang_model.model.layers.5.self_attn.k_proj.weight,lang_model.model.layers.5.self_attn.v_proj.weight,lang_model.model.layers.5.self_attn.o_proj.weight,lang_model.model.layers.5.mlp.gate_proj.weight,lang_model.model.layers.5.mlp.down_proj.weight,lang_model.model.layers.5.mlp.up_proj.weight,lang_model.model.layers.5.input_layernorm.weight,lang_model.model.layers.5.post_attention_layernorm.weight,lang_model.model.layers.6.self_attn.q_proj.weight,lang_model.model.layers.6.self_attn.k_proj.weight,lang_model.model.layers.6.self_attn.v_proj.weight,lang_model.model.layers.6.self_attn.o_proj.weight,lang_model.model.layers.6.mlp.gate_proj.weight,lang_model.model.layers.6.mlp.down_proj.weight,lang_model.model.layers.6.mlp.up_proj.weight,lang_model.model.layers.6.input_layernorm.weight,lang_model.model.layers.6.post_attention_layernorm.weight,lang_model.model.layers.7.self_attn.q_proj.weight,lang_model.model.layers.7.self_attn.k_proj.weight,lang_model.model.layers.7.self_attn.v_proj.weight,lang_model.model.layers.7.self_attn.o_proj.weight,lang_model.model.layers.7.mlp.gate_proj.weight,lang_model.model.layers.7.mlp.down_proj.weight,lang_model.model.layers.7.mlp.up_proj.weight,lang_model.model.layers.7.input_layernorm.weight,lang_model.model.layers.7.post_attention_layernorm.weight,lang_model.model.layers.8.self_attn.q_proj.weight,lang_model.model.layers.8.self_attn.k_proj.weight,lang_model.model.layers.8.self_attn.v_proj.weight,lang_model.model.layers.8.self_attn.o_proj.weight,lang_model.model.layers.8.mlp.gate_proj.weight,lang_model.model.layers.8.mlp.down_proj.weight,lang_model.model.layers.8.mlp.up_proj.weight,lang_model.model.layers.8.input_layernorm.weight,lang_model.model.layers.8.post_attention_layernorm.weight,lang_model.model.layers.9.self_attn.q_proj.weight,lang_model.model.layers.9.self_attn.k_proj.weight,lang_model.model.layers.9.self_attn.v_proj.weight,lang_model.model.layers.9.self_attn.o_proj.weight,lang_model.model.layers.9.mlp.gate_proj.weight,lang_model.model.layers.9.mlp.down_proj.weight,lang_model.model.layers.9.mlp.up_proj.weight,lang_model.model.layers.9.input_layernorm.weight,lang_model.model.layers.9.post_attention_layernorm.weight,lang_model.model.layers.10.self_attn.q_proj.weight,lang_model.model.layers.10.self_attn.k_proj.weight,lang_model.model.layers.10.self_attn.v_proj.weight,lang_model.model.layers.10.self_attn.o_proj.weight,lang_model.model.layers.10.mlp.gate_proj.weight,lang_model.model.layers.10.mlp.down_proj.weight,lang_model.model.layers.10.mlp.up_proj.weight,lang_model.model.layers.10.input_layernorm.weight,lang_model.model.layers.10.post_attention_layernorm.weight,lang_model.model.layers.11.self_attn.q_proj.weight,lang_model.model.layers.11.self_attn.k_proj.weight,lang_model.model.layers.11.self_attn.v_proj.weight,lang_model.model.layers.11.self_attn.o_proj.weight,lang_model.model.layers.11.mlp.gate_proj.weight,lang_model.model.layers.11.mlp.down_proj.weight,lang_model.model.layers.11.mlp.up_proj.weight,lang_model.model.layers.11.input_layernorm.weight,lang_model.model.layers.11.post_attention_layernorm.weight,lang_model.model.layers.12.self_attn.q_proj.weight,lang_model.model.layers.12.self_attn.k_proj.weight,lang_model.model.layers.12.self_attn.v_proj.weight,lang_model.model.layers.12.self_attn.o_proj.weight,lang_model.model.layers.12.mlp.gate_proj.weight,lang_model.model.layers.12.mlp.down_proj.weight,lang_model.model.layers.12.mlp.up_proj.weight,lang_model.model.layers.12.input_layernorm.weight,lang_model.model.layers.12.post_attention_layernorm.weight,lang_model.model.layers.13.self_attn.q_proj.weight,lang_model.model.layers.13.self_attn.k_proj.weight,lang_model.model.layers.13.self_attn.v_proj.weight,lang_model.model.layers.13.self_attn.o_proj.weight,lang_model.model.layers.13.mlp.gate_proj.weight,lang_model.model.layers.13.mlp.down_proj.weight,lang_model.model.layers.13.mlp.up_proj.weight,lang_model.model.layers.13.input_layernorm.weight,lang_model.model.layers.13.post_attention_layernorm.weight,lang_model.model.layers.14.self_attn.q_proj.weight,lang_model.model.layers.14.self_attn.k_proj.weight,lang_model.model.layers.14.self_attn.v_proj.weight,lang_model.model.layers.14.self_attn.o_proj.weight,lang_model.model.layers.14.mlp.gate_proj.weight,lang_model.model.layers.14.mlp.down_proj.weight,lang_model.model.layers.14.mlp.up_proj.weight,lang_model.model.layers.14.input_layernorm.weight,lang_model.model.layers.14.post_attention_layernorm.weight,lang_model.model.layers.15.self_attn.q_proj.weight,lang_model.model.layers.15.self_attn.k_proj.weight,lang_model.model.layers.15.self_attn.v_proj.weight,lang_model.model.layers.15.self_attn.o_proj.weight,lang_model.model.layers.15.mlp.gate_proj.weight,lang_model.model.layers.15.mlp.down_proj.weight,lang_model.model.layers.15.mlp.up_proj.weight,lang_model.model.layers.15.input_layernorm.weight,lang_model.model.layers.15.post_attention_layernorm.weight,lang_model.model.layers.16.self_attn.q_proj.weight,lang_model.model.layers.16.self_attn.k_proj.weight,lang_model.model.layers.16.self_attn.v_proj.weight,lang_model.model.layers.16.self_attn.o_proj.weight,lang_model.model.layers.16.mlp.gate_proj.weight,lang_model.model.layers.16.mlp.down_proj.weight,lang_model.model.layers.16.mlp.up_proj.weight,lang_model.model.layers.16.input_layernorm.weight,lang_model.model.layers.16.post_attention_layernorm.weight,lang_model.model.layers.17.self_attn.q_proj.weight,lang_model.model.layers.17.self_attn.k_proj.weight,lang_model.model.layers.17.self_attn.v_proj.weight,lang_model.model.layers.17.self_attn.o_proj.weight,lang_model.model.layers.17.mlp.gate_proj.weight,lang_model.model.layers.17.mlp.down_proj.weight,lang_model.model.layers.17.mlp.up_proj.weight,lang_model.model.layers.17.input_layernorm.weight,lang_model.model.layers.17.post_attention_layernorm.weight,lang_model.model.layers.18.self_attn.q_proj.weight,lang_model.model.layers.18.self_attn.k_proj.weight,lang_model.model.layers.18.self_attn.v_proj.weight,lang_model.model.layers.18.self_attn.o_proj.weight,lang_model.model.layers.18.mlp.gate_proj.weight,lang_model.model.layers.18.mlp.down_proj.weight,lang_model.model.layers.18.mlp.up_proj.weight,lang_model.model.layers.18.input_layernorm.weight,lang_model.model.layers.18.post_attention_layernorm.weight,lang_model.model.layers.19.self_attn.q_proj.weight,lang_model.model.layers.19.self_attn.k_proj.weight,lang_model.model.layers.19.self_attn.v_proj.weight,lang_model.model.layers.19.self_attn.o_proj.weight,lang_model.model.layers.19.mlp.gate_proj.weight,lang_model.model.layers.19.mlp.down_proj.weight,lang_model.model.layers.19.mlp.up_proj.weight,lang_model.model.layers.19.input_layernorm.weight,lang_model.model.layers.19.post_attention_layernorm.weight,lang_model.model.layers.20.self_attn.q_proj.weight,lang_model.model.layers.20.self_attn.k_proj.weight,lang_model.model.layers.20.self_attn.v_proj.weight,lang_model.model.layers.20.self_attn.o_proj.weight,lang_model.model.layers.20.mlp.gate_proj.weight,lang_model.model.layers.20.mlp.down_proj.weight,lang_model.model.layers.20.mlp.up_proj.weight,lang_model.model.layers.20.input_layernorm.weight,lang_model.model.layers.20.post_attention_layernorm.weight,lang_model.model.layers.21.self_attn.q_proj.weight,lang_model.model.layers.21.self_attn.k_proj.weight,lang_model.model.layers.21.self_attn.v_proj.weight,lang_model.model.layers.21.self_attn.o_proj.weight,lang_model.model.layers.21.mlp.gate_proj.weight,lang_model.model.layers.21.mlp.down_proj.weight,lang_model.model.layers.21.mlp.up_proj.weight,lang_model.model.layers.21.input_layernorm.weight,lang_model.model.layers.21.post_attention_layernorm.weight,lang_model.model.layers.22.self_attn.q_proj.weight,lang_model.model.layers.22.self_attn.k_proj.weight,lang_model.model.layers.22.self_attn.v_proj.weight,lang_model.model.layers.22.self_attn.o_proj.weight,lang_model.model.layers.22.mlp.gate_proj.weight,lang_model.model.layers.22.mlp.down_proj.weight,lang_model.model.layers.22.mlp.up_proj.weight,lang_model.model.layers.22.input_layernorm.weight,lang_model.model.layers.22.post_attention_layernorm.weight,lang_model.model.layers.23.self_attn.q_proj.weight,lang_model.model.layers.23.self_attn.k_proj.weight,lang_model.model.layers.23.self_attn.v_proj.weight,lang_model.model.layers.23.self_attn.o_proj.weight,lang_model.model.layers.23.mlp.gate_proj.weight,lang_model.model.layers.23.mlp.down_proj.weight,lang_model.model.layers.23.mlp.up_proj.weight,lang_model.model.layers.23.input_layernorm.weight,lang_model.model.layers.23.post_attention_layernorm.weight,lang_model.model.layers.24.self_attn.q_proj.weight,lang_model.model.layers.24.self_attn.k_proj.weight,lang_model.model.layers.24.self_attn.v_proj.weight,lang_model.model.layers.24.self_attn.o_proj.weight,lang_model.model.layers.24.mlp.gate_proj.weight,lang_model.model.layers.24.mlp.down_proj.weight,lang_model.model.layers.24.mlp.up_proj.weight,lang_model.model.layers.24.input_layernorm.weight,lang_model.model.layers.24.post_attention_layernorm.weight,lang_model.model.layers.25.self_attn.q_proj.weight,lang_model.model.layers.25.self_attn.k_proj.weight,lang_model.model.layers.25.self_attn.v_proj.weight,lang_model.model.layers.25.self_attn.o_proj.weight,lang_model.model.layers.25.mlp.gate_proj.weight,lang_model.model.layers.25.mlp.down_proj.weight,lang_model.model.layers.25.mlp.up_proj.weight,lang_model.model.layers.25.input_layernorm.weight,lang_model.model.layers.25.post_attention_layernorm.weight,lang_model.model.layers.26.self_attn.q_proj.weight,lang_model.model.layers.26.self_attn.k_proj.weight,lang_model.model.layers.26.self_attn.v_proj.weight,lang_model.model.layers.26.self_attn.o_proj.weight,lang_model.model.layers.26.mlp.gate_proj.weight,lang_model.model.layers.26.mlp.down_proj.weight,lang_model.model.layers.26.mlp.up_proj.weight,lang_model.model.layers.26.input_layernorm.weight,lang_model.model.layers.26.post_attention_layernorm.weight,lang_model.model.layers.27.self_attn.q_proj.weight,lang_model.model.layers.27.self_attn.k_proj.weight,lang_model.model.layers.27.self_attn.v_proj.weight,lang_model.model.layers.27.self_attn.o_proj.weight,lang_model.model.layers.27.mlp.gate_proj.weight,lang_model.model.layers.27.mlp.down_proj.weight,lang_model.model.layers.27.mlp.up_proj.weight,lang_model.model.layers.27.input_layernorm.weight,lang_model.model.layers.27.post_attention_layernorm.weight,lang_model.model.layers.28.self_attn.q_proj.weight,lang_model.model.layers.28.self_attn.k_proj.weight,lang_model.model.layers.28.self_attn.v_proj.weight,lang_model.model.layers.28.self_attn.o_proj.weight,lang_model.model.layers.28.mlp.gate_proj.weight,lang_model.model.layers.28.mlp.down_proj.weight,lang_model.model.layers.28.mlp.up_proj.weight,lang_model.model.layers.28.input_layernorm.weight,lang_model.model.layers.28.post_attention_layernorm.weight,lang_model.model.layers.29.self_attn.q_proj.weight,lang_model.model.layers.29.self_attn.k_proj.weight,lang_model.model.layers.29.self_attn.v_proj.weight,lang_model.model.layers.29.self_attn.o_proj.weight,lang_model.model.layers.29.mlp.gate_proj.weight,lang_model.model.layers.29.mlp.down_proj.weight,lang_model.model.layers.29.mlp.up_proj.weight,lang_model.model.layers.29.input_layernorm.weight,lang_model.model.layers.29.post_attention_layernorm.weight,lang_model.model.layers.30.self_attn.q_proj.weight,lang_model.model.layers.30.self_attn.k_proj.weight,lang_model.model.layers.30.self_attn.v_proj.weight,lang_model.model.layers.30.self_attn.o_proj.weight,lang_model.model.layers.30.mlp.gate_proj.weight,lang_model.model.layers.30.mlp.down_proj.weight,lang_model.model.layers.30.mlp.up_proj.weight,lang_model.model.layers.30.input_layernorm.weight,lang_model.model.layers.30.post_attention_layernorm.weight,lang_model.model.layers.31.self_attn.q_proj.weight,lang_model.model.layers.31.self_attn.k_proj.weight,lang_model.model.layers.31.self_attn.v_proj.weight,lang_model.model.layers.31.self_attn.o_proj.weight,lang_model.model.layers.31.mlp.gate_proj.weight,lang_model.model.layers.31.mlp.down_proj.weight,lang_model.model.layers.31.mlp.up_proj.weight,lang_model.model.layers.31.input_layernorm.weight,lang_model.model.layers.31.post_attention_layernorm.weight,lang_model.model.norm.weight,lang_model.lm_head.weight,img_embeddings.img_linear.weight,img_embeddings.img_linear.bias,img_embeddings.img_layer_norm.weight,img_embeddings.img_layer_norm.bias,img_embeddings.loc_linear.weight,img_embeddings.loc_linear.bias,img_embeddings.loc_layer_norm.weight,img_embeddings.loc_layer_norm.bias,img_embeddings.obj_projector.0.weight,img_embeddings.obj_projector.0.bias,img_embeddings.obj_projector.1.weight,img_embeddings.obj_projector.1.bias,img_embeddings.nav_type_embedding.weight,img_embeddings.layer_norm.weight,img_embeddings.layer_norm.bias,img_embeddings.pano_encoder.layers.0.self_attn.in_proj_weight,img_embeddings.pano_encoder.layers.0.self_attn.in_proj_bias,img_embeddings.pano_encoder.layers.0.self_attn.out_proj.weight,img_embeddings.pano_encoder.layers.0.self_attn.out_proj.bias,img_embeddings.pano_encoder.layers.0.linear1.weight,img_embeddings.pano_encoder.layers.0.linear1.bias,img_embeddings.pano_encoder.layers.0.linear2.weight,img_embeddings.pano_encoder.layers.0.linear2.bias,img_embeddings.pano_encoder.layers.0.norm1.weight,img_embeddings.pano_encoder.layers.0.norm1.bias,img_embeddings.pano_encoder.layers.0.norm2.weight,img_embeddings.pano_encoder.layers.0.norm2.bias,img_embeddings.pano_encoder.layers.1.self_attn.in_proj_weight,img_embeddings.pano_encoder.layers.1.self_attn.in_proj_bias,img_embeddings.pano_encoder.layers.1.self_attn.out_proj.weight,img_embeddings.pano_encoder.layers.1.self_attn.out_proj.bias,img_embeddings.pano_encoder.layers.1.linear1.weight,img_embeddings.pano_encoder.layers.1.linear1.bias,img_embeddings.pano_encoder.layers.1.linear2.weight,img_embeddings.pano_encoder.layers.1.linear2.bias,img_embeddings.pano_encoder.layers.1.norm1.weight,img_embeddings.pano_encoder.layers.1.norm1.bias,img_embeddings.pano_encoder.layers.1.norm2.weight,img_embeddings.pano_encoder.layers.1.norm2.bias,img_embeddings.pano_encoder.norm.weight,img_embeddings.pano_encoder.norm.bias,img_embeddings.mapper.weight,img_embeddings.mapper.bias,token_type_embeddings.weight,gmap_pos_embeddings.0.weight,gmap_pos_embeddings.0.bias,gmap_pos_embeddings.1.weight,gmap_pos_embeddings.1.bias,gmap_step_embeddings.weight,vp_pos_embeddings.0.weight,vp_pos_embeddings.0.bias,vp_pos_embeddings.1.weight,vp_pos_embeddings.1.bias,obj_pos_embeddings.0.weight,obj_pos_embeddings.0.bias,obj_pos_embeddings.1.weight,obj_pos_embeddings.1.bias,og_head.0.weight,og_head.0.bias,out_head.0.weight,out_head.0.bias
2026-01-05 21:56:09,972   INFO  *************** init model *************** 
2026-01-05 21:56:12,723   INFO  Loading checkpoint from /data/wanghaoxuan/model_with_pretrain.pt
2026-01-05 21:56:18,200   INFO  <All keys matched successfully>
2026-01-05 21:56:18,530   INFO  model initialized with 6773.48 M trainable parameters
2026-01-05 21:56:18,530   INFO  Training with a single process
2026-01-05 21:56:18,531   INFO  **************************** Test ****************************
2026-01-05 21:56:18,533   INFO  ***** validate test split on SOON task *****
2026-01-06 02:00:29,909   INFO  
[Eval] test epoch 0

2026-01-06 07:41:07,042   INFO  **********************Start logging**********************
2026-01-06 07:41:07,042   INFO  CUDA_VISIBLE_DEVICES=0
2026-01-06 07:41:07,042   INFO  data_dir         /data/wanghaoxuan/data
2026-01-06 07:41:07,042   INFO  cfg_file         configs/multi.yaml
2026-01-06 07:41:07,042   INFO  pretrained_model_name_or_path /data/wanghaoxuan/data/models/Vicuna-7B
2026-01-06 07:41:07,042   INFO  off_batch_task   False
2026-01-06 07:41:07,042   INFO  debug            False
2026-01-06 07:41:07,042   INFO  few_shot         None
2026-01-06 07:41:07,042   INFO  tour3d_nav_head  False
2026-01-06 07:41:07,042   INFO  seed             0
2026-01-06 07:41:07,042   INFO  num_epochs       30
2026-01-06 07:41:07,042   INFO  resume_from_checkpoint /data/wanghaoxuan/model_with_pretrain.pt
2026-01-06 07:41:07,042   INFO  from_scratch     False
2026-01-06 07:41:07,043   INFO  batch_size       4
2026-01-06 07:41:07,043   INFO  val_batch_size   2
2026-01-06 07:41:07,043   INFO  lr               1e-05
2026-01-06 07:41:07,043   INFO  feat_dropout     0.4
2026-01-06 07:41:07,043   INFO  num_warmup_steps 0
2026-01-06 07:41:07,043   INFO  num_steps_per_epoch -1
2026-01-06 07:41:07,043   INFO  gradient_accumulation_step 2
2026-01-06 07:41:07,043   INFO  precision        amp_bf16
2026-01-06 07:41:07,043   INFO  workers          0
2026-01-06 07:41:07,043   INFO  gpu              0
2026-01-06 07:41:07,043   INFO  world_size       1
2026-01-06 07:41:07,043   INFO  local_rank       0
2026-01-06 07:41:07,043   INFO  dist_url         env://
2026-01-06 07:41:07,043   INFO  dist_backend     nccl
2026-01-06 07:41:07,043   INFO  horovod          False
2026-01-06 07:41:07,043   INFO  no_set_device_rank False
2026-01-06 07:41:07,043   INFO  output_dir       build/eval
2026-01-06 07:41:07,043   INFO  max_saved_checkpoints 0
2026-01-06 07:41:07,043   INFO  save_ckpt_per_epochs 10
2026-01-06 07:41:07,044   INFO  save_latest_states False
2026-01-06 07:41:07,044   INFO  save_pred_results True
2026-01-06 07:41:07,044   INFO  save_detail_results False
2026-01-06 07:41:07,044   INFO  mode             test
2026-01-06 07:41:07,044   INFO  stage            multi
2026-01-06 07:41:07,044   INFO  ignoreid         -100
2026-01-06 07:41:07,044   INFO  enable_og        True
2026-01-06 07:41:07,044   INFO  enable_summarize False
2026-01-06 07:41:07,044   INFO  enable_fgr2r     False
2026-01-06 07:41:07,044   INFO  disable_nav      False
2026-01-06 07:41:07,044   INFO  gen_loss_coef    1.0
2026-01-06 07:41:07,044   INFO  obj_loss_coef    1.0
2026-01-06 07:41:07,044   INFO  teacher_forcing_coef 1.0
2026-01-06 07:41:07,044   INFO  fuse_obj         False
2026-01-06 07:41:07,044   INFO  use_lora         False
2026-01-06 07:41:07,044   INFO  lora_rank        8
2026-01-06 07:41:07,044   INFO  lora_alpha       16
2026-01-06 07:41:07,044   INFO  lora_dropout     0.05
2026-01-06 07:41:07,044   INFO  lora_target      None
2026-01-06 07:41:07,045   INFO  freeze_llama     False
2026-01-06 07:41:07,045   INFO  tune_token_emb   False
2026-01-06 07:41:07,045   INFO  no_loc_fts       False
2026-01-06 07:41:07,045   INFO  multi_endpoints  1
2026-01-06 07:41:07,045   INFO  path_type        trusted_path
2026-01-06 07:41:07,045   INFO  test_datasets    ['REVERIE']
2026-01-06 07:41:07,045   INFO  validation_split test
2026-01-06 07:41:07,045   INFO  do_sample        True
2026-01-06 07:41:07,045   INFO  temperature      0.01
2026-01-06 07:41:07,045   INFO  max_datapoints   None
2026-01-06 07:41:07,045   INFO  rank             0
2026-01-06 07:41:07,045   INFO  distributed      False
2026-01-06 07:41:07,045   INFO  device           cuda:0
2026-01-06 07:41:07,045   INFO  image_feat_size  1024
2026-01-06 07:41:07,045   INFO  obj_feat_size    768
2026-01-06 07:41:07,045   INFO  angle_feat_size  4
2026-01-06 07:41:07,045   INFO  enc_full_graph   True
2026-01-06 07:41:07,045   INFO  expert_policy    spl
2026-01-06 07:41:07,046   INFO  num_pano_layers  2
2026-01-06 07:41:07,046   INFO  ----------- Feature -----------
2026-01-06 07:41:07,046   INFO  cfg.Feature.object_feature_type: 
2026-01-06 07:41:07,046   INFO  cfg.Feature.angle_feat_size: 4
2026-01-06 07:41:07,046   INFO  cfg.Feature.max_objects: 70
2026-01-06 07:41:07,046   INFO  cfg.Feature.image_feat_size: 1024
2026-01-06 07:41:07,046   INFO  ----------- feature_database -----------
2026-01-06 07:41:07,046   INFO  cfg.Feature.feature_database.mp3d: eva_features/mp3d_EVA02-CLIP-L-14-336.hdf5
2026-01-06 07:41:07,046   INFO  cfg.Feature.feature_database.scan_qa: eva_features/scanqa_EVA02-CLIP-L-14-336.hdf5
2026-01-06 07:41:07,046   INFO  cfg.Feature.feature_database.room_tour: eva_features/web_obj_prog_p1_EVA02-CLIP-L-14-336.hdf5.bak
2026-01-06 07:41:07,046   INFO  cfg.Feature.feature_database.room3d_tour: eva_features/web_3d_obj_prog_crop_p1_EVA02-CLIP-L-14-336.hdf5
2026-01-06 07:41:07,046   INFO  cfg.Feature.feature_database.coco: eva_features/coco_EVA02-CLIP-L-14-336.hdf5
2026-01-06 07:41:07,046   INFO  cfg.Feature.obj_feat_size: 768
2026-01-06 07:41:07,046   INFO  ----------- object_database -----------
2026-01-06 07:41:07,046   INFO  cfg.Feature.object_database.reverie: obj_features/reverie_obj_feat
2026-01-06 07:41:07,046   INFO  cfg.Feature.object_database.soon: obj_features/soon_obj_feat
2026-01-06 07:41:07,046   INFO  ----------- Dataset -----------
2026-01-06 07:41:07,046   INFO  ----------- R2R -----------
2026-01-06 07:41:07,046   INFO  cfg.Dataset.R2R.DIR: R2R
2026-01-06 07:41:07,047   INFO  ----------- SPLIT -----------
2026-01-06 07:41:07,047   INFO  cfg.Dataset.R2R.SPLIT.train: FGR2R_train.json
2026-01-06 07:41:07,047   INFO  cfg.Dataset.R2R.SPLIT.val_seen: R2R_val_seen_enc.json
2026-01-06 07:41:07,047   INFO  cfg.Dataset.R2R.SPLIT.val_unseen: R2R_val_unseen_enc.json
2026-01-06 07:41:07,047   INFO  cfg.Dataset.R2R.SPLIT.test: R2R_test_enc.json
2026-01-06 07:41:07,047   INFO  ----------- REVERIE -----------
2026-01-06 07:41:07,047   INFO  cfg.Dataset.REVERIE.DIR: REVERIE
2026-01-06 07:41:07,047   INFO  cfg.Dataset.REVERIE.bbox_file: BBoxes.json
2026-01-06 07:41:07,047   INFO  ----------- SPLIT -----------
2026-01-06 07:41:07,047   INFO  cfg.Dataset.REVERIE.SPLIT.train: REVERIE_train_enc.json
2026-01-06 07:41:07,047   INFO  cfg.Dataset.REVERIE.SPLIT.val_seen: REVERIE_val_seen_enc.json
2026-01-06 07:41:07,047   INFO  cfg.Dataset.REVERIE.SPLIT.val_unseen: REVERIE_val_unseen_enc.json
2026-01-06 07:41:07,047   INFO  cfg.Dataset.REVERIE.SPLIT.test: REVERIE_test_enc.json
2026-01-06 07:41:07,047   INFO  ----------- CVDN -----------
2026-01-06 07:41:07,047   INFO  cfg.Dataset.CVDN.DIR: CVDN
2026-01-06 07:41:07,047   INFO  ----------- SPLIT -----------
2026-01-06 07:41:07,047   INFO  cfg.Dataset.CVDN.SPLIT.train: train.json
2026-01-06 07:41:07,047   INFO  cfg.Dataset.CVDN.SPLIT.val_seen: val_seen.json
2026-01-06 07:41:07,047   INFO  cfg.Dataset.CVDN.SPLIT.val_unseen: val_unseen.json
2026-01-06 07:41:07,048   INFO  cfg.Dataset.CVDN.SPLIT.test: test_cleaned.json
2026-01-06 07:41:07,048   INFO  ----------- SOON -----------
2026-01-06 07:41:07,048   INFO  cfg.Dataset.SOON.DIR: SOON
2026-01-06 07:41:07,048   INFO  ----------- SPLIT -----------
2026-01-06 07:41:07,048   INFO  cfg.Dataset.SOON.SPLIT.train: train_enc_pseudo_obj_ade30k_label.jsonl
2026-01-06 07:41:07,048   INFO  cfg.Dataset.SOON.SPLIT.val_seen: val_unseen_instrs_enc_pseudo_obj_ade30k_label.jsonl
2026-01-06 07:41:07,048   INFO  cfg.Dataset.SOON.SPLIT.val_unseen: val_unseen_house_enc_pseudo_obj_ade30k_label.jsonl
2026-01-06 07:41:07,048   INFO  cfg.Dataset.SOON.SPLIT.test: test_v2_enc.jsonl
2026-01-06 07:41:07,048   INFO  ----------- ScanQA -----------
2026-01-06 07:41:07,048   INFO  cfg.Dataset.ScanQA.DIR: ScanQA
2026-01-06 07:41:07,048   INFO  ----------- SPLIT -----------
2026-01-06 07:41:07,048   INFO  cfg.Dataset.ScanQA.SPLIT.train: ScanQA_v1.0_train_reformat.json
2026-01-06 07:41:07,048   INFO  cfg.Dataset.ScanQA.SPLIT.val_unseen: ScanQA_v1.0_val_reformat.json
2026-01-06 07:41:07,048   INFO  cfg.Dataset.ScanQA.SPLIT.test_wo_obj: ScanQA_v1.0_test_wo_obj_reformat.json
2026-01-06 07:41:07,048   INFO  cfg.Dataset.ScanQA.SPLIT.test_w_obj: ScanQA_v1.0_test_w_obj_reformat.json
2026-01-06 07:41:07,048   INFO  ----------- RoomTour -----------
2026-01-06 07:41:07,048   INFO  cfg.Dataset.RoomTour.DIR: RoomTour
2026-01-06 07:41:07,048   INFO  ----------- SPLIT -----------
2026-01-06 07:41:07,048   INFO  cfg.Dataset.RoomTour.SPLIT.train: p1_train_reformat.json
2026-01-06 07:41:07,049   INFO  ----------- Tour3D -----------
2026-01-06 07:41:07,049   INFO  cfg.Dataset.Tour3D.DIR: RoomTour
2026-01-06 07:41:07,049   INFO  ----------- SPLIT -----------
2026-01-06 07:41:07,049   INFO  cfg.Dataset.Tour3D.SPLIT.train: p1_train_colmap_trajectory_tour3d.json
2026-01-06 07:41:07,049   INFO  ----------- EQA -----------
2026-01-06 07:41:07,049   INFO  cfg.Dataset.EQA.DIR: EQA_MP3D
2026-01-06 07:41:07,049   INFO  ----------- SPLIT -----------
2026-01-06 07:41:07,049   INFO  cfg.Dataset.EQA.SPLIT.val_unseen: eqa_val_enc.json
2026-01-06 07:41:07,049   INFO  cfg.Dataset.EQA.ANSWER_VOCAB: eqa_answer_vocab.json
2026-01-06 07:41:07,049   INFO  ----------- R2R_AUG -----------
2026-01-06 07:41:07,049   INFO  cfg.Dataset.R2R_AUG.DIR: R2R
2026-01-06 07:41:07,049   INFO  ----------- SPLIT -----------
2026-01-06 07:41:07,049   INFO  cfg.Dataset.R2R_AUG.SPLIT.train: R2R_prevalent_aug_train_enc.jsonl
2026-01-06 07:41:07,049   INFO  ----------- REVERIE_AUG -----------
2026-01-06 07:41:07,049   INFO  cfg.Dataset.REVERIE_AUG.DIR: REVERIE
2026-01-06 07:41:07,049   INFO  cfg.Dataset.REVERIE_AUG.bbox_file: BBoxes.json
2026-01-06 07:41:07,049   INFO  ----------- SPLIT -----------
2026-01-06 07:41:07,049   INFO  cfg.Dataset.REVERIE_AUG.SPLIT.train: REVERIE_speaker_aug_enc.jsonl
2026-01-06 07:41:07,050   INFO  ----------- LLaVA -----------
2026-01-06 07:41:07,050   INFO  cfg.Dataset.LLaVA.DIR: LLaVA
2026-01-06 07:41:07,050   INFO  ----------- SPLIT -----------
2026-01-06 07:41:07,050   INFO  cfg.Dataset.LLaVA.SPLIT.train: detail_23k.json
2026-01-06 07:41:07,050   INFO  ----------- Pretrain -----------
2026-01-06 07:41:07,050   INFO  cfg.Pretrain.SOURCE: ['Tour3D', 'RoomTour', 'ScanQA', 'LLaVA']
2026-01-06 07:41:07,050   INFO  cfg.Pretrain.Ratio: [10, 20, 5, 2]
2026-01-06 07:41:07,050   INFO  ----------- LOSS_COEF -----------
2026-01-06 07:41:07,050   INFO  cfg.Pretrain.LOSS_COEF.R2R_AUG: 1
2026-01-06 07:41:07,050   INFO  cfg.Pretrain.LOSS_COEF.REVERIE_AUG: 1
2026-01-06 07:41:07,050   INFO  ----------- Multi -----------
2026-01-06 07:41:07,050   INFO  cfg.Multi.SOURCE: ['Tour3D', 'R2R', 'REVERIE', 'CVDN', 'SOON', 'ScanQA', 'LLaVA']
2026-01-06 07:41:07,050   INFO  cfg.Multi.Ratio: [10, 20, 5, 1, 5, 5, 5]
2026-01-06 07:41:07,050   INFO  ----------- LOSS_COEF -----------
2026-01-06 07:41:07,050   INFO  ----------- Model -----------
2026-01-06 07:41:07,050   INFO  cfg.Model.num_l_layers: 9
2026-01-06 07:41:07,050   INFO  cfg.Model.num_pano_layers: 2
2026-01-06 07:41:07,050   INFO  cfg.Model.num_x_layers: 4
2026-01-06 07:41:07,050   INFO  cfg.Model.graph_sprels: True
2026-01-06 07:41:07,051   INFO  cfg.Model.fusion: dynamic
2026-01-06 07:41:07,051   INFO  cfg.Model.enc_full_graph: True
2026-01-06 07:41:07,051   INFO  cfg.Model.expert_policy: spl
2026-01-06 07:41:07,051   INFO  ----------- Optim -----------
2026-01-06 07:41:07,051   INFO  ----------- val_max_action_len -----------
2026-01-06 07:41:07,051   INFO  cfg.Optim.val_max_action_len.R2R: 15
2026-01-06 07:41:07,051   INFO  cfg.Optim.val_max_action_len.REVERIE: 15
2026-01-06 07:41:07,051   INFO  cfg.Optim.val_max_action_len.CVDN: 30
2026-01-06 07:41:07,051   INFO  cfg.Optim.val_max_action_len.SOON: 20
2026-01-06 07:41:07,051   INFO  cfg.Optim.val_max_action_len.EQA: 15
2026-01-06 07:41:07,051   INFO  ----------- train_max_action_len -----------
2026-01-06 07:41:07,051   INFO  cfg.Optim.train_max_action_len.R2R: 15
2026-01-06 07:41:07,051   INFO  cfg.Optim.train_max_action_len.Tour3D: 15
2026-01-06 07:41:07,051   INFO  cfg.Optim.train_max_action_len.REVERIE: 15
2026-01-06 07:41:07,051   INFO  cfg.Optim.train_max_action_len.CVDN: 15
2026-01-06 07:41:07,051   INFO  cfg.Optim.train_max_action_len.SOON: 15
2026-01-06 07:41:07,051   INFO  cfg.Optim.train_max_action_len.EQA: 15
2026-01-06 07:41:07,051   INFO  cfg.Optim.train_max_action_len.R2R_AUG: 15
2026-01-06 07:41:07,052   INFO  cfg.Optim.train_max_action_len.REVERIE_AUG: 15
2026-01-06 07:41:10,811   INFO  [INFO] REVERIEDataset loaded with 6292 instructions, using splits: test
2026-01-06 07:41:10,812   INFO  
- Dataset: load 6292 REVERIE samples
- Dataset: load test split: 6292 samples in total
- Dataset: load test split: 16 scans in total
2026-01-06 07:41:10,812   INFO  REVERIE: 6292 samples loaded
2026-01-06 07:41:11,067   INFO  Initialize the model from config.
2026-01-06 07:42:36,731   INFO  model type: torch.bfloat16
2026-01-06 07:42:36,734   INFO  Trainable params: lang_model.model.embed_tokens.weight,lang_model.model.layers.0.self_attn.q_proj.weight,lang_model.model.layers.0.self_attn.k_proj.weight,lang_model.model.layers.0.self_attn.v_proj.weight,lang_model.model.layers.0.self_attn.o_proj.weight,lang_model.model.layers.0.mlp.gate_proj.weight,lang_model.model.layers.0.mlp.down_proj.weight,lang_model.model.layers.0.mlp.up_proj.weight,lang_model.model.layers.0.input_layernorm.weight,lang_model.model.layers.0.post_attention_layernorm.weight,lang_model.model.layers.1.self_attn.q_proj.weight,lang_model.model.layers.1.self_attn.k_proj.weight,lang_model.model.layers.1.self_attn.v_proj.weight,lang_model.model.layers.1.self_attn.o_proj.weight,lang_model.model.layers.1.mlp.gate_proj.weight,lang_model.model.layers.1.mlp.down_proj.weight,lang_model.model.layers.1.mlp.up_proj.weight,lang_model.model.layers.1.input_layernorm.weight,lang_model.model.layers.1.post_attention_layernorm.weight,lang_model.model.layers.2.self_attn.q_proj.weight,lang_model.model.layers.2.self_attn.k_proj.weight,lang_model.model.layers.2.self_attn.v_proj.weight,lang_model.model.layers.2.self_attn.o_proj.weight,lang_model.model.layers.2.mlp.gate_proj.weight,lang_model.model.layers.2.mlp.down_proj.weight,lang_model.model.layers.2.mlp.up_proj.weight,lang_model.model.layers.2.input_layernorm.weight,lang_model.model.layers.2.post_attention_layernorm.weight,lang_model.model.layers.3.self_attn.q_proj.weight,lang_model.model.layers.3.self_attn.k_proj.weight,lang_model.model.layers.3.self_attn.v_proj.weight,lang_model.model.layers.3.self_attn.o_proj.weight,lang_model.model.layers.3.mlp.gate_proj.weight,lang_model.model.layers.3.mlp.down_proj.weight,lang_model.model.layers.3.mlp.up_proj.weight,lang_model.model.layers.3.input_layernorm.weight,lang_model.model.layers.3.post_attention_layernorm.weight,lang_model.model.layers.4.self_attn.q_proj.weight,lang_model.model.layers.4.self_attn.k_proj.weight,lang_model.model.layers.4.self_attn.v_proj.weight,lang_model.model.layers.4.self_attn.o_proj.weight,lang_model.model.layers.4.mlp.gate_proj.weight,lang_model.model.layers.4.mlp.down_proj.weight,lang_model.model.layers.4.mlp.up_proj.weight,lang_model.model.layers.4.input_layernorm.weight,lang_model.model.layers.4.post_attention_layernorm.weight,lang_model.model.layers.5.self_attn.q_proj.weight,lang_model.model.layers.5.self_attn.k_proj.weight,lang_model.model.layers.5.self_attn.v_proj.weight,lang_model.model.layers.5.self_attn.o_proj.weight,lang_model.model.layers.5.mlp.gate_proj.weight,lang_model.model.layers.5.mlp.down_proj.weight,lang_model.model.layers.5.mlp.up_proj.weight,lang_model.model.layers.5.input_layernorm.weight,lang_model.model.layers.5.post_attention_layernorm.weight,lang_model.model.layers.6.self_attn.q_proj.weight,lang_model.model.layers.6.self_attn.k_proj.weight,lang_model.model.layers.6.self_attn.v_proj.weight,lang_model.model.layers.6.self_attn.o_proj.weight,lang_model.model.layers.6.mlp.gate_proj.weight,lang_model.model.layers.6.mlp.down_proj.weight,lang_model.model.layers.6.mlp.up_proj.weight,lang_model.model.layers.6.input_layernorm.weight,lang_model.model.layers.6.post_attention_layernorm.weight,lang_model.model.layers.7.self_attn.q_proj.weight,lang_model.model.layers.7.self_attn.k_proj.weight,lang_model.model.layers.7.self_attn.v_proj.weight,lang_model.model.layers.7.self_attn.o_proj.weight,lang_model.model.layers.7.mlp.gate_proj.weight,lang_model.model.layers.7.mlp.down_proj.weight,lang_model.model.layers.7.mlp.up_proj.weight,lang_model.model.layers.7.input_layernorm.weight,lang_model.model.layers.7.post_attention_layernorm.weight,lang_model.model.layers.8.self_attn.q_proj.weight,lang_model.model.layers.8.self_attn.k_proj.weight,lang_model.model.layers.8.self_attn.v_proj.weight,lang_model.model.layers.8.self_attn.o_proj.weight,lang_model.model.layers.8.mlp.gate_proj.weight,lang_model.model.layers.8.mlp.down_proj.weight,lang_model.model.layers.8.mlp.up_proj.weight,lang_model.model.layers.8.input_layernorm.weight,lang_model.model.layers.8.post_attention_layernorm.weight,lang_model.model.layers.9.self_attn.q_proj.weight,lang_model.model.layers.9.self_attn.k_proj.weight,lang_model.model.layers.9.self_attn.v_proj.weight,lang_model.model.layers.9.self_attn.o_proj.weight,lang_model.model.layers.9.mlp.gate_proj.weight,lang_model.model.layers.9.mlp.down_proj.weight,lang_model.model.layers.9.mlp.up_proj.weight,lang_model.model.layers.9.input_layernorm.weight,lang_model.model.layers.9.post_attention_layernorm.weight,lang_model.model.layers.10.self_attn.q_proj.weight,lang_model.model.layers.10.self_attn.k_proj.weight,lang_model.model.layers.10.self_attn.v_proj.weight,lang_model.model.layers.10.self_attn.o_proj.weight,lang_model.model.layers.10.mlp.gate_proj.weight,lang_model.model.layers.10.mlp.down_proj.weight,lang_model.model.layers.10.mlp.up_proj.weight,lang_model.model.layers.10.input_layernorm.weight,lang_model.model.layers.10.post_attention_layernorm.weight,lang_model.model.layers.11.self_attn.q_proj.weight,lang_model.model.layers.11.self_attn.k_proj.weight,lang_model.model.layers.11.self_attn.v_proj.weight,lang_model.model.layers.11.self_attn.o_proj.weight,lang_model.model.layers.11.mlp.gate_proj.weight,lang_model.model.layers.11.mlp.down_proj.weight,lang_model.model.layers.11.mlp.up_proj.weight,lang_model.model.layers.11.input_layernorm.weight,lang_model.model.layers.11.post_attention_layernorm.weight,lang_model.model.layers.12.self_attn.q_proj.weight,lang_model.model.layers.12.self_attn.k_proj.weight,lang_model.model.layers.12.self_attn.v_proj.weight,lang_model.model.layers.12.self_attn.o_proj.weight,lang_model.model.layers.12.mlp.gate_proj.weight,lang_model.model.layers.12.mlp.down_proj.weight,lang_model.model.layers.12.mlp.up_proj.weight,lang_model.model.layers.12.input_layernorm.weight,lang_model.model.layers.12.post_attention_layernorm.weight,lang_model.model.layers.13.self_attn.q_proj.weight,lang_model.model.layers.13.self_attn.k_proj.weight,lang_model.model.layers.13.self_attn.v_proj.weight,lang_model.model.layers.13.self_attn.o_proj.weight,lang_model.model.layers.13.mlp.gate_proj.weight,lang_model.model.layers.13.mlp.down_proj.weight,lang_model.model.layers.13.mlp.up_proj.weight,lang_model.model.layers.13.input_layernorm.weight,lang_model.model.layers.13.post_attention_layernorm.weight,lang_model.model.layers.14.self_attn.q_proj.weight,lang_model.model.layers.14.self_attn.k_proj.weight,lang_model.model.layers.14.self_attn.v_proj.weight,lang_model.model.layers.14.self_attn.o_proj.weight,lang_model.model.layers.14.mlp.gate_proj.weight,lang_model.model.layers.14.mlp.down_proj.weight,lang_model.model.layers.14.mlp.up_proj.weight,lang_model.model.layers.14.input_layernorm.weight,lang_model.model.layers.14.post_attention_layernorm.weight,lang_model.model.layers.15.self_attn.q_proj.weight,lang_model.model.layers.15.self_attn.k_proj.weight,lang_model.model.layers.15.self_attn.v_proj.weight,lang_model.model.layers.15.self_attn.o_proj.weight,lang_model.model.layers.15.mlp.gate_proj.weight,lang_model.model.layers.15.mlp.down_proj.weight,lang_model.model.layers.15.mlp.up_proj.weight,lang_model.model.layers.15.input_layernorm.weight,lang_model.model.layers.15.post_attention_layernorm.weight,lang_model.model.layers.16.self_attn.q_proj.weight,lang_model.model.layers.16.self_attn.k_proj.weight,lang_model.model.layers.16.self_attn.v_proj.weight,lang_model.model.layers.16.self_attn.o_proj.weight,lang_model.model.layers.16.mlp.gate_proj.weight,lang_model.model.layers.16.mlp.down_proj.weight,lang_model.model.layers.16.mlp.up_proj.weight,lang_model.model.layers.16.input_layernorm.weight,lang_model.model.layers.16.post_attention_layernorm.weight,lang_model.model.layers.17.self_attn.q_proj.weight,lang_model.model.layers.17.self_attn.k_proj.weight,lang_model.model.layers.17.self_attn.v_proj.weight,lang_model.model.layers.17.self_attn.o_proj.weight,lang_model.model.layers.17.mlp.gate_proj.weight,lang_model.model.layers.17.mlp.down_proj.weight,lang_model.model.layers.17.mlp.up_proj.weight,lang_model.model.layers.17.input_layernorm.weight,lang_model.model.layers.17.post_attention_layernorm.weight,lang_model.model.layers.18.self_attn.q_proj.weight,lang_model.model.layers.18.self_attn.k_proj.weight,lang_model.model.layers.18.self_attn.v_proj.weight,lang_model.model.layers.18.self_attn.o_proj.weight,lang_model.model.layers.18.mlp.gate_proj.weight,lang_model.model.layers.18.mlp.down_proj.weight,lang_model.model.layers.18.mlp.up_proj.weight,lang_model.model.layers.18.input_layernorm.weight,lang_model.model.layers.18.post_attention_layernorm.weight,lang_model.model.layers.19.self_attn.q_proj.weight,lang_model.model.layers.19.self_attn.k_proj.weight,lang_model.model.layers.19.self_attn.v_proj.weight,lang_model.model.layers.19.self_attn.o_proj.weight,lang_model.model.layers.19.mlp.gate_proj.weight,lang_model.model.layers.19.mlp.down_proj.weight,lang_model.model.layers.19.mlp.up_proj.weight,lang_model.model.layers.19.input_layernorm.weight,lang_model.model.layers.19.post_attention_layernorm.weight,lang_model.model.layers.20.self_attn.q_proj.weight,lang_model.model.layers.20.self_attn.k_proj.weight,lang_model.model.layers.20.self_attn.v_proj.weight,lang_model.model.layers.20.self_attn.o_proj.weight,lang_model.model.layers.20.mlp.gate_proj.weight,lang_model.model.layers.20.mlp.down_proj.weight,lang_model.model.layers.20.mlp.up_proj.weight,lang_model.model.layers.20.input_layernorm.weight,lang_model.model.layers.20.post_attention_layernorm.weight,lang_model.model.layers.21.self_attn.q_proj.weight,lang_model.model.layers.21.self_attn.k_proj.weight,lang_model.model.layers.21.self_attn.v_proj.weight,lang_model.model.layers.21.self_attn.o_proj.weight,lang_model.model.layers.21.mlp.gate_proj.weight,lang_model.model.layers.21.mlp.down_proj.weight,lang_model.model.layers.21.mlp.up_proj.weight,lang_model.model.layers.21.input_layernorm.weight,lang_model.model.layers.21.post_attention_layernorm.weight,lang_model.model.layers.22.self_attn.q_proj.weight,lang_model.model.layers.22.self_attn.k_proj.weight,lang_model.model.layers.22.self_attn.v_proj.weight,lang_model.model.layers.22.self_attn.o_proj.weight,lang_model.model.layers.22.mlp.gate_proj.weight,lang_model.model.layers.22.mlp.down_proj.weight,lang_model.model.layers.22.mlp.up_proj.weight,lang_model.model.layers.22.input_layernorm.weight,lang_model.model.layers.22.post_attention_layernorm.weight,lang_model.model.layers.23.self_attn.q_proj.weight,lang_model.model.layers.23.self_attn.k_proj.weight,lang_model.model.layers.23.self_attn.v_proj.weight,lang_model.model.layers.23.self_attn.o_proj.weight,lang_model.model.layers.23.mlp.gate_proj.weight,lang_model.model.layers.23.mlp.down_proj.weight,lang_model.model.layers.23.mlp.up_proj.weight,lang_model.model.layers.23.input_layernorm.weight,lang_model.model.layers.23.post_attention_layernorm.weight,lang_model.model.layers.24.self_attn.q_proj.weight,lang_model.model.layers.24.self_attn.k_proj.weight,lang_model.model.layers.24.self_attn.v_proj.weight,lang_model.model.layers.24.self_attn.o_proj.weight,lang_model.model.layers.24.mlp.gate_proj.weight,lang_model.model.layers.24.mlp.down_proj.weight,lang_model.model.layers.24.mlp.up_proj.weight,lang_model.model.layers.24.input_layernorm.weight,lang_model.model.layers.24.post_attention_layernorm.weight,lang_model.model.layers.25.self_attn.q_proj.weight,lang_model.model.layers.25.self_attn.k_proj.weight,lang_model.model.layers.25.self_attn.v_proj.weight,lang_model.model.layers.25.self_attn.o_proj.weight,lang_model.model.layers.25.mlp.gate_proj.weight,lang_model.model.layers.25.mlp.down_proj.weight,lang_model.model.layers.25.mlp.up_proj.weight,lang_model.model.layers.25.input_layernorm.weight,lang_model.model.layers.25.post_attention_layernorm.weight,lang_model.model.layers.26.self_attn.q_proj.weight,lang_model.model.layers.26.self_attn.k_proj.weight,lang_model.model.layers.26.self_attn.v_proj.weight,lang_model.model.layers.26.self_attn.o_proj.weight,lang_model.model.layers.26.mlp.gate_proj.weight,lang_model.model.layers.26.mlp.down_proj.weight,lang_model.model.layers.26.mlp.up_proj.weight,lang_model.model.layers.26.input_layernorm.weight,lang_model.model.layers.26.post_attention_layernorm.weight,lang_model.model.layers.27.self_attn.q_proj.weight,lang_model.model.layers.27.self_attn.k_proj.weight,lang_model.model.layers.27.self_attn.v_proj.weight,lang_model.model.layers.27.self_attn.o_proj.weight,lang_model.model.layers.27.mlp.gate_proj.weight,lang_model.model.layers.27.mlp.down_proj.weight,lang_model.model.layers.27.mlp.up_proj.weight,lang_model.model.layers.27.input_layernorm.weight,lang_model.model.layers.27.post_attention_layernorm.weight,lang_model.model.layers.28.self_attn.q_proj.weight,lang_model.model.layers.28.self_attn.k_proj.weight,lang_model.model.layers.28.self_attn.v_proj.weight,lang_model.model.layers.28.self_attn.o_proj.weight,lang_model.model.layers.28.mlp.gate_proj.weight,lang_model.model.layers.28.mlp.down_proj.weight,lang_model.model.layers.28.mlp.up_proj.weight,lang_model.model.layers.28.input_layernorm.weight,lang_model.model.layers.28.post_attention_layernorm.weight,lang_model.model.layers.29.self_attn.q_proj.weight,lang_model.model.layers.29.self_attn.k_proj.weight,lang_model.model.layers.29.self_attn.v_proj.weight,lang_model.model.layers.29.self_attn.o_proj.weight,lang_model.model.layers.29.mlp.gate_proj.weight,lang_model.model.layers.29.mlp.down_proj.weight,lang_model.model.layers.29.mlp.up_proj.weight,lang_model.model.layers.29.input_layernorm.weight,lang_model.model.layers.29.post_attention_layernorm.weight,lang_model.model.layers.30.self_attn.q_proj.weight,lang_model.model.layers.30.self_attn.k_proj.weight,lang_model.model.layers.30.self_attn.v_proj.weight,lang_model.model.layers.30.self_attn.o_proj.weight,lang_model.model.layers.30.mlp.gate_proj.weight,lang_model.model.layers.30.mlp.down_proj.weight,lang_model.model.layers.30.mlp.up_proj.weight,lang_model.model.layers.30.input_layernorm.weight,lang_model.model.layers.30.post_attention_layernorm.weight,lang_model.model.layers.31.self_attn.q_proj.weight,lang_model.model.layers.31.self_attn.k_proj.weight,lang_model.model.layers.31.self_attn.v_proj.weight,lang_model.model.layers.31.self_attn.o_proj.weight,lang_model.model.layers.31.mlp.gate_proj.weight,lang_model.model.layers.31.mlp.down_proj.weight,lang_model.model.layers.31.mlp.up_proj.weight,lang_model.model.layers.31.input_layernorm.weight,lang_model.model.layers.31.post_attention_layernorm.weight,lang_model.model.norm.weight,lang_model.lm_head.weight,img_embeddings.img_linear.weight,img_embeddings.img_linear.bias,img_embeddings.img_layer_norm.weight,img_embeddings.img_layer_norm.bias,img_embeddings.loc_linear.weight,img_embeddings.loc_linear.bias,img_embeddings.loc_layer_norm.weight,img_embeddings.loc_layer_norm.bias,img_embeddings.obj_projector.0.weight,img_embeddings.obj_projector.0.bias,img_embeddings.obj_projector.1.weight,img_embeddings.obj_projector.1.bias,img_embeddings.nav_type_embedding.weight,img_embeddings.layer_norm.weight,img_embeddings.layer_norm.bias,img_embeddings.pano_encoder.layers.0.self_attn.in_proj_weight,img_embeddings.pano_encoder.layers.0.self_attn.in_proj_bias,img_embeddings.pano_encoder.layers.0.self_attn.out_proj.weight,img_embeddings.pano_encoder.layers.0.self_attn.out_proj.bias,img_embeddings.pano_encoder.layers.0.linear1.weight,img_embeddings.pano_encoder.layers.0.linear1.bias,img_embeddings.pano_encoder.layers.0.linear2.weight,img_embeddings.pano_encoder.layers.0.linear2.bias,img_embeddings.pano_encoder.layers.0.norm1.weight,img_embeddings.pano_encoder.layers.0.norm1.bias,img_embeddings.pano_encoder.layers.0.norm2.weight,img_embeddings.pano_encoder.layers.0.norm2.bias,img_embeddings.pano_encoder.layers.1.self_attn.in_proj_weight,img_embeddings.pano_encoder.layers.1.self_attn.in_proj_bias,img_embeddings.pano_encoder.layers.1.self_attn.out_proj.weight,img_embeddings.pano_encoder.layers.1.self_attn.out_proj.bias,img_embeddings.pano_encoder.layers.1.linear1.weight,img_embeddings.pano_encoder.layers.1.linear1.bias,img_embeddings.pano_encoder.layers.1.linear2.weight,img_embeddings.pano_encoder.layers.1.linear2.bias,img_embeddings.pano_encoder.layers.1.norm1.weight,img_embeddings.pano_encoder.layers.1.norm1.bias,img_embeddings.pano_encoder.layers.1.norm2.weight,img_embeddings.pano_encoder.layers.1.norm2.bias,img_embeddings.pano_encoder.norm.weight,img_embeddings.pano_encoder.norm.bias,img_embeddings.mapper.weight,img_embeddings.mapper.bias,token_type_embeddings.weight,gmap_pos_embeddings.0.weight,gmap_pos_embeddings.0.bias,gmap_pos_embeddings.1.weight,gmap_pos_embeddings.1.bias,gmap_step_embeddings.weight,vp_pos_embeddings.0.weight,vp_pos_embeddings.0.bias,vp_pos_embeddings.1.weight,vp_pos_embeddings.1.bias,obj_pos_embeddings.0.weight,obj_pos_embeddings.0.bias,obj_pos_embeddings.1.weight,obj_pos_embeddings.1.bias,og_head.0.weight,og_head.0.bias,out_head.0.weight,out_head.0.bias
2026-01-06 07:42:36,734   INFO  *************** init model *************** 
2026-01-06 07:42:39,220   INFO  Loading checkpoint from /data/wanghaoxuan/model_with_pretrain.pt
2026-01-06 07:42:44,710   INFO  <All keys matched successfully>
2026-01-06 07:42:45,042   INFO  model initialized with 6773.48 M trainable parameters
2026-01-06 07:42:45,042   INFO  Training with a single process
2026-01-06 07:42:45,043   INFO  **************************** Test ****************************
2026-01-06 07:42:45,044   INFO  ***** validate test split on REVERIE task *****
2026-01-06 08:44:17,263   INFO  
[Eval] test epoch 0

